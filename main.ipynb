{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267c7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & config\n",
    "\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead36b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"./data/csv\"\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LEN = 20              # number of past games per team\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 3\n",
    "LR = 1e-4\n",
    "EPOCHS = 40\n",
    "ERA_START = pd.to_datetime(\"2010-10-01\")\n",
    "VAL_SPLIT_DATE = \"2021-10-01\"\n",
    "TEST_SPLIT_DATE = \"2022-10-01\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56555458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== common_player_info.csv ===\n",
      "shape: (4171, 33)\n",
      "columns: ['person_id', 'first_name', 'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last', 'player_slug', 'birthdate', 'school', 'country', 'last_affiliation', 'height', 'weight', 'season_exp', 'jersey'] ...\n",
      "\n",
      "=== game_info.csv ===\n",
      "shape: (58053, 4)\n",
      "columns: ['game_id', 'game_date', 'attendance', 'game_time'] ...\n",
      "\n",
      "=== officials.csv ===\n",
      "shape: (70971, 5)\n",
      "columns: ['game_id', 'official_id', 'first_name', 'last_name', 'jersey_num'] ...\n",
      "\n",
      "=== team.csv ===\n",
      "shape: (30, 7)\n",
      "columns: ['id', 'full_name', 'abbreviation', 'nickname', 'city', 'state', 'year_founded'] ...\n",
      "\n",
      "=== draft_combine_stats.csv ===\n",
      "shape: (1202, 47)\n",
      "columns: ['season', 'player_id', 'first_name', 'last_name', 'player_name', 'position', 'height_wo_shoes', 'height_wo_shoes_ft_in', 'height_w_shoes', 'height_w_shoes_ft_in', 'weight', 'wingspan', 'wingspan_ft_in', 'standing_reach', 'standing_reach_ft_in'] ...\n",
      "\n",
      "=== game_summary.csv ===\n",
      "shape: (58110, 14)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'game_status_id', 'game_status_text', 'gamecode', 'home_team_id', 'visitor_team_id', 'season', 'live_period', 'live_pc_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast', 'wh_status'] ...\n",
      "\n",
      "=== other_stats.csv ===\n",
      "shape: (28271, 26)\n",
      "columns: ['game_id', 'league_id', 'team_id_home', 'team_abbreviation_home', 'team_city_home', 'pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home'] ...\n",
      "\n",
      "=== team_details.csv ===\n",
      "shape: (25, 14)\n",
      "columns: ['team_id', 'abbreviation', 'nickname', 'yearfounded', 'city', 'arena', 'arenacapacity', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'facebook', 'instagram', 'twitter'] ...\n",
      "\n",
      "=== draft_history.csv ===\n",
      "shape: (7990, 14)\n",
      "columns: ['person_id', 'player_name', 'season', 'round_number', 'round_pick', 'overall_pick', 'draft_type', 'team_id', 'team_city', 'team_name', 'team_abbreviation', 'organization', 'organization_type', 'player_profile_flag'] ...\n",
      "\n",
      "=== inactive_players.csv ===\n",
      "shape: (110191, 9)\n",
      "columns: ['game_id', 'player_id', 'first_name', 'last_name', 'jersey_num', 'team_id', 'team_city', 'team_name', 'team_abbreviation'] ...\n",
      "\n",
      "=== play_by_play.csv ===\n",
      "shape: (13592899, 34)\n",
      "columns: ['game_id', 'eventnum', 'eventmsgtype', 'eventmsgactiontype', 'period', 'wctimestring', 'pctimestring', 'homedescription', 'neutraldescription', 'visitordescription', 'score', 'scoremargin', 'person1type', 'player1_id', 'player1_name'] ...\n",
      "\n",
      "=== team_history.csv ===\n",
      "shape: (52, 5)\n",
      "columns: ['team_id', 'city', 'nickname', 'year_founded', 'year_active_till'] ...\n",
      "\n",
      "=== game.csv ===\n",
      "shape: (65698, 55)\n",
      "columns: ['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home', 'game_id', 'game_date', 'matchup_home', 'wl_home', 'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home'] ...\n",
      "\n",
      "=== line_score.csv ===\n",
      "shape: (58053, 43)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'team_id_home', 'team_abbreviation_home', 'team_city_name_home', 'team_nickname_home', 'team_wins_losses_home', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home'] ...\n",
      "\n",
      "=== player.csv ===\n",
      "shape: (4831, 5)\n",
      "columns: ['id', 'full_name', 'first_name', 'last_name', 'is_active'] ...\n",
      "\n",
      "=== team_info_common.csv ===\n",
      "shape: (0, 26)\n",
      "columns: ['team_id', 'season_year', 'team_city', 'team_name', 'team_abbreviation', 'team_conference', 'team_division', 'team_code', 'team_slug', 'w', 'l', 'pct', 'conf_rank', 'div_rank', 'min_year'] ...\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"common_player_info.csv\",\n",
    "    \"game_info.csv\",\n",
    "    \"officials.csv\",\n",
    "    \"team.csv\",\n",
    "    \"draft_combine_stats.csv\",\n",
    "    \"game_summary.csv\",\n",
    "    \"other_stats.csv\",\n",
    "    \"team_details.csv\",\n",
    "    \"draft_history.csv\",\n",
    "    \"inactive_players.csv\",\n",
    "    \"play_by_play.csv\",\n",
    "    \"team_history.csv\",\n",
    "    \"game.csv\",\n",
    "    \"line_score.csv\",\n",
    "    \"player.csv\",\n",
    "    \"team_info_common.csv\",\n",
    "]\n",
    "\n",
    "for fname in files:\n",
    "    path = os.path.join(DATA_DIR, fname)\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\n=== {fname} ===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"columns:\", list(df.columns)[:15], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd2417f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games: (65698, 55)\n",
      "game_info: (58053, 4)\n",
      "other_stats: (28271, 26)\n"
     ]
    }
   ],
   "source": [
    "# Core tables for modeling\n",
    "games = pd.read_csv(os.path.join(DATA_DIR, \"game.csv\"))\n",
    "game_info = pd.read_csv(os.path.join(DATA_DIR, \"game_info.csv\"))\n",
    "other_stats = pd.read_csv(os.path.join(DATA_DIR, \"other_stats.csv\"))\n",
    "\n",
    "print(\"games:\", games.shape)\n",
    "print(\"game_info:\", game_info.shape)\n",
    "print(\"other_stats:\", other_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47f7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column config for our pipeline\n",
    "GAME_ID_COL = \"game_id\"\n",
    "GAME_DATE_COL = \"game_date\"\n",
    "HOME_TEAM_COL = \"team_id_home\"\n",
    "AWAY_TEAM_COL = \"team_id_away\"\n",
    "PTS_HOME_COL = \"pts_home\"\n",
    "PTS_AWAY_COL = \"pts_away\"\n",
    "\n",
    "# Make sure game_date is datetime\n",
    "games[GAME_DATE_COL] = pd.to_datetime(games[GAME_DATE_COL])\n",
    "game_info[\"game_date\"] = pd.to_datetime(game_info[\"game_date\"])\n",
    "\n",
    "# Keep only modern-era games\n",
    "mask_games = games[GAME_DATE_COL] >= ERA_START\n",
    "games = games.loc[mask_games].reset_index(drop=True)\n",
    "\n",
    "# Match game_info to the same window\n",
    "mask_info = game_info[\"game_date\"] >= ERA_START\n",
    "game_info = game_info.loc[mask_info].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f2af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num home_feature_cols: 24\n",
      "Num away_feature_cols: 24\n",
      "team_games initial: (32560, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pf</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>94.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-38</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-33</td>\n",
       "      <td>81.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...    pf  plus_minus    pts   reb   stl  team_abbreviation  \\\n",
       "0  31.0  ...  20.0         -27   80.0  36.0   7.0                MTA   \n",
       "1  26.0  ...  27.0         -17   94.0  43.0   4.0                MTA   \n",
       "2  19.0  ...  30.0         -38   70.0  37.0  10.0                MAC   \n",
       "3  21.0  ...  22.0          -8  100.0  38.0   9.0                MAC   \n",
       "4  27.0  ...  30.0         -33   81.0  45.0   9.0                MAC   \n",
       "\n",
       "                  team_name   tov  video_available  wl  \n",
       "0  Tel Aviv Maccabi Electra   9.0                0   L  \n",
       "1  Tel Aviv Maccabi Electra  21.0                0   L  \n",
       "2       Haifa Maccabi Haifa  21.0                0   L  \n",
       "3       Haifa Maccabi Haifa  14.0                0   L  \n",
       "4       Haifa Maccabi Haifa  26.0                0   L  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Select home/away feature columns, EXCLUDING the team_id columns\n",
    "home_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_home\") and c != HOME_TEAM_COL\n",
    "]\n",
    "\n",
    "away_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_away\") and c != AWAY_TEAM_COL\n",
    "]\n",
    "\n",
    "print(\"Num home_feature_cols:\", len(home_feature_cols))\n",
    "print(\"Num away_feature_cols:\", len(away_feature_cols))\n",
    "\n",
    "# 2) Home rows\n",
    "home_df = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL] + home_feature_cols].copy()\n",
    "home_df = home_df.rename(columns={HOME_TEAM_COL: \"team_id\"})\n",
    "home_df[\"is_home\"] = 1\n",
    "\n",
    "for col in home_feature_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_df[base] = home_df[col]\n",
    "\n",
    "home_df[\"y_points\"] = home_df[PTS_HOME_COL]\n",
    "\n",
    "# 3) Away rows\n",
    "away_df = games[[GAME_ID_COL, GAME_DATE_COL, AWAY_TEAM_COL] + away_feature_cols].copy()\n",
    "away_df = away_df.rename(columns={AWAY_TEAM_COL: \"team_id\"})\n",
    "away_df[\"is_home\"] = 0\n",
    "\n",
    "for col in away_feature_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_df[base] = away_df[col]\n",
    "\n",
    "away_df[\"y_points\"] = away_df[PTS_AWAY_COL]\n",
    "\n",
    "# 4) Keep only unified columns\n",
    "keep_cols = [GAME_ID_COL, GAME_DATE_COL, \"team_id\", \"is_home\", \"y_points\"]\n",
    "base_feature_names = sorted(\n",
    "    {c.replace(\"_home\", \"\").replace(\"_away\", \"\") for c in home_feature_cols + away_feature_cols}\n",
    ")\n",
    "keep_cols += base_feature_names\n",
    "\n",
    "home_df = home_df[keep_cols].copy()\n",
    "away_df = away_df[keep_cols].copy()\n",
    "\n",
    "# 5) Combine into team_games\n",
    "team_games = pd.concat([home_df, away_df], axis=0).reset_index(drop=True)\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "print(\"team_games initial:\", team_games.shape)\n",
    "team_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed3ab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_info_small sample:\n",
      "    game_id  attendance  game_hour\n",
      "0  21000003     18997.0        NaN\n",
      "1  21000002     20603.0        NaN\n",
      "2  21000001     18624.0        NaN\n",
      "3  21000015     18428.0        NaN\n",
      "4  21000010     15039.0        NaN\n",
      "team_games after game_info: (32584, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "      <th>attendance</th>\n",
       "      <th>game_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>15915.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>5174.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>11192.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...    pts   reb   stl  team_abbreviation                 team_name  \\\n",
       "0  31.0  ...   80.0  36.0   7.0                MTA  Tel Aviv Maccabi Electra   \n",
       "1  26.0  ...   94.0  43.0   4.0                MTA  Tel Aviv Maccabi Electra   \n",
       "2  19.0  ...   70.0  37.0  10.0                MAC       Haifa Maccabi Haifa   \n",
       "3  21.0  ...  100.0  38.0   9.0                MAC       Haifa Maccabi Haifa   \n",
       "4  27.0  ...   81.0  45.0   9.0                MAC       Haifa Maccabi Haifa   \n",
       "\n",
       "    tov  video_available wl  attendance  game_hour  \n",
       "0   9.0                0  L     20562.0        NaN  \n",
       "1  21.0                0  L     15915.0        NaN  \n",
       "2  21.0                0  L      5174.0        NaN  \n",
       "3  14.0                0  L         NaN        NaN  \n",
       "4  26.0                0  L     11192.0        NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 2: merge game_info (attendance + game_hour) ---\n",
    "\n",
    "# Parse game_time to hour-of-day\n",
    "game_info[\"game_hour\"] = pd.to_datetime(\n",
    "    game_info[\"game_time\"],\n",
    "    format=\"%I:%M %p\",\n",
    "    errors=\"coerce\"\n",
    ").dt.hour\n",
    "\n",
    "# Keep only what we need\n",
    "game_info_small = game_info[[GAME_ID_COL, \"attendance\", \"game_hour\"]].copy()\n",
    "\n",
    "print(\"game_info_small sample:\")\n",
    "print(game_info_small.head())\n",
    "\n",
    "# Merge into team_games\n",
    "team_games = team_games.merge(\n",
    "    game_info_small,\n",
    "    on=GAME_ID_COL,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after game_info:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2b61f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_stats sample:\n",
      "    game_id  league_id  team_id_home team_abbreviation_home team_city_home  \\\n",
      "0  29600012          0    1610612756                    PHX        Phoenix   \n",
      "1  29600005          0    1610612737                    ATL        Atlanta   \n",
      "2  29600002          0    1610612739                    CLE      Cleveland   \n",
      "3  29600007          0    1610612754                    IND        Indiana   \n",
      "4  29600013          0    1610612746                    LAC    Los Angeles   \n",
      "\n",
      "   pts_paint_home  pts_2nd_chance_home  pts_fb_home  largest_lead_home  \\\n",
      "0              44                   18            2                  1   \n",
      "1              32                    9            6                  0   \n",
      "2              36                   14            6                 20   \n",
      "3              34                   11            4                 10   \n",
      "4              40                   19            2                 12   \n",
      "\n",
      "   lead_changes  ...  team_abbreviation_away  team_city_away  pts_paint_away  \\\n",
      "0             4  ...                     LAL     Los Angeles              42   \n",
      "1             0  ...                     MIA           Miami              32   \n",
      "2             1  ...                     NJN      New Jersey              26   \n",
      "3             7  ...                     DET         Detroit              30   \n",
      "4             5  ...                     GSW    Golden State              30   \n",
      "\n",
      "   pts_2nd_chance_away  pts_fb_away  largest_lead_away team_turnovers_away  \\\n",
      "0                   10           13                 19                 0.0   \n",
      "1                   15           14                 16                 1.0   \n",
      "2                   16            4                  2                 1.0   \n",
      "3                   14            7                  9                 2.0   \n",
      "4                    9            2                  6                 0.0   \n",
      "\n",
      "  total_turnovers_away  team_rebounds_away  pts_off_to_away  \n",
      "0                 23.0                11.0              NaN  \n",
      "1                 19.0                 6.0              NaN  \n",
      "2                 22.0                12.0              NaN  \n",
      "3                 19.0                10.0              NaN  \n",
      "4                 20.0                 7.0              NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "home_stat_cols: ['pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home']\n",
      "away_stat_cols: ['pts_paint_away', 'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away', 'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away']\n",
      "game_level_cols: ['lead_changes', 'times_tied']\n",
      "home_adv shape: (28271, 12)\n",
      "away_adv shape: (28271, 12)\n",
      "adv_long shape: (56542, 12)\n",
      "    game_id     team_id  lead_changes  times_tied  pts_paint  pts_2nd_chance  \\\n",
      "0  29600012  1610612756             4           1         44              18   \n",
      "1  29600005  1610612737             0           0         32               9   \n",
      "2  29600002  1610612739             1           1         36              14   \n",
      "3  29600007  1610612754             7           4         34              11   \n",
      "4  29600013  1610612746             5           4         40              19   \n",
      "\n",
      "   pts_fb  largest_lead  team_turnovers  total_turnovers  team_rebounds  \\\n",
      "0       2             1             0.0             12.0           11.0   \n",
      "1       6             0             1.0             24.0            7.0   \n",
      "2       6            20             0.0             15.0            5.0   \n",
      "3       4            10             0.0             18.0            8.0   \n",
      "4       2            12             0.0             20.0            7.0   \n",
      "\n",
      "   pts_off_to  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "team_games after other_stats: (32632, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>lead_changes</th>\n",
       "      <th>times_tied</th>\n",
       "      <th>pts_paint</th>\n",
       "      <th>pts_2nd_chance</th>\n",
       "      <th>pts_fb</th>\n",
       "      <th>largest_lead</th>\n",
       "      <th>team_turnovers</th>\n",
       "      <th>total_turnovers</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...  lead_changes  times_tied  pts_paint  pts_2nd_chance  pts_fb  \\\n",
       "0  31.0  ...           1.0         3.0       32.0            12.0     3.0   \n",
       "1  26.0  ...           0.0         0.0       54.0            15.0    12.0   \n",
       "2  19.0  ...           3.0         1.0       28.0             8.0    17.0   \n",
       "3  21.0  ...           NaN         NaN        NaN             NaN     NaN   \n",
       "4  27.0  ...           2.0         2.0       30.0            19.0     4.0   \n",
       "\n",
       "   largest_lead  team_turnovers total_turnovers  team_rebounds  pts_off_to  \n",
       "0           3.0             0.0             9.0            5.0         8.0  \n",
       "1           0.0             1.0            21.0            7.0        28.0  \n",
       "2           3.0             0.0            21.0           10.0        29.0  \n",
       "3           NaN             NaN             NaN            NaN         NaN  \n",
       "4           3.0             0.0            26.0            7.0        35.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 3: merge other_stats (advanced team stats) ---\n",
    "\n",
    "print(\"other_stats sample:\")\n",
    "print(other_stats.head())\n",
    "\n",
    "# Game-level columns that apply to the whole game\n",
    "game_level_cols = []\n",
    "for col in [\"lead_changes\", \"times_tied\"]:\n",
    "    if col in other_stats.columns:\n",
    "        game_level_cols.append(col)\n",
    "\n",
    "# Home/away advanced stat columns (excluding id/label columns)\n",
    "home_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_home\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "away_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_away\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "print(\"home_stat_cols:\", home_stat_cols)\n",
    "print(\"away_stat_cols:\", away_stat_cols)\n",
    "print(\"game_level_cols:\", game_level_cols)\n",
    "\n",
    "# 4.1 Home advanced stats → unified format\n",
    "home_adv = other_stats[[\"game_id\", \"team_id_home\"] + game_level_cols + home_stat_cols].copy()\n",
    "home_adv = home_adv.rename(columns={\"team_id_home\": \"team_id\"})\n",
    "\n",
    "for col in home_stat_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_adv[base] = home_adv[col]\n",
    "\n",
    "home_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_home\", \"\") for c in home_stat_cols]\n",
    "home_adv = home_adv[home_keep_cols]\n",
    "\n",
    "# 4.2 Away advanced stats → unified format\n",
    "away_adv = other_stats[[\"game_id\", \"team_id_away\"] + game_level_cols + away_stat_cols].copy()\n",
    "away_adv = away_adv.rename(columns={\"team_id_away\": \"team_id\"})\n",
    "\n",
    "for col in away_stat_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_adv[base] = away_adv[col]\n",
    "\n",
    "away_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_away\", \"\") for c in away_stat_cols]\n",
    "away_adv = away_adv[away_keep_cols]\n",
    "\n",
    "print(\"home_adv shape:\", home_adv.shape)\n",
    "print(\"away_adv shape:\", away_adv.shape)\n",
    "\n",
    "# 4.3 Combine advanced stats\n",
    "adv_long = pd.concat([home_adv, away_adv], axis=0).reset_index(drop=True)\n",
    "print(\"adv_long shape:\", adv_long.shape)\n",
    "print(adv_long.head())\n",
    "\n",
    "# 4.4 Merge advanced stats into team_games\n",
    "team_games = team_games.merge(\n",
    "    adv_long,\n",
    "    on=[\"game_id\", \"team_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after other_stats:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e860f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequence features: 37\n",
      "First 30 SEQ_FEATURES: ['is_home', 'ast', 'blk', 'dreb', 'fg3_pct', 'fg3a', 'fg3m', 'fg_pct', 'fga', 'fgm', 'ft_pct', 'fta', 'ftm', 'oreb', 'pf', 'plus_minus', 'pts', 'reb', 'stl', 'tov', 'video_available', 'attendance', 'game_hour', 'lead_changes', 'times_tied', 'pts_paint', 'pts_2nd_chance', 'pts_fb', 'largest_lead', 'team_turnovers']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>prev3_date</th>\n",
       "      <th>prev4_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>is_3in4</th>\n",
       "      <th>is_4in6</th>\n",
       "      <th>team_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.693698</td>\n",
       "      <td>0.849701</td>\n",
       "      <td>-0.903462</td>\n",
       "      <td>-0.953262</td>\n",
       "      <td>0.554806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501082</td>\n",
       "      <td>-0.738944</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.173476</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-1.447486</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>-0.180799</td>\n",
       "      <td>-1.222245</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>1.702937</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.104295</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1.635933</td>\n",
       "      <td>-1.131691</td>\n",
       "      <td>-1.445459</td>\n",
       "      <td>-0.375448</td>\n",
       "      <td>-0.783777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712153</td>\n",
       "      <td>1.825031</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.173476</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060090</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>-1.264794</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>-0.560680</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.714317</td>\n",
       "      <td>-1.715697</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>25.388655</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-1.070592</td>\n",
       "      <td>-0.339134</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.162517</td>\n",
       "      <td>0.108612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>2.557596</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points       ast       blk  \\\n",
       "0  11400003 2014-10-05       41     -1.0      80.0 -0.693698  0.849701   \n",
       "1  11400011 2014-10-07       41     -1.0      94.0 -1.447486  0.057144   \n",
       "2  11000002 2010-10-03       93     -1.0      70.0 -1.635933 -1.131691   \n",
       "3  11200029 2012-10-11       93     -1.0     100.0  0.060090  0.057144   \n",
       "4  11200056 2012-10-16       93     -1.0      81.0 -1.070592 -0.339134   \n",
       "\n",
       "       dreb   fg3_pct      fg3a  ...  team_rebounds  pts_off_to  prev_date  \\\n",
       "0 -0.903462 -0.953262  0.554806  ...      -0.501082   -0.738944        NaT   \n",
       "1 -0.180799 -1.222245 -0.002937  ...      -0.015788    1.702937 2014-10-05   \n",
       "2 -1.445459 -0.375448 -0.783777  ...       0.712153    1.825031        NaT   \n",
       "3 -1.264794  0.272103 -0.560680  ...      -1.714317   -1.715697 2010-10-03   \n",
       "4 -0.000133  0.162517  0.108612  ...      -0.015788    2.557596 2012-10-11   \n",
       "\n",
       "   prev3_date  prev4_date  days_rest    is_b2b  is_3in4   is_4in6  team_idx  \n",
       "0         NaT         NaT  -0.173476 -0.485414 -0.14156 -0.217296         0  \n",
       "1         NaT         NaT  -0.104295 -0.485414 -0.14156 -0.217296         0  \n",
       "2         NaT         NaT  -0.173476 -0.485414 -0.14156 -0.217296         1  \n",
       "3         NaT         NaT  25.388655 -0.485414 -0.14156 -0.217296         1  \n",
       "4         NaT         NaT  -0.000525 -0.485414 -0.14156 -0.217296         1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compute SEQ_FEATURES and scale ---\n",
    "\n",
    "# --- Schedule features: rest / B2B / 3-in-4 / 4-in-6 ---\n",
    "\n",
    "# Ensure sorted by team + date\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "grouped = team_games.groupby(\"team_id\")\n",
    "\n",
    "# Previous game dates\n",
    "team_games[\"prev_date\"]  = grouped[GAME_DATE_COL].shift(1)\n",
    "team_games[\"prev3_date\"] = grouped[GAME_DATE_COL].shift(3)\n",
    "team_games[\"prev4_date\"] = grouped[GAME_DATE_COL].shift(4)\n",
    "\n",
    "# Days of rest since last game\n",
    "team_games[\"days_rest\"] = (team_games[GAME_DATE_COL] - team_games[\"prev_date\"]).dt.days\n",
    "\n",
    "# Schedule intensity flags\n",
    "team_games[\"is_b2b\"]  = (team_games[\"days_rest\"] == 1).astype(int)\n",
    "\n",
    "team_games[\"is_3in4\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev3_date\"]).dt.days <= 4\n",
    ").astype(int)\n",
    "\n",
    "team_games[\"is_4in6\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev4_date\"]).dt.days <= 6\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# --- Team ID ↔ index mapping for embeddings ---\n",
    "\n",
    "team_ids = sorted(team_games[\"team_id\"].unique())\n",
    "team_id_to_idx = {tid: i for i, tid in enumerate(team_ids)}\n",
    "num_teams = len(team_ids)\n",
    "\n",
    "# Optional: store per-row team index (not used in SEQ_FEATURES)\n",
    "team_games[\"team_idx\"] = team_games[\"team_id\"].map(team_id_to_idx)\n",
    "\n",
    "\n",
    "\n",
    "exclude_cols = {\n",
    "    GAME_ID_COL,\n",
    "    GAME_DATE_COL,\n",
    "    \"team_id\",\n",
    "    \"y_points\",\n",
    "    \"prev_date\",\n",
    "    \"prev3_date\",\n",
    "    \"prev4_date\",\n",
    "    \"team_idx\",   # NEW: don't treat this as numeric feature\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in team_games.columns\n",
    "    if c not in exclude_cols and pd.api.types.is_numeric_dtype(team_games[c])\n",
    "]\n",
    "\n",
    "SEQ_FEATURES = numeric_cols\n",
    "print(\"Number of sequence features:\", len(SEQ_FEATURES))\n",
    "print(\"First 30 SEQ_FEATURES:\", SEQ_FEATURES[:30])\n",
    "\n",
    "train_rows = team_games[team_games[GAME_DATE_COL] < VAL_SPLIT_DATE].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_rows[SEQ_FEATURES].fillna(0.0))\n",
    "\n",
    "team_games[SEQ_FEATURES] = scaler.transform(\n",
    "    team_games[SEQ_FEATURES].fillna(0.0)\n",
    ")\n",
    "\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d671461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_sequences: (31929, 20, 37)\n",
      "team_targets: (31929,)\n"
     ]
    }
   ],
   "source": [
    "team_sequences = []\n",
    "team_targets = []\n",
    "team_meta = []  # (game_id, team_id, game_date)\n",
    "\n",
    "for team_id, group in team_games.groupby(\"team_id\"):\n",
    "    group = group.sort_values(GAME_DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    feats = group[SEQ_FEATURES].values           # [num_games, F]\n",
    "    targets = group[\"y_points\"].values\n",
    "    game_ids = group[GAME_ID_COL].values\n",
    "    dates = group[GAME_DATE_COL].values\n",
    "\n",
    "    # require SEQ_LEN previous games\n",
    "    for i in range(SEQ_LEN, len(group)):\n",
    "        seq = feats[i-SEQ_LEN:i]\n",
    "        y = targets[i]\n",
    "        gid = game_ids[i]\n",
    "        date = dates[i]\n",
    "\n",
    "        team_sequences.append(seq)\n",
    "        team_targets.append(y)\n",
    "        team_meta.append((gid, team_id, date))\n",
    "\n",
    "team_sequences = np.stack(team_sequences)          # [N_team_games, T, F]\n",
    "team_targets = np.array(team_targets, dtype=np.float32)\n",
    "\n",
    "print(\"team_sequences:\", team_sequences.shape)\n",
    "print(\"team_targets:\", team_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6a9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_index_by_game_team = {\n",
    "    (gid, tid): idx\n",
    "    for idx, (gid, tid, date) in enumerate(team_meta)\n",
    "}\n",
    "\n",
    "len(seq_index_by_game_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18856e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_full: (16280, 6)\n"
     ]
    }
   ],
   "source": [
    "games_full = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL, AWAY_TEAM_COL, PTS_HOME_COL, PTS_AWAY_COL]].copy()\n",
    "\n",
    "games_full = games_full.rename(columns={\n",
    "    HOME_TEAM_COL: \"home_team_id\",\n",
    "    AWAY_TEAM_COL: \"away_team_id\",\n",
    "    PTS_HOME_COL: \"y_home\",\n",
    "    PTS_AWAY_COL: \"y_away\"\n",
    "})\n",
    "\n",
    "print(\"games_full:\", games_full.shape)\n",
    "games_full.head()\n",
    "\n",
    "\n",
    "X_home = []\n",
    "X_away = []\n",
    "Y = []\n",
    "GAME_DATES = []\n",
    "\n",
    "HOME_TEAM_IDX = []\n",
    "AWAY_TEAM_IDX = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c119c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes:\n",
      "X_home: (15908, 20, 37)\n",
      "X_away: (15908, 20, 37)\n",
      "Y: (15908, 2)\n",
      "home team idx [34 27 30 ... 27 52 52]\n",
      "away team idx [31 35 36 ... 32 51 51]\n"
     ]
    }
   ],
   "source": [
    "X_home = []\n",
    "X_away = []\n",
    "Y = []\n",
    "GAME_DATES = []\n",
    "\n",
    "for _, row in games_full.iterrows():\n",
    "    gid = row[GAME_ID_COL]\n",
    "    home_id = row[\"home_team_id\"]\n",
    "    away_id = row[\"away_team_id\"]\n",
    "    date = row[GAME_DATE_COL]\n",
    "\n",
    "    key_home = (gid, home_id)\n",
    "    key_away = (gid, away_id)\n",
    "\n",
    "    if key_home not in seq_index_by_game_team or key_away not in seq_index_by_game_team:\n",
    "        continue  # skip early games\n",
    "\n",
    "    idx_h = seq_index_by_game_team[key_home]\n",
    "    idx_a = seq_index_by_game_team[key_away]\n",
    "\n",
    "    X_home.append(team_sequences[idx_h])\n",
    "    X_away.append(team_sequences[idx_a])\n",
    "    \n",
    "    # Build as margin instead of abs\n",
    "    home = row[\"y_home\"]\n",
    "    away = row[\"y_away\"]\n",
    "\n",
    "    margin = home - away\n",
    "    total  = home + away\n",
    "\n",
    "    Y.append([margin, total])\n",
    "    \n",
    "    GAME_DATES.append(date)\n",
    "    \n",
    "    HOME_TEAM_IDX.append(team_id_to_idx[home_id])\n",
    "    AWAY_TEAM_IDX.append(team_id_to_idx[away_id])\n",
    "\n",
    "X_home = np.stack(X_home)\n",
    "X_away = np.stack(X_away)\n",
    "Y = np.array(Y, dtype=np.float32)\n",
    "GAME_DATES = np.array(GAME_DATES)\n",
    "\n",
    "HOME_TEAM_IDX = np.array(HOME_TEAM_IDX, dtype=np.int64)\n",
    "AWAY_TEAM_IDX = np.array(AWAY_TEAM_IDX, dtype=np.int64)\n",
    "\n",
    "print(\"Final dataset shapes:\")\n",
    "print(\"X_home:\", X_home.shape)\n",
    "print(\"X_away:\", X_away.shape)\n",
    "print(\"Y:\", Y.shape)\n",
    "print(\"home team idx\", HOME_TEAM_IDX)\n",
    "print(\"away team idx\", AWAY_TEAM_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25fd0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 13143 Val: 1385 Test: 1380\n",
      "Train mean scores (margin, total): [  2.5303204 208.5638   ]\n"
     ]
    }
   ],
   "source": [
    "VAL_SPLIT_DATE = pd.to_datetime(VAL_SPLIT_DATE)\n",
    "TEST_SPLIT_DATE = pd.to_datetime(TEST_SPLIT_DATE)\n",
    "\n",
    "dates = pd.to_datetime(GAME_DATES)\n",
    "\n",
    "train_mask = dates < VAL_SPLIT_DATE\n",
    "val_mask = (dates >= VAL_SPLIT_DATE) & (dates < TEST_SPLIT_DATE)\n",
    "test_mask = dates >= TEST_SPLIT_DATE\n",
    "\n",
    "def split(arr):\n",
    "    return arr[train_mask], arr[val_mask], arr[test_mask]\n",
    "\n",
    "X_home_train, X_home_val, X_home_test = split(X_home)\n",
    "X_away_train, X_away_val, X_away_test = split(X_away)\n",
    "Y_train, Y_val, Y_test = split(Y)\n",
    "\n",
    "home_idx_train, home_idx_val, home_idx_test = split(HOME_TEAM_IDX)\n",
    "away_idx_train, away_idx_val, away_idx_test = split(AWAY_TEAM_IDX)\n",
    "\n",
    "print(\"Train:\", len(Y_train), \"Val:\", len(Y_val), \"Test:\", len(Y_test))\n",
    "\n",
    "\n",
    "# --- NEW: keep raw targets and create a scaler for [margin, total] ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_mean_scores = Y_train.mean(axis=0)   # still raw here!\n",
    "print(\"Train mean scores (margin, total):\", train_mean_scores)\n",
    "\n",
    "Y_train_raw = Y_train.copy()\n",
    "Y_val_raw   = Y_val.copy()\n",
    "Y_test_raw  = Y_test.copy()\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(Y_train_raw)        # fit on train only\n",
    "\n",
    "Y_train = y_scaler.transform(Y_train_raw)\n",
    "Y_val   = y_scaler.transform(Y_val_raw)\n",
    "Y_test  = y_scaler.transform(Y_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba18b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameSequenceDataset(Dataset):\n",
    "    def __init__(self, x_home, x_away, y, home_idx, away_idx):\n",
    "        self.x_home = torch.tensor(x_home, dtype=torch.float32)\n",
    "        self.x_away = torch.tensor(x_away, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        self.home_idx = torch.tensor(home_idx, dtype=torch.long)\n",
    "        self.away_idx = torch.tensor(away_idx, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_home[idx],\n",
    "            self.x_away[idx],\n",
    "            self.y[idx],\n",
    "            self.home_idx[idx],\n",
    "            self.away_idx[idx],\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = GameSequenceDataset(\n",
    "    X_home_train, X_away_train, Y_train, home_idx_train, away_idx_train\n",
    ")\n",
    "val_dataset = GameSequenceDataset(\n",
    "    X_home_val, X_away_val, Y_val, home_idx_val, away_idx_val\n",
    ")\n",
    "test_dataset = GameSequenceDataset(\n",
    "    X_home_test, X_away_test, Y_test, home_idx_test, away_idx_test\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cf0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamSequenceEncoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int = 1, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # output: [B, T, 2H]\n",
    "        return output\n",
    "    \n",
    "class ScorePredictorMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Model A — LSTM Encoder + Mean Pooling + Team Embeddings + MLP.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        num_teams: int = None,\n",
    "        team_emb_dim: int = 16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = hidden_size * 2  # BiLSTM output size\n",
    "        self.team_emb_dim = team_emb_dim\n",
    "\n",
    "        # Shared sequence encoder\n",
    "        self.encoder = TeamSequenceEncoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "        # NEW: team embedding table\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        pair_input_dim = self.embed_dim * 2 + team_emb_dim * 2  # home/away seq + home/away team emb\n",
    "\n",
    "        # MLP prediction head (margin, total)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 2),   # [margin, total]\n",
    "        )\n",
    "\n",
    "    def forward(self, x_home, x_away, home_team_idx, away_team_idx):\n",
    "        \"\"\"\n",
    "        x_home, x_away: [B, T, F]\n",
    "        home_team_idx, away_team_idx: [B] (LongTensor)\n",
    "        \"\"\"\n",
    "        # Encode sequences\n",
    "        h_home_seq = self.encoder(x_home)  # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)  # [B, T, 2H]\n",
    "\n",
    "        # Temporal mean pooling\n",
    "        home_vec = h_home_seq.mean(dim=1)  # [B, 2H]\n",
    "        away_vec = h_away_seq.mean(dim=1)  # [B, 2H]\n",
    "\n",
    "        # Team identity embeddings\n",
    "        home_emb = self.team_embedding(home_team_idx)  # [B, D]\n",
    "        away_emb = self.team_embedding(away_team_idx)  # [B, D]\n",
    "\n",
    "        # Concatenate all\n",
    "        pair_vec = torch.cat([home_vec, away_vec, home_emb, away_emb], dim=-1)\n",
    "        y_pred = self.mlp(pair_vec)  # [B, 2]\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "\n",
    "class ScorePredictorCrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        num_heads: int = 4,\n",
    "        num_teams: int = None,\n",
    "        team_emb_dim: int = 16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = hidden_size * 2  # BiLSTM\n",
    "        self.team_emb_dim = team_emb_dim\n",
    "\n",
    "        self.encoder = TeamSequenceEncoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        pair_input_dim = self.embed_dim * 2 + team_emb_dim * 2\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 2),  # [margin, total]\n",
    "        )\n",
    "\n",
    "    def forward(self, x_home, x_away, home_team_idx, away_team_idx):\n",
    "        # Encode sequences\n",
    "        h_home_seq = self.encoder(x_home)   # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)   # [B, T, 2H]\n",
    "\n",
    "        # Home attends to away\n",
    "        home_ctx, _ = self.cross_attn(\n",
    "            query=h_home_seq,\n",
    "            key=h_away_seq,\n",
    "            value=h_away_seq,\n",
    "        )\n",
    "\n",
    "        # Away attends to home\n",
    "        away_ctx, _ = self.cross_attn(\n",
    "            query=h_away_seq,\n",
    "            key=h_home_seq,\n",
    "            value=h_home_seq,\n",
    "        )\n",
    "\n",
    "        # Pool over time\n",
    "        home_vec = home_ctx.mean(dim=1)   # [B, 2H]\n",
    "        away_vec = away_ctx.mean(dim=1)   # [B, 2H]\n",
    "\n",
    "        # Team embeddings\n",
    "        home_emb = self.team_embedding(home_team_idx)  # [B, D]\n",
    "        away_emb = self.team_embedding(away_team_idx)  # [B, D]\n",
    "\n",
    "        pair_vec = torch.cat([home_vec, away_vec, home_emb, away_emb], dim=-1)\n",
    "        y_pred = self.mlp(pair_vec)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab37699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScorePredictorMLP(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(37, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(53, 16)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "ScorePredictorCrossAttention(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(37, 64, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (cross_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(53, 16)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = len(SEQ_FEATURES)\n",
    "\n",
    "model_a = ScorePredictorMLP(\n",
    "    input_size=input_size,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_teams=num_teams,\n",
    "    team_emb_dim=16,\n",
    ").to(device)\n",
    "\n",
    "model_b = ScorePredictorCrossAttention(\n",
    "    input_size=input_size,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=4,\n",
    "    num_teams=num_teams,\n",
    "    team_emb_dim=16,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(model_a)\n",
    "print(model_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e7c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train: bool = True, model=None):\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"model not set\")\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for x_home, x_away, y, home_idx, away_idx in loader:\n",
    "        x_home = x_home.to(device)\n",
    "        x_away = x_away.to(device)\n",
    "        y = y.to(device)  # scaled targets\n",
    "        home_idx = home_idx.to(device)\n",
    "        away_idx = away_idx.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            y_pred = model(x_home, x_away, home_idx, away_idx)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        all_true.append(y.detach().cpu().numpy())\n",
    "        all_pred.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)  # scaled\n",
    "    all_pred = np.concatenate(all_pred, axis=0)  # scaled\n",
    "\n",
    "    # --- NEW: convert back to real [margin, total] for metrics ---\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    mae = mean_absolute_error(all_true_unscaled, all_pred_unscaled)\n",
    "    rmse = math.sqrt(mean_squared_error(all_true_unscaled, all_pred_unscaled))\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9bfbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.390, MAE 13.687, RMSE 17.712 | Val Loss 0.416, MAE 13.976, RMSE 17.772\n",
      "Epoch 02 | Train Loss 0.355, MAE 12.792, RMSE 16.492 | Val Loss 0.395, MAE 13.510, RMSE 17.296\n",
      "Epoch 03 | Train Loss 0.338, MAE 12.404, RMSE 16.107 | Val Loss 0.388, MAE 13.321, RMSE 17.087\n",
      "Epoch 04 | Train Loss 0.333, MAE 12.307, RMSE 15.952 | Val Loss 0.385, MAE 13.280, RMSE 17.026\n",
      "Epoch 05 | Train Loss 0.332, MAE 12.281, RMSE 15.914 | Val Loss 0.384, MAE 13.256, RMSE 16.985\n",
      "Epoch 06 | Train Loss 0.330, MAE 12.229, RMSE 15.861 | Val Loss 0.383, MAE 13.212, RMSE 16.930\n",
      "Epoch 07 | Train Loss 0.328, MAE 12.195, RMSE 15.804 | Val Loss 0.382, MAE 13.190, RMSE 16.887\n",
      "Epoch 08 | Train Loss 0.328, MAE 12.172, RMSE 15.778 | Val Loss 0.383, MAE 13.206, RMSE 16.921\n",
      "Epoch 09 | Train Loss 0.325, MAE 12.117, RMSE 15.711 | Val Loss 0.384, MAE 13.238, RMSE 16.963\n",
      "Epoch 10 | Train Loss 0.325, MAE 12.107, RMSE 15.686 | Val Loss 0.387, MAE 13.350, RMSE 17.092\n",
      "Epoch 11 | Train Loss 0.323, MAE 12.056, RMSE 15.633 | Val Loss 0.386, MAE 13.310, RMSE 17.033\n",
      "Epoch 12 | Train Loss 0.323, MAE 12.062, RMSE 15.628 | Val Loss 0.383, MAE 13.214, RMSE 16.912\n",
      "Epoch 13 | Train Loss 0.322, MAE 12.046, RMSE 15.595 | Val Loss 0.383, MAE 13.226, RMSE 16.932\n",
      "Epoch 14 | Train Loss 0.322, MAE 12.035, RMSE 15.594 | Val Loss 0.384, MAE 13.250, RMSE 16.958\n",
      "Epoch 15 | Train Loss 0.322, MAE 12.031, RMSE 15.574 | Val Loss 0.384, MAE 13.242, RMSE 16.948\n",
      "Epoch 16 | Train Loss 0.321, MAE 12.023, RMSE 15.574 | Val Loss 0.383, MAE 13.234, RMSE 16.935\n",
      "Epoch 17 | Train Loss 0.321, MAE 12.012, RMSE 15.568 | Val Loss 0.384, MAE 13.261, RMSE 16.971\n",
      "Epoch 18 | Train Loss 0.321, MAE 12.001, RMSE 15.556 | Val Loss 0.384, MAE 13.245, RMSE 16.950\n",
      "Epoch 19 | Train Loss 0.321, MAE 12.014, RMSE 15.561 | Val Loss 0.385, MAE 13.268, RMSE 16.980\n",
      "Epoch 20 | Train Loss 0.321, MAE 11.996, RMSE 15.549 | Val Loss 0.384, MAE 13.245, RMSE 16.950\n",
      "Epoch 21 | Train Loss 0.321, MAE 12.004, RMSE 15.549 | Val Loss 0.384, MAE 13.256, RMSE 16.964\n",
      "Epoch 22 | Train Loss 0.321, MAE 11.999, RMSE 15.546 | Val Loss 0.384, MAE 13.256, RMSE 16.964\n",
      "Epoch 23 | Train Loss 0.320, MAE 11.983, RMSE 15.528 | Val Loss 0.384, MAE 13.253, RMSE 16.960\n",
      "Epoch 24 | Train Loss 0.321, MAE 12.001, RMSE 15.543 | Val Loss 0.384, MAE 13.250, RMSE 16.957\n",
      "Epoch 25 | Train Loss 0.320, MAE 11.986, RMSE 15.540 | Val Loss 0.384, MAE 13.252, RMSE 16.959\n",
      "Epoch 26 | Train Loss 0.320, MAE 11.991, RMSE 15.531 | Val Loss 0.384, MAE 13.253, RMSE 16.961\n",
      "Epoch 27 | Train Loss 0.320, MAE 11.989, RMSE 15.537 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 28 | Train Loss 0.320, MAE 11.981, RMSE 15.538 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 29 | Train Loss 0.321, MAE 12.004, RMSE 15.563 | Val Loss 0.384, MAE 13.255, RMSE 16.963\n",
      "Epoch 30 | Train Loss 0.320, MAE 11.992, RMSE 15.546 | Val Loss 0.384, MAE 13.255, RMSE 16.963\n",
      "Epoch 31 | Train Loss 0.320, MAE 12.000, RMSE 15.535 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 32 | Train Loss 0.320, MAE 11.983, RMSE 15.537 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 33 | Train Loss 0.320, MAE 11.993, RMSE 15.532 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 34 | Train Loss 0.320, MAE 11.996, RMSE 15.536 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 35 | Train Loss 0.320, MAE 12.001, RMSE 15.551 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 36 | Train Loss 0.320, MAE 11.997, RMSE 15.527 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 37 | Train Loss 0.320, MAE 11.997, RMSE 15.536 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 38 | Train Loss 0.320, MAE 11.998, RMSE 15.546 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 39 | Train Loss 0.320, MAE 11.982, RMSE 15.536 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n",
      "Epoch 40 | Train Loss 0.320, MAE 11.990, RMSE 15.531 | Val Loss 0.384, MAE 13.254, RMSE 16.962\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_a.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',      # lower RMSE is better\n",
    "    factor=0.5,      # reduce LR by half\n",
    "    patience=2,      # wait 2 epochs before dropping LR\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_a\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_a\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 🔥 IMPORTANT → Notify the scheduler\n",
    "    scheduler.step(val_rmse)  # or val_loss if you prefer loss\n",
    "\n",
    "    # 🔥 Standard early stopping capture\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_a.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c19adcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.353, MAE 12.668, RMSE 16.422\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_a)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385a6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.382, MAE 13.493, RMSE 17.481 | Val Loss 0.406, MAE 13.734, RMSE 17.549\n",
      "Epoch 02 | Train Loss 0.355, MAE 12.786, RMSE 16.517 | Val Loss 0.402, MAE 13.643, RMSE 17.441\n",
      "Epoch 03 | Train Loss 0.350, MAE 12.695, RMSE 16.424 | Val Loss 0.401, MAE 13.646, RMSE 17.439\n",
      "Epoch 04 | Train Loss 0.338, MAE 12.430, RMSE 16.113 | Val Loss 0.385, MAE 13.279, RMSE 17.010\n",
      "Epoch 05 | Train Loss 0.331, MAE 12.265, RMSE 15.915 | Val Loss 0.384, MAE 13.237, RMSE 16.937\n",
      "Epoch 06 | Train Loss 0.329, MAE 12.218, RMSE 15.822 | Val Loss 0.382, MAE 13.195, RMSE 16.871\n",
      "Epoch 07 | Train Loss 0.328, MAE 12.180, RMSE 15.764 | Val Loss 0.382, MAE 13.191, RMSE 16.871\n",
      "Epoch 08 | Train Loss 0.327, MAE 12.168, RMSE 15.744 | Val Loss 0.384, MAE 13.245, RMSE 16.947\n",
      "Epoch 09 | Train Loss 0.326, MAE 12.144, RMSE 15.708 | Val Loss 0.381, MAE 13.173, RMSE 16.842\n",
      "Epoch 10 | Train Loss 0.326, MAE 12.130, RMSE 15.706 | Val Loss 0.381, MAE 13.169, RMSE 16.853\n",
      "Epoch 11 | Train Loss 0.324, MAE 12.088, RMSE 15.638 | Val Loss 0.382, MAE 13.203, RMSE 16.888\n",
      "Epoch 12 | Train Loss 0.324, MAE 12.070, RMSE 15.637 | Val Loss 0.381, MAE 13.189, RMSE 16.861\n",
      "Epoch 13 | Train Loss 0.322, MAE 12.040, RMSE 15.582 | Val Loss 0.383, MAE 13.235, RMSE 16.937\n",
      "Epoch 14 | Train Loss 0.321, MAE 12.009, RMSE 15.551 | Val Loss 0.382, MAE 13.209, RMSE 16.894\n",
      "Epoch 15 | Train Loss 0.321, MAE 12.020, RMSE 15.568 | Val Loss 0.382, MAE 13.195, RMSE 16.877\n",
      "Epoch 16 | Train Loss 0.320, MAE 11.974, RMSE 15.542 | Val Loss 0.382, MAE 13.202, RMSE 16.886\n",
      "Epoch 17 | Train Loss 0.320, MAE 11.983, RMSE 15.527 | Val Loss 0.382, MAE 13.199, RMSE 16.878\n",
      "Epoch 18 | Train Loss 0.319, MAE 11.975, RMSE 15.523 | Val Loss 0.382, MAE 13.202, RMSE 16.883\n",
      "Epoch 19 | Train Loss 0.319, MAE 11.979, RMSE 15.526 | Val Loss 0.382, MAE 13.210, RMSE 16.895\n",
      "Epoch 20 | Train Loss 0.319, MAE 11.975, RMSE 15.516 | Val Loss 0.382, MAE 13.192, RMSE 16.870\n",
      "Epoch 21 | Train Loss 0.319, MAE 11.974, RMSE 15.518 | Val Loss 0.382, MAE 13.204, RMSE 16.886\n",
      "Epoch 22 | Train Loss 0.319, MAE 11.964, RMSE 15.503 | Val Loss 0.382, MAE 13.204, RMSE 16.883\n",
      "Epoch 23 | Train Loss 0.319, MAE 11.962, RMSE 15.500 | Val Loss 0.382, MAE 13.214, RMSE 16.898\n",
      "Epoch 24 | Train Loss 0.319, MAE 11.967, RMSE 15.506 | Val Loss 0.382, MAE 13.211, RMSE 16.893\n",
      "Epoch 25 | Train Loss 0.319, MAE 11.974, RMSE 15.505 | Val Loss 0.382, MAE 13.214, RMSE 16.897\n",
      "Epoch 26 | Train Loss 0.318, MAE 11.937, RMSE 15.471 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 27 | Train Loss 0.319, MAE 11.959, RMSE 15.512 | Val Loss 0.382, MAE 13.210, RMSE 16.892\n",
      "Epoch 28 | Train Loss 0.319, MAE 11.967, RMSE 15.510 | Val Loss 0.382, MAE 13.211, RMSE 16.894\n",
      "Epoch 29 | Train Loss 0.318, MAE 11.944, RMSE 15.496 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 30 | Train Loss 0.318, MAE 11.938, RMSE 15.485 | Val Loss 0.382, MAE 13.212, RMSE 16.896\n",
      "Epoch 31 | Train Loss 0.319, MAE 11.953, RMSE 15.497 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 32 | Train Loss 0.319, MAE 11.955, RMSE 15.498 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 33 | Train Loss 0.319, MAE 11.962, RMSE 15.505 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 34 | Train Loss 0.319, MAE 11.962, RMSE 15.501 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 35 | Train Loss 0.318, MAE 11.945, RMSE 15.497 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 36 | Train Loss 0.318, MAE 11.952, RMSE 15.493 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 37 | Train Loss 0.318, MAE 11.949, RMSE 15.489 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 38 | Train Loss 0.319, MAE 11.955, RMSE 15.501 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 39 | Train Loss 0.318, MAE 11.959, RMSE 15.497 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n",
      "Epoch 40 | Train Loss 0.319, MAE 11.959, RMSE 15.507 | Val Loss 0.382, MAE 13.212, RMSE 16.895\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL B\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_b.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',      # lower RMSE is better\n",
    "    factor=0.5,      # reduce LR by half\n",
    "    patience=2,      # wait 2 epochs before dropping LR\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_b\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_b\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 🔥 IMPORTANT → Notify the scheduler\n",
    "    scheduler.step(val_rmse)  # or val_loss if you prefer loss\n",
    "\n",
    "    # 🔥 Standard early stopping capture\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_b.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b74ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.351, MAE 12.663, RMSE 16.391\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_b)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad7da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant baseline | MAE 16.971, RMSE 22.351\n"
     ]
    }
   ],
   "source": [
    "# Using your train split\n",
    "\n",
    "\n",
    "def evaluate_constant_baseline(Y_true, const_pred):\n",
    "    const = np.tile(const_pred, (Y_true.shape[0], 1))\n",
    "    mae = mean_absolute_error(Y_true, const)\n",
    "    rmse = math.sqrt(mean_squared_error(Y_true, const))\n",
    "    return mae, rmse\n",
    "\n",
    "baseline_mae, baseline_rmse = evaluate_constant_baseline(Y_test_raw, train_mean_scores)\n",
    "print(f\"Constant baseline | MAE {baseline_mae:.3f}, RMSE {baseline_rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea930d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A winner accuracy: 61.594%\n",
      "Model B winner accuracy: 61.522%\n",
      "Model A margin accuracy (within 5 points): 30.145%\n",
      "Model B margin accuracy (within 5 points): 28.986%\n",
      "Model A totals accuracy (within 5 points): 23.043%\n",
      "Model B totals accuracy (within 5 points): 22.246%\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, loader):\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x_home, x_away, y, home_idx, away_idx in loader:\n",
    "            x_home = x_home.to(device)\n",
    "            x_away = x_away.to(device)\n",
    "            y = y.to(device)  # scaled\n",
    "            home_idx = home_idx.to(device)\n",
    "            away_idx = away_idx.to(device)\n",
    "\n",
    "            y_pred = model(x_home, x_away, home_idx, away_idx)\n",
    "            all_true.append(y.cpu().numpy())\n",
    "            all_pred.append(y_pred.cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)  # scaled\n",
    "    all_pred = np.concatenate(all_pred, axis=0)  # scaled\n",
    "\n",
    "    # --- NEW: unscale before returning ---\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    return all_true_unscaled, all_pred_unscaled\n",
    "\n",
    "\n",
    "Y_true_test, Y_pred_a = get_predictions(model_a, test_loader)\n",
    "_, Y_pred_b = get_predictions(model_b, test_loader)\n",
    "\n",
    "# True margin/total\n",
    "true_margin = Y_true_test[:, 0]\n",
    "true_total  = Y_true_test[:, 1]\n",
    "\n",
    "# Reconstruct true scores\n",
    "true_home = (true_total + true_margin) / 2\n",
    "true_away = (true_total - true_margin) / 2\n",
    "\n",
    "# Model A margin/total\n",
    "pred_margin_a = Y_pred_a[:, 0]\n",
    "pred_total_a  = Y_pred_a[:, 1]\n",
    "pred_home_a   = (pred_total_a + pred_margin_a) / 2\n",
    "pred_away_a   = (pred_total_a - pred_margin_a) / 2\n",
    "\n",
    "# Model B margin/total\n",
    "pred_margin_b = Y_pred_b[:, 0]\n",
    "pred_total_b  = Y_pred_b[:, 1]\n",
    "pred_home_b   = (pred_total_b + pred_margin_b) / 2\n",
    "pred_away_b   = (pred_total_b - pred_margin_b) / 2\n",
    "\n",
    "\n",
    "def winner_accuracy(y_true, y_pred):\n",
    "    true_margin = y_true[:, 0]\n",
    "    pred_margin = y_pred[:, 0]\n",
    "    return ((true_margin > 0) == (pred_margin > 0)).mean()\n",
    "\n",
    "def margin_accuracy(y_true, y_pred):\n",
    "    true_margin = y_true[:, 0]\n",
    "    pred_margin = y_pred[:, 0]\n",
    "    return (np.abs(true_margin - pred_margin) < 5).mean()\n",
    "\n",
    "def totals_accuracy(y_true, y_pred):\n",
    "    true_total = y_true[:, 1]\n",
    "    pred_total = y_pred[:, 1]\n",
    "    return (np.abs(true_total - pred_total) < 5).mean()\n",
    "\n",
    "\n",
    "acc_a = winner_accuracy(Y_true_test, Y_pred_a)\n",
    "acc_b = winner_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A winner accuracy: {acc_a:.3%}\")\n",
    "print(f\"Model B winner accuracy: {acc_b:.3%}\")\n",
    "\n",
    "margin_a = margin_accuracy(Y_true_test, Y_pred_a)\n",
    "margin_b = margin_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A margin accuracy (within 5 points): {margin_a:.3%}\")\n",
    "print(f\"Model B margin accuracy (within 5 points): {margin_b:.3%}\")\n",
    "\n",
    "total_a = totals_accuracy(Y_true_test, Y_pred_a)\n",
    "total_b = totals_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A totals accuracy (within 5 points): {total_a:.3%}\")\n",
    "print(f\"Model B totals accuracy (within 5 points): {total_b:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f77994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_betting = pd.read_csv(f'{DATA_DIR}/nba_2008-2025.csv')\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "df_betting = df_betting[df_betting['game_date'] >= ERA_START].reset_index(drop=True)\n",
    "\n",
    "team_df = pd.read_csv(os.path.join(DATA_DIR, 'team.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3992c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_map = dict(zip(team_df['id'], team_df['nickname']))\n",
    "\n",
    "test_indices = np.where(test_mask)[0]\n",
    "test_game_indices = []\n",
    "\n",
    "# Rebuild to track which games_full indices match test_mask\n",
    "idx = 0\n",
    "for i, row in games_full.iterrows():\n",
    "    gid = row[GAME_ID_COL]\n",
    "    home_id = row[\"home_team_id\"]\n",
    "    away_id = row[\"away_team_id\"]\n",
    "    date = row[GAME_DATE_COL]\n",
    "\n",
    "    key_home = (gid, home_id)\n",
    "    key_away = (gid, away_id)\n",
    "\n",
    "    if key_home not in seq_index_by_game_team or key_away not in seq_index_by_game_team:\n",
    "        continue\n",
    "    \n",
    "    # This game is in our dataset\n",
    "    if pd.to_datetime(date) >= TEST_SPLIT_DATE:\n",
    "        test_game_indices.append(i)\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "# Build test_predictions_df with correct games_full rows\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    'game_date': games_full.iloc[test_game_indices][GAME_DATE_COL].values,\n",
    "    'home_team': [team_map.get(games_full.iloc[i]['home_team_id'], 'UNK') \n",
    "                  for i in test_game_indices],\n",
    "    'away_team': [team_map.get(games_full.iloc[i]['away_team_id'], 'UNK') \n",
    "                  for i in test_game_indices],\n",
    "    'y_home': true_home,\n",
    "    'y_away': true_away,\n",
    "    'pred_home_a': pred_home_a,\n",
    "    'pred_away_a': pred_away_a,\n",
    "    'pred_home_b': pred_home_b,\n",
    "    'pred_away_b': pred_away_b,\n",
    "}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e60b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       game_date whos_favored  spread      home_team away_team\n",
      "0     2010-10-26         away    -1.0        Celtics      Heat\n",
      "1     2010-10-26         home     7.0  Trail Blazers      Suns\n",
      "2     2010-10-26         home     6.5         Lakers   Rockets\n",
      "3     2010-10-27         home     4.0           Nets   Pistons\n",
      "4     2010-10-27         away    -4.5      Cavaliers   Celtics\n",
      "...          ...          ...     ...            ...       ...\n",
      "19170 2025-06-11         away    -4.5         Pacers   Thunder\n",
      "19171 2025-06-13         away    -6.5         Pacers   Thunder\n",
      "19172 2025-06-16         home     8.5        Thunder    Pacers\n",
      "19173 2025-06-19         away    -5.5         Pacers   Thunder\n",
      "19174 2025-06-22         home     6.5        Thunder    Pacers\n",
      "\n",
      "[19175 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'atl': 'Hawks',\n",
    "    'bos': 'Celtics',\n",
    "    'bkn': 'Nets',\n",
    "    'cha': 'Hornets',\n",
    "    'chi': 'Bulls',\n",
    "    'cle': 'Cavaliers',\n",
    "    'dal': 'Mavericks',\n",
    "    'den': 'Nuggets',\n",
    "    'det': 'Pistons',\n",
    "    'gs': 'Warriors',\n",
    "    'hou': 'Rockets',\n",
    "    'ind': 'Pacers',\n",
    "    'lac': 'Clippers',\n",
    "    'lal': 'Lakers',\n",
    "    'mem': 'Grizzlies',\n",
    "    'mia': 'Heat',\n",
    "    'mil': 'Bucks',\n",
    "    'min': 'Timberwolves',\n",
    "    'no': 'Pelicans',\n",
    "    'ny': 'Knicks',\n",
    "    'okc': 'Thunder',\n",
    "    'orl': 'Magic',\n",
    "    'phi': '76ers',\n",
    "    'phx': 'Suns',\n",
    "    'por': 'Trail Blazers',\n",
    "    'sac': 'Kings',\n",
    "    'sa': 'Spurs',\n",
    "    'tor': 'Raptors',\n",
    "    'utah': 'Jazz',\n",
    "    'wsh': 'Wizards'\n",
    "}\n",
    "\n",
    "df_betting['away_team'] = df_betting['away'].map(abbreviation_mapping)\n",
    "df_betting['home_team'] = df_betting['home'].map(abbreviation_mapping)\n",
    "# Rename date to game_date to match test_predictions_df\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "# Convert the spread to negative if the away team is favored\n",
    "df_betting['spread'] = df_betting.apply(\n",
    "    lambda row: -row['spread'] if 'away' == row['whos_favored'] else row['spread'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Print modified columns for verification\n",
    "print(df_betting[['game_date', 'whos_favored', 'spread', 'home_team', 'away_team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9009931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged betting data shape: (1314, 36)\n"
     ]
    }
   ],
   "source": [
    "# Merge betting data with test predictions on date, home_team, away_team\n",
    "merged_df = pd.merge(\n",
    "    test_predictions_df,\n",
    "    df_betting,\n",
    "    on=['game_date', 'home_team', 'away_team'],\n",
    "    how='inner'\n",
    ")\n",
    "print(\"Merged betting data shape:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cf1dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Spread Record (W-L-P): {'W': 648, 'L': 653, 'P': 13}\n",
      "Model A Total Record (W-L-P): {'W': 697, 'L': 608, 'P': 9}\n",
      "Model B Spread Record (W-L-P): {'W': 664, 'L': 637, 'P': 13}\n",
      "Model B Total Record (W-L-P): {'W': 677, 'L': 628, 'P': 9}\n"
     ]
    }
   ],
   "source": [
    "def predict_betting_results(df):\n",
    "    \"\"\"\n",
    "    The spread will always be from the home team's perspective, if it is negative the away team is favored.\n",
    "    The total is the combined score of both teams.\n",
    "\n",
    "    Returns:\n",
    "        spread_record_a: wins-losses-pushes for model A spread bets\n",
    "        total_record_a: wins-losses-pushes for model A total bets\n",
    "        spread_record_b: wins-losses-pushes for model B spread bets\n",
    "        total_record_b: wins-losses-pushes for model B total bets\n",
    "    \"\"\"\n",
    "    for game in df:\n",
    "        # Model A predictions\n",
    "        pred_home_a = game['pred_home_a']\n",
    "        pred_away_a = game['pred_away_a']\n",
    "        pred_margin_a = pred_home_a - pred_away_a\n",
    "        pred_total_a = pred_home_a + pred_away_a\n",
    "\n",
    "        # Model B predictions\n",
    "        pred_home_b = game['pred_home_b']\n",
    "        pred_away_b = game['pred_away_b']\n",
    "        pred_margin_b = pred_home_b - pred_away_b\n",
    "        pred_total_b = pred_home_b + pred_away_b\n",
    "\n",
    "        # Actual results\n",
    "        actual_home = game['y_home']\n",
    "        actual_away = game['y_away']\n",
    "        actual_margin = actual_home - actual_away\n",
    "        actual_total = actual_home + actual_away\n",
    "\n",
    "        spread = game['spread']\n",
    "        total_line = game['total']\n",
    "\n",
    "        # Spread bet results for Model A\n",
    "        if (spread) > 0: # Home team Favoured\n",
    "            if (actual_margin - spread) > 0: # If home team covers\n",
    "                if (pred_margin_a - spread) > 0: # Predicted home team covers\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            elif (actual_margin - spread) < 0: # If home team fails to cover\n",
    "                if (pred_margin_a - spread) < 0: # Predicted home team fails to cover\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_a'] = 'P'\n",
    "        elif (spread) < 0: # Away team Favoured\n",
    "            if (actual_margin - spread) < 0: # If away team covers\n",
    "                if (pred_margin_a - spread) < 0: # Predicted away team covers\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            elif (actual_margin - spread) > 0: # If away team fails to cover\n",
    "                if (pred_margin_a - spread) > 0: # Predicted away team fails to cover\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_a'] = 'P'\n",
    "        else: # Spread is 0, no favorite\n",
    "            if (actual_margin and pred_margin_a) > 0: # Home team wins, predicted home team wins\n",
    "                game['spread_result_a'] = 'W'\n",
    "            elif (actual_margin and pred_margin_a) < 0: # Away team wins, predicted away team wins\n",
    "                game['spread_result_a'] = 'W'\n",
    "            else: # One team wins, predicted the other team wins\n",
    "                game['spread_result_a'] = 'L'\n",
    "\n",
    "\n",
    "         # Spread bet results for Model B\n",
    "        if (spread) > 0: # Home team Favoured\n",
    "            if (actual_margin - spread) > 0: # If home team covers\n",
    "                if (pred_margin_b - spread) > 0: # Predicted home team covers\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            elif (actual_margin - spread) < 0: # If home team fails to cover\n",
    "                if (pred_margin_b - spread) < 0: # Predicted home team fails to cover\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_b'] = 'P'\n",
    "        elif (spread) < 0: # Away team Favoured\n",
    "            if (actual_margin - spread) < 0: # If away team covers\n",
    "                if (pred_margin_b - spread) < 0: # Predicted away team covers\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            elif (actual_margin - spread) > 0: # If away team fails to cover\n",
    "                if (pred_margin_b - spread) > 0: # Predicted away team fails to cover\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_b'] = 'P'\n",
    "        else: # Spread is 0, no favorite\n",
    "            if (actual_margin and pred_margin_b) > 0: # Home team wins, predicted home team wins\n",
    "                game['spread_result_b'] = 'W'\n",
    "            elif (actual_margin and pred_margin_b) < 0: # Away team wins, predicted away team wins\n",
    "                game['spread_result_b'] = 'W'\n",
    "            else: # One team wins, predicted the other team wins\n",
    "                game['spread_result_b'] = 'L'\n",
    "\n",
    "        # Total bet results for Model A\n",
    "        if (actual_total > total_line): # Over pays\n",
    "            if (pred_total_a > total_line):\n",
    "                game['total_result_a'] = 'W'\n",
    "            else:\n",
    "                game['total_result_a'] = 'L'\n",
    "        elif (actual_total < total_line): # Under Pays\n",
    "            if (pred_total_a < total_line):\n",
    "                game['total_result_a'] = 'W'\n",
    "            else:\n",
    "                game['total_result_a'] = 'L'\n",
    "        else: # Push = Exactly on the total line, bet refunded\n",
    "            game['total_result_a'] = 'P'\n",
    "\n",
    "        # Total bet results for Model B\n",
    "        if (actual_total > total_line): # Over pays\n",
    "            if (pred_total_b > total_line):\n",
    "                game['total_result_b'] = 'W'\n",
    "            else:\n",
    "                game['total_result_b'] = 'L'\n",
    "        elif (actual_total < total_line): # Under Pays\n",
    "            if (pred_total_b < total_line):\n",
    "                game['total_result_b'] = 'W'\n",
    "            else:\n",
    "                game['total_result_b'] = 'L'\n",
    "        else: # Push = Exactly on the total line, bet refunded\n",
    "            game['total_result_b'] = 'P'\n",
    "            \n",
    "    # Calculate records\n",
    "    spread_record_a = {'W': 0, 'L': 0, 'P': 0}\n",
    "    total_record_a = {'W': 0, 'L': 0, 'P': 0}\n",
    "    spread_record_b = {'W': 0, 'L': 0, 'P': 0}\n",
    "    total_record_b = {'W': 0, 'L': 0, 'P': 0}\n",
    "    for game in df:\n",
    "        spread_record_a[game['spread_result_a']] += 1\n",
    "        total_record_a[game['total_result_a']] += 1\n",
    "        spread_record_b[game['spread_result_b']] += 1\n",
    "        total_record_b[game['total_result_b']] += 1\n",
    "    return spread_record_a, total_record_a, spread_record_b, total_record_b\n",
    "\n",
    "spread_record_a, total_record_a, spread_record_b, total_record_b = predict_betting_results(merged_df.to_dict('records'))\n",
    "print(\"Model A Spread Record (W-L-P):\", spread_record_a)\n",
    "print(\"Model A Total Record (W-L-P):\", total_record_a)\n",
    "print(\"Model B Spread Record (W-L-P):\", spread_record_b)\n",
    "print(\"Model B Total Record (W-L-P):\", total_record_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fde74b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model Bet Type  Wins  Losses  Pushes  Win Ratio\n",
      "0     A   Spread   648     653      13   0.498078\n",
      "1     A    Total   697     608       9   0.534100\n",
      "2     B   Spread   664     637      13   0.510377\n",
      "3     B    Total   677     628       9   0.518774\n"
     ]
    }
   ],
   "source": [
    "# create a summary betting DF\n",
    "betting_summary = pd.DataFrame({\n",
    "    'Model': ['A', 'A', 'B', 'B'],\n",
    "    'Bet Type': ['Spread', 'Total', 'Spread', 'Total'],\n",
    "    'Wins': [spread_record_a['W'], total_record_a['W'], spread_record_b['W'], total_record_b['W']],\n",
    "    'Losses': [spread_record_a['L'], total_record_a['L'], spread_record_b['L'], total_record_b['L']],\n",
    "    'Pushes': [spread_record_a['P'], total_record_a['P'], spread_record_b['P'], total_record_b['P']],\n",
    "    'Win Ratio': [\n",
    "        spread_record_a['W'] / (spread_record_a['W'] + spread_record_a['L']),\n",
    "        total_record_a['W'] / (total_record_a['W'] + total_record_a['L']),\n",
    "        spread_record_b['W'] / (spread_record_b['W'] + spread_record_b['L']),\n",
    "        total_record_b['W'] / (total_record_b['W'] + total_record_b ['L']),\n",
    "    ]\n",
    "})\n",
    "print(betting_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaf0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe1fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
