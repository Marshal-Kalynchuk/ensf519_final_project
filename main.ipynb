{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267c7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & config\n",
    "\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead36b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"./data/csv\"\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LEN = 15              # number of past games per team\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "ERA_START = pd.to_datetime(\"2010-10-01\")\n",
    "VAL_SPLIT_DATE = \"2021-10-01\"\n",
    "TEST_SPLIT_DATE = \"2022-10-01\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56555458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== common_player_info.csv ===\n",
      "shape: (4171, 33)\n",
      "columns: ['person_id', 'first_name', 'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last', 'player_slug', 'birthdate', 'school', 'country', 'last_affiliation', 'height', 'weight', 'season_exp', 'jersey'] ...\n",
      "\n",
      "=== game_info.csv ===\n",
      "shape: (58053, 4)\n",
      "columns: ['game_id', 'game_date', 'attendance', 'game_time'] ...\n",
      "\n",
      "=== officials.csv ===\n",
      "shape: (70971, 5)\n",
      "columns: ['game_id', 'official_id', 'first_name', 'last_name', 'jersey_num'] ...\n",
      "\n",
      "=== team.csv ===\n",
      "shape: (30, 7)\n",
      "columns: ['id', 'full_name', 'abbreviation', 'nickname', 'city', 'state', 'year_founded'] ...\n",
      "\n",
      "=== draft_combine_stats.csv ===\n",
      "shape: (1202, 47)\n",
      "columns: ['season', 'player_id', 'first_name', 'last_name', 'player_name', 'position', 'height_wo_shoes', 'height_wo_shoes_ft_in', 'height_w_shoes', 'height_w_shoes_ft_in', 'weight', 'wingspan', 'wingspan_ft_in', 'standing_reach', 'standing_reach_ft_in'] ...\n",
      "\n",
      "=== game_summary.csv ===\n",
      "shape: (58110, 14)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'game_status_id', 'game_status_text', 'gamecode', 'home_team_id', 'visitor_team_id', 'season', 'live_period', 'live_pc_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast', 'wh_status'] ...\n",
      "\n",
      "=== other_stats.csv ===\n",
      "shape: (28271, 26)\n",
      "columns: ['game_id', 'league_id', 'team_id_home', 'team_abbreviation_home', 'team_city_home', 'pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home'] ...\n",
      "\n",
      "=== team_details.csv ===\n",
      "shape: (25, 14)\n",
      "columns: ['team_id', 'abbreviation', 'nickname', 'yearfounded', 'city', 'arena', 'arenacapacity', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'facebook', 'instagram', 'twitter'] ...\n",
      "\n",
      "=== draft_history.csv ===\n",
      "shape: (7990, 14)\n",
      "columns: ['person_id', 'player_name', 'season', 'round_number', 'round_pick', 'overall_pick', 'draft_type', 'team_id', 'team_city', 'team_name', 'team_abbreviation', 'organization', 'organization_type', 'player_profile_flag'] ...\n",
      "\n",
      "=== inactive_players.csv ===\n",
      "shape: (110191, 9)\n",
      "columns: ['game_id', 'player_id', 'first_name', 'last_name', 'jersey_num', 'team_id', 'team_city', 'team_name', 'team_abbreviation'] ...\n",
      "\n",
      "=== play_by_play.csv ===\n",
      "shape: (13592899, 34)\n",
      "columns: ['game_id', 'eventnum', 'eventmsgtype', 'eventmsgactiontype', 'period', 'wctimestring', 'pctimestring', 'homedescription', 'neutraldescription', 'visitordescription', 'score', 'scoremargin', 'person1type', 'player1_id', 'player1_name'] ...\n",
      "\n",
      "=== team_history.csv ===\n",
      "shape: (52, 5)\n",
      "columns: ['team_id', 'city', 'nickname', 'year_founded', 'year_active_till'] ...\n",
      "\n",
      "=== game.csv ===\n",
      "shape: (65698, 55)\n",
      "columns: ['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home', 'game_id', 'game_date', 'matchup_home', 'wl_home', 'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home'] ...\n",
      "\n",
      "=== line_score.csv ===\n",
      "shape: (58053, 43)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'team_id_home', 'team_abbreviation_home', 'team_city_name_home', 'team_nickname_home', 'team_wins_losses_home', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home'] ...\n",
      "\n",
      "=== player.csv ===\n",
      "shape: (4831, 5)\n",
      "columns: ['id', 'full_name', 'first_name', 'last_name', 'is_active'] ...\n",
      "\n",
      "=== team_info_common.csv ===\n",
      "shape: (0, 26)\n",
      "columns: ['team_id', 'season_year', 'team_city', 'team_name', 'team_abbreviation', 'team_conference', 'team_division', 'team_code', 'team_slug', 'w', 'l', 'pct', 'conf_rank', 'div_rank', 'min_year'] ...\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"common_player_info.csv\",\n",
    "    \"game_info.csv\",\n",
    "    \"officials.csv\",\n",
    "    \"team.csv\",\n",
    "    \"draft_combine_stats.csv\",\n",
    "    \"game_summary.csv\",\n",
    "    \"other_stats.csv\",\n",
    "    \"team_details.csv\",\n",
    "    \"draft_history.csv\",\n",
    "    \"inactive_players.csv\",\n",
    "    \"play_by_play.csv\",\n",
    "    \"team_history.csv\",\n",
    "    \"game.csv\",\n",
    "    \"line_score.csv\",\n",
    "    \"player.csv\",\n",
    "    \"team_info_common.csv\",\n",
    "]\n",
    "\n",
    "for fname in files:\n",
    "    path = os.path.join(DATA_DIR, fname)\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\n=== {fname} ===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"columns:\", list(df.columns)[:15], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd2417f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games: (65698, 55)\n",
      "game_info: (58053, 4)\n",
      "other_stats: (28271, 26)\n"
     ]
    }
   ],
   "source": [
    "# Core tables for modeling\n",
    "games = pd.read_csv(os.path.join(DATA_DIR, \"game.csv\"))\n",
    "game_info = pd.read_csv(os.path.join(DATA_DIR, \"game_info.csv\"))\n",
    "other_stats = pd.read_csv(os.path.join(DATA_DIR, \"other_stats.csv\"))\n",
    "\n",
    "print(\"games:\", games.shape)\n",
    "print(\"game_info:\", game_info.shape)\n",
    "print(\"other_stats:\", other_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416bc1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_df: (4831, 5)\n",
      "common_player_info: (4171, 33)\n",
      "play_by_play: (13592899, 34)\n",
      "num_players (including padding): 4832\n"
     ]
    }
   ],
   "source": [
    "# --- Player-level tables ---\n",
    "player_df = pd.read_csv(os.path.join(DATA_DIR, \"player.csv\"))\n",
    "common_player_info = pd.read_csv(os.path.join(DATA_DIR, \"common_player_info.csv\"))\n",
    "play_by_play = pd.read_csv(os.path.join(DATA_DIR, \"play_by_play.csv\"))\n",
    "\n",
    "print(\"player_df:\", player_df.shape)\n",
    "print(\"common_player_info:\", common_player_info.shape)\n",
    "print(\"play_by_play:\", play_by_play.shape)\n",
    "\n",
    "# Player ID mapping (reserve 0 for padding / unknown)\n",
    "player_ids = sorted(player_df[\"id\"].unique())\n",
    "player_id_to_idx = {pid: i + 1 for i, pid in enumerate(player_ids)}\n",
    "num_players = len(player_ids) + 1  # +1 for padding index 0\n",
    "\n",
    "print(\"num_players (including padding):\", num_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47f7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column config for our pipeline\n",
    "GAME_ID_COL = \"game_id\"\n",
    "GAME_DATE_COL = \"game_date\"\n",
    "HOME_TEAM_COL = \"team_id_home\"\n",
    "AWAY_TEAM_COL = \"team_id_away\"\n",
    "PTS_HOME_COL = \"pts_home\"\n",
    "PTS_AWAY_COL = \"pts_away\"\n",
    "\n",
    "# Make sure game_date is datetime\n",
    "games[GAME_DATE_COL] = pd.to_datetime(games[GAME_DATE_COL])\n",
    "game_info[\"game_date\"] = pd.to_datetime(game_info[\"game_date\"])\n",
    "\n",
    "# Keep only modern-era games\n",
    "mask_games = games[GAME_DATE_COL] >= ERA_START\n",
    "games = games.loc[mask_games].reset_index(drop=True)\n",
    "\n",
    "# Match game_info to the same window\n",
    "mask_info = game_info[\"game_date\"] >= ERA_START\n",
    "game_info = game_info.loc[mask_info].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede8cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Restrict PBP to games in our modeling window ---\n",
    "valid_game_ids = set(games[GAME_ID_COL].unique())\n",
    "play_by_play = play_by_play[play_by_play[\"game_id\"].isin(valid_game_ids)].copy()\n",
    "\n",
    "# Attach home/away team IDs to each pbp row\n",
    "games_for_merge = games[[GAME_ID_COL, HOME_TEAM_COL, AWAY_TEAM_COL]].drop_duplicates()\n",
    "play_by_play = play_by_play.merge(games_for_merge, on=GAME_ID_COL, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ca0e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_games (per game/team/player): (428039, 4)\n",
      "    game_id  team_id  player_id  event_count\n",
      "0  11300001    12321        965            1\n",
      "1  11300001    12321       2555            1\n",
      "2  11300001    12321      12321           16\n",
      "3  11300001    12321      42531           17\n",
      "4  11300001    12321      42534            4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Infer team_id for each event where we have a player1_id\n",
    "def infer_team(row):\n",
    "    # home side event if homedescription is non-null\n",
    "    if pd.notna(row.get(\"homedescription\")) and row[\"homedescription\"] != \"\":\n",
    "        return row[HOME_TEAM_COL]\n",
    "    # visitor side event if visitordescription is non-null\n",
    "    if pd.notna(row.get(\"visitordescription\")) and row[\"visitordescription\"] != \"\":\n",
    "        return row[AWAY_TEAM_COL]\n",
    "    return np.nan\n",
    "\n",
    "play_by_play[\"team_id_event\"] = play_by_play.apply(infer_team, axis=1)\n",
    "\n",
    "# Keep only rows where we can assign team + player\n",
    "pbp_players = play_by_play.dropna(subset=[\"team_id_event\", \"player1_id\"]).copy()\n",
    "pbp_players[\"team_id_event\"] = pbp_players[\"team_id_event\"].astype(int)\n",
    "\n",
    "# Count events per (game, team, player) as a crude \"usage\" proxy\n",
    "pbp_players[\"event_count\"] = 1\n",
    "player_games = (\n",
    "    pbp_players\n",
    "    .groupby([\"game_id\", \"team_id_event\", \"player1_id\"], as_index=False)\n",
    "    .agg(event_count=(\"event_count\", \"sum\"))\n",
    "    .rename(columns={\"team_id_event\": \"team_id\", \"player1_id\": \"player_id\"})\n",
    ")\n",
    "\n",
    "print(\"player_games (per game/team/player):\", player_games.shape)\n",
    "print(player_games.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edab5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num (game, team) rosters: 29030\n"
     ]
    }
   ],
   "source": [
    "P = 10  # max players per side we keep (you can tweak this)\n",
    "\n",
    "roster_by_game_team = {}\n",
    "\n",
    "for (gid, tid), group in player_games.groupby([\"game_id\", \"team_id\"]):\n",
    "    # sort players by event_count desc (proxy for minutes/importance)\n",
    "    group = group.sort_values(\"event_count\", ascending=False)\n",
    "    player_ids_this = group[\"player_id\"].astype(int).tolist()\n",
    "    \n",
    "    # truncate / pad to length P\n",
    "    player_ids_this = player_ids_this[:P]\n",
    "    while len(player_ids_this) < P:\n",
    "        player_ids_this.append(0)  # 0 = padding / unknown player\n",
    "    \n",
    "    roster_by_game_team[(gid, tid)] = player_ids_this\n",
    "\n",
    "print(\"Num (game, team) rosters:\", len(roster_by_game_team))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f2af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num home_feature_cols: 24\n",
      "Num away_feature_cols: 24\n",
      "team_games initial: (32560, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pf</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>94.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-38</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-33</td>\n",
       "      <td>81.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...    pf  plus_minus    pts   reb   stl  team_abbreviation  \\\n",
       "0  31.0  ...  20.0         -27   80.0  36.0   7.0                MTA   \n",
       "1  26.0  ...  27.0         -17   94.0  43.0   4.0                MTA   \n",
       "2  19.0  ...  30.0         -38   70.0  37.0  10.0                MAC   \n",
       "3  21.0  ...  22.0          -8  100.0  38.0   9.0                MAC   \n",
       "4  27.0  ...  30.0         -33   81.0  45.0   9.0                MAC   \n",
       "\n",
       "                  team_name   tov  video_available  wl  \n",
       "0  Tel Aviv Maccabi Electra   9.0                0   L  \n",
       "1  Tel Aviv Maccabi Electra  21.0                0   L  \n",
       "2       Haifa Maccabi Haifa  21.0                0   L  \n",
       "3       Haifa Maccabi Haifa  14.0                0   L  \n",
       "4       Haifa Maccabi Haifa  26.0                0   L  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Select home/away feature columns, EXCLUDING the team_id columns\n",
    "home_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_home\") and c != HOME_TEAM_COL\n",
    "]\n",
    "\n",
    "away_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_away\") and c != AWAY_TEAM_COL\n",
    "]\n",
    "\n",
    "print(\"Num home_feature_cols:\", len(home_feature_cols))\n",
    "print(\"Num away_feature_cols:\", len(away_feature_cols))\n",
    "\n",
    "# 2) Home rows\n",
    "home_df = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL] + home_feature_cols].copy()\n",
    "home_df = home_df.rename(columns={HOME_TEAM_COL: \"team_id\"})\n",
    "home_df[\"is_home\"] = 1\n",
    "\n",
    "for col in home_feature_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_df[base] = home_df[col]\n",
    "\n",
    "home_df[\"y_points\"] = home_df[PTS_HOME_COL]\n",
    "\n",
    "# 3) Away rows\n",
    "away_df = games[[GAME_ID_COL, GAME_DATE_COL, AWAY_TEAM_COL] + away_feature_cols].copy()\n",
    "away_df = away_df.rename(columns={AWAY_TEAM_COL: \"team_id\"})\n",
    "away_df[\"is_home\"] = 0\n",
    "\n",
    "for col in away_feature_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_df[base] = away_df[col]\n",
    "\n",
    "away_df[\"y_points\"] = away_df[PTS_AWAY_COL]\n",
    "\n",
    "# 4) Keep only unified columns\n",
    "keep_cols = [GAME_ID_COL, GAME_DATE_COL, \"team_id\", \"is_home\", \"y_points\"]\n",
    "base_feature_names = sorted(\n",
    "    {c.replace(\"_home\", \"\").replace(\"_away\", \"\") for c in home_feature_cols + away_feature_cols}\n",
    ")\n",
    "keep_cols += base_feature_names\n",
    "\n",
    "home_df = home_df[keep_cols].copy()\n",
    "away_df = away_df[keep_cols].copy()\n",
    "\n",
    "# 5) Combine into team_games\n",
    "team_games = pd.concat([home_df, away_df], axis=0).reset_index(drop=True)\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "print(\"team_games initial:\", team_games.shape)\n",
    "team_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed3ab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_info_small sample:\n",
      "    game_id  attendance  game_hour\n",
      "0  21000003     18997.0        NaN\n",
      "1  21000002     20603.0        NaN\n",
      "2  21000001     18624.0        NaN\n",
      "3  21000015     18428.0        NaN\n",
      "4  21000010     15039.0        NaN\n",
      "team_games after game_info: (32584, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "      <th>attendance</th>\n",
       "      <th>game_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MTA</td>\n",
       "      <td>Tel Aviv Maccabi Electra</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>15915.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>5174.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>11192.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...    pts   reb   stl  team_abbreviation                 team_name  \\\n",
       "0  31.0  ...   80.0  36.0   7.0                MTA  Tel Aviv Maccabi Electra   \n",
       "1  26.0  ...   94.0  43.0   4.0                MTA  Tel Aviv Maccabi Electra   \n",
       "2  19.0  ...   70.0  37.0  10.0                MAC       Haifa Maccabi Haifa   \n",
       "3  21.0  ...  100.0  38.0   9.0                MAC       Haifa Maccabi Haifa   \n",
       "4  27.0  ...   81.0  45.0   9.0                MAC       Haifa Maccabi Haifa   \n",
       "\n",
       "    tov  video_available wl  attendance  game_hour  \n",
       "0   9.0                0  L     20562.0        NaN  \n",
       "1  21.0                0  L     15915.0        NaN  \n",
       "2  21.0                0  L      5174.0        NaN  \n",
       "3  14.0                0  L         NaN        NaN  \n",
       "4  26.0                0  L     11192.0        NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 2: merge game_info (attendance + game_hour) ---\n",
    "\n",
    "# Parse game_time to hour-of-day\n",
    "game_info[\"game_hour\"] = pd.to_datetime(\n",
    "    game_info[\"game_time\"],\n",
    "    format=\"%I:%M %p\",\n",
    "    errors=\"coerce\"\n",
    ").dt.hour\n",
    "\n",
    "# Keep only what we need\n",
    "game_info_small = game_info[[GAME_ID_COL, \"attendance\", \"game_hour\"]].copy()\n",
    "\n",
    "print(\"game_info_small sample:\")\n",
    "print(game_info_small.head())\n",
    "\n",
    "# Merge into team_games\n",
    "team_games = team_games.merge(\n",
    "    game_info_small,\n",
    "    on=GAME_ID_COL,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after game_info:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2b61f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_stats sample:\n",
      "    game_id  league_id  team_id_home team_abbreviation_home team_city_home  \\\n",
      "0  29600012          0    1610612756                    PHX        Phoenix   \n",
      "1  29600005          0    1610612737                    ATL        Atlanta   \n",
      "2  29600002          0    1610612739                    CLE      Cleveland   \n",
      "3  29600007          0    1610612754                    IND        Indiana   \n",
      "4  29600013          0    1610612746                    LAC    Los Angeles   \n",
      "\n",
      "   pts_paint_home  pts_2nd_chance_home  pts_fb_home  largest_lead_home  \\\n",
      "0              44                   18            2                  1   \n",
      "1              32                    9            6                  0   \n",
      "2              36                   14            6                 20   \n",
      "3              34                   11            4                 10   \n",
      "4              40                   19            2                 12   \n",
      "\n",
      "   lead_changes  ...  team_abbreviation_away  team_city_away  pts_paint_away  \\\n",
      "0             4  ...                     LAL     Los Angeles              42   \n",
      "1             0  ...                     MIA           Miami              32   \n",
      "2             1  ...                     NJN      New Jersey              26   \n",
      "3             7  ...                     DET         Detroit              30   \n",
      "4             5  ...                     GSW    Golden State              30   \n",
      "\n",
      "   pts_2nd_chance_away  pts_fb_away  largest_lead_away team_turnovers_away  \\\n",
      "0                   10           13                 19                 0.0   \n",
      "1                   15           14                 16                 1.0   \n",
      "2                   16            4                  2                 1.0   \n",
      "3                   14            7                  9                 2.0   \n",
      "4                    9            2                  6                 0.0   \n",
      "\n",
      "  total_turnovers_away  team_rebounds_away  pts_off_to_away  \n",
      "0                 23.0                11.0              NaN  \n",
      "1                 19.0                 6.0              NaN  \n",
      "2                 22.0                12.0              NaN  \n",
      "3                 19.0                10.0              NaN  \n",
      "4                 20.0                 7.0              NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "home_stat_cols: ['pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home']\n",
      "away_stat_cols: ['pts_paint_away', 'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away', 'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away']\n",
      "game_level_cols: ['lead_changes', 'times_tied']\n",
      "home_adv shape: (28271, 12)\n",
      "away_adv shape: (28271, 12)\n",
      "adv_long shape: (56542, 12)\n",
      "    game_id     team_id  lead_changes  times_tied  pts_paint  pts_2nd_chance  \\\n",
      "0  29600012  1610612756             4           1         44              18   \n",
      "1  29600005  1610612737             0           0         32               9   \n",
      "2  29600002  1610612739             1           1         36              14   \n",
      "3  29600007  1610612754             7           4         34              11   \n",
      "4  29600013  1610612746             5           4         40              19   \n",
      "\n",
      "   pts_fb  largest_lead  team_turnovers  total_turnovers  team_rebounds  \\\n",
      "0       2             1             0.0             12.0           11.0   \n",
      "1       6             0             1.0             24.0            7.0   \n",
      "2       6            20             0.0             15.0            5.0   \n",
      "3       4            10             0.0             18.0            8.0   \n",
      "4       2            12             0.0             20.0            7.0   \n",
      "\n",
      "   pts_off_to  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "team_games after other_stats: (32632, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>lead_changes</th>\n",
       "      <th>times_tied</th>\n",
       "      <th>pts_paint</th>\n",
       "      <th>pts_2nd_chance</th>\n",
       "      <th>pts_fb</th>\n",
       "      <th>largest_lead</th>\n",
       "      <th>team_turnovers</th>\n",
       "      <th>total_turnovers</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.231</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11400003 2014-10-05       41        0      80.0  19.0  7.0  28.0    0.258   \n",
       "1  11400011 2014-10-07       41        0      94.0  15.0  5.0  32.0    0.231   \n",
       "2  11000002 2010-10-03       93        0      70.0  14.0  2.0  25.0    0.316   \n",
       "3  11200029 2012-10-11       93        0     100.0  23.0  5.0  26.0    0.381   \n",
       "4  11200056 2012-10-16       93        0      81.0  17.0  4.0  33.0    0.370   \n",
       "\n",
       "   fg3a  ...  lead_changes  times_tied  pts_paint  pts_2nd_chance  pts_fb  \\\n",
       "0  31.0  ...           1.0         3.0       32.0            12.0     3.0   \n",
       "1  26.0  ...           0.0         0.0       54.0            15.0    12.0   \n",
       "2  19.0  ...           3.0         1.0       28.0             8.0    17.0   \n",
       "3  21.0  ...           NaN         NaN        NaN             NaN     NaN   \n",
       "4  27.0  ...           2.0         2.0       30.0            19.0     4.0   \n",
       "\n",
       "   largest_lead  team_turnovers total_turnovers  team_rebounds  pts_off_to  \n",
       "0           3.0             0.0             9.0            5.0         8.0  \n",
       "1           0.0             1.0            21.0            7.0        28.0  \n",
       "2           3.0             0.0            21.0           10.0        29.0  \n",
       "3           NaN             NaN             NaN            NaN         NaN  \n",
       "4           3.0             0.0            26.0            7.0        35.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 3: merge other_stats (advanced team stats) ---\n",
    "\n",
    "print(\"other_stats sample:\")\n",
    "print(other_stats.head())\n",
    "\n",
    "# Game-level columns that apply to the whole game\n",
    "game_level_cols = []\n",
    "for col in [\"lead_changes\", \"times_tied\"]:\n",
    "    if col in other_stats.columns:\n",
    "        game_level_cols.append(col)\n",
    "\n",
    "# Home/away advanced stat columns (excluding id/label columns)\n",
    "home_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_home\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "away_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_away\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "print(\"home_stat_cols:\", home_stat_cols)\n",
    "print(\"away_stat_cols:\", away_stat_cols)\n",
    "print(\"game_level_cols:\", game_level_cols)\n",
    "\n",
    "# 4.1 Home advanced stats → unified format\n",
    "home_adv = other_stats[[\"game_id\", \"team_id_home\"] + game_level_cols + home_stat_cols].copy()\n",
    "home_adv = home_adv.rename(columns={\"team_id_home\": \"team_id\"})\n",
    "\n",
    "for col in home_stat_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_adv[base] = home_adv[col]\n",
    "\n",
    "home_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_home\", \"\") for c in home_stat_cols]\n",
    "home_adv = home_adv[home_keep_cols]\n",
    "\n",
    "# 4.2 Away advanced stats → unified format\n",
    "away_adv = other_stats[[\"game_id\", \"team_id_away\"] + game_level_cols + away_stat_cols].copy()\n",
    "away_adv = away_adv.rename(columns={\"team_id_away\": \"team_id\"})\n",
    "\n",
    "for col in away_stat_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_adv[base] = away_adv[col]\n",
    "\n",
    "away_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_away\", \"\") for c in away_stat_cols]\n",
    "away_adv = away_adv[away_keep_cols]\n",
    "\n",
    "print(\"home_adv shape:\", home_adv.shape)\n",
    "print(\"away_adv shape:\", away_adv.shape)\n",
    "\n",
    "# 4.3 Combine advanced stats\n",
    "adv_long = pd.concat([home_adv, away_adv], axis=0).reset_index(drop=True)\n",
    "print(\"adv_long shape:\", adv_long.shape)\n",
    "print(adv_long.head())\n",
    "\n",
    "# 4.4 Merge advanced stats into team_games\n",
    "team_games = team_games.merge(\n",
    "    adv_long,\n",
    "    on=[\"game_id\", \"team_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after other_stats:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e860f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequence features: 36\n",
      "First 30 SEQ_FEATURES: ['is_home', 'ast', 'blk', 'dreb', 'fg3_pct', 'fg3a', 'fg3m', 'fg_pct', 'fga', 'fgm', 'ft_pct', 'fta', 'ftm', 'oreb', 'pf', 'plus_minus', 'pts', 'reb', 'stl', 'tov', 'attendance', 'game_hour', 'lead_changes', 'times_tied', 'pts_paint', 'pts_2nd_chance', 'pts_fb', 'largest_lead', 'team_turnovers', 'total_turnovers']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>prev3_date</th>\n",
       "      <th>prev4_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>is_3in4</th>\n",
       "      <th>is_4in6</th>\n",
       "      <th>team_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11400003</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.693698</td>\n",
       "      <td>0.849701</td>\n",
       "      <td>-0.903462</td>\n",
       "      <td>-0.953262</td>\n",
       "      <td>0.554806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501082</td>\n",
       "      <td>-0.738944</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.173476</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11400011</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>41</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-1.447486</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>-0.180799</td>\n",
       "      <td>-1.222245</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>1.702937</td>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.104295</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000002</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1.635933</td>\n",
       "      <td>-1.131691</td>\n",
       "      <td>-1.445459</td>\n",
       "      <td>-0.375448</td>\n",
       "      <td>-0.783777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712153</td>\n",
       "      <td>1.825031</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.173476</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11200029</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.060090</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>-1.264794</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>-0.560680</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.714317</td>\n",
       "      <td>-1.715697</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>25.388655</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11200056</td>\n",
       "      <td>2012-10-16</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-1.070592</td>\n",
       "      <td>-0.339134</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.162517</td>\n",
       "      <td>0.108612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>2.557596</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.485414</td>\n",
       "      <td>-0.14156</td>\n",
       "      <td>-0.217296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points       ast       blk  \\\n",
       "0  11400003 2014-10-05       41     -1.0      80.0 -0.693698  0.849701   \n",
       "1  11400011 2014-10-07       41     -1.0      94.0 -1.447486  0.057144   \n",
       "2  11000002 2010-10-03       93     -1.0      70.0 -1.635933 -1.131691   \n",
       "3  11200029 2012-10-11       93     -1.0     100.0  0.060090  0.057144   \n",
       "4  11200056 2012-10-16       93     -1.0      81.0 -1.070592 -0.339134   \n",
       "\n",
       "       dreb   fg3_pct      fg3a  ...  team_rebounds  pts_off_to  prev_date  \\\n",
       "0 -0.903462 -0.953262  0.554806  ...      -0.501082   -0.738944        NaT   \n",
       "1 -0.180799 -1.222245 -0.002937  ...      -0.015788    1.702937 2014-10-05   \n",
       "2 -1.445459 -0.375448 -0.783777  ...       0.712153    1.825031        NaT   \n",
       "3 -1.264794  0.272103 -0.560680  ...      -1.714317   -1.715697 2010-10-03   \n",
       "4 -0.000133  0.162517  0.108612  ...      -0.015788    2.557596 2012-10-11   \n",
       "\n",
       "   prev3_date  prev4_date  days_rest    is_b2b  is_3in4   is_4in6  team_idx  \n",
       "0         NaT         NaT  -0.173476 -0.485414 -0.14156 -0.217296         0  \n",
       "1         NaT         NaT  -0.104295 -0.485414 -0.14156 -0.217296         0  \n",
       "2         NaT         NaT  -0.173476 -0.485414 -0.14156 -0.217296         1  \n",
       "3         NaT         NaT  25.388655 -0.485414 -0.14156 -0.217296         1  \n",
       "4         NaT         NaT  -0.000525 -0.485414 -0.14156 -0.217296         1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compute SEQ_FEATURES and scale ---\n",
    "\n",
    "# --- Schedule features: rest / B2B / 3-in-4 / 4-in-6 ---\n",
    "\n",
    "# Ensure sorted by team + date\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "grouped = team_games.groupby(\"team_id\")\n",
    "\n",
    "# Previous game dates\n",
    "team_games[\"prev_date\"]  = grouped[GAME_DATE_COL].shift(1)\n",
    "team_games[\"prev3_date\"] = grouped[GAME_DATE_COL].shift(3)\n",
    "team_games[\"prev4_date\"] = grouped[GAME_DATE_COL].shift(4)\n",
    "\n",
    "# Days of rest since last game\n",
    "team_games[\"days_rest\"] = (team_games[GAME_DATE_COL] - team_games[\"prev_date\"]).dt.days\n",
    "\n",
    "# Schedule intensity flags\n",
    "team_games[\"is_b2b\"]  = (team_games[\"days_rest\"] == 1).astype(int)\n",
    "\n",
    "team_games[\"is_3in4\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev3_date\"]).dt.days <= 4\n",
    ").astype(int)\n",
    "\n",
    "team_games[\"is_4in6\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev4_date\"]).dt.days <= 6\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# --- Team ID ↔ index mapping for embeddings ---\n",
    "\n",
    "team_ids = sorted(team_games[\"team_id\"].unique())\n",
    "team_id_to_idx = {tid: i for i, tid in enumerate(team_ids)}\n",
    "num_teams = len(team_ids)\n",
    "\n",
    "# Optional: store per-row team index (not used in SEQ_FEATURES)\n",
    "team_games[\"team_idx\"] = team_games[\"team_id\"].map(team_id_to_idx)\n",
    "\n",
    "\n",
    "\n",
    "exclude_cols = {\n",
    "    GAME_ID_COL,\n",
    "    GAME_DATE_COL,\n",
    "    \"team_id\",\n",
    "    \"y_points\",\n",
    "    \"prev_date\",\n",
    "    \"prev3_date\",\n",
    "    \"prev4_date\",\n",
    "    \"team_idx\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    # non signals (i think)\n",
    "    \"video_available\",\n",
    "    \"attedance\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in team_games.columns\n",
    "    if c not in exclude_cols and pd.api.types.is_numeric_dtype(team_games[c])\n",
    "]\n",
    "\n",
    "SEQ_FEATURES = numeric_cols\n",
    "print(\"Number of sequence features:\", len(SEQ_FEATURES))\n",
    "print(\"First 30 SEQ_FEATURES:\", SEQ_FEATURES[:30])\n",
    "\n",
    "train_rows = team_games[team_games[GAME_DATE_COL] < VAL_SPLIT_DATE].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_rows[SEQ_FEATURES].fillna(0.0))\n",
    "\n",
    "team_games[SEQ_FEATURES] = scaler.transform(\n",
    "    team_games[SEQ_FEATURES].fillna(0.0)\n",
    ")\n",
    "\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d671461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_sequences: (32090, 15, 36)\n",
      "team_targets: (32090,)\n"
     ]
    }
   ],
   "source": [
    "team_sequences = []\n",
    "team_targets = []\n",
    "team_meta = []  # (game_id, team_id, game_date)\n",
    "\n",
    "for team_id, group in team_games.groupby(\"team_id\"):\n",
    "    group = group.sort_values(GAME_DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    feats = group[SEQ_FEATURES].values           # [num_games, F]\n",
    "    targets = group[\"y_points\"].values\n",
    "    game_ids = group[GAME_ID_COL].values\n",
    "    dates = group[GAME_DATE_COL].values\n",
    "\n",
    "    # require SEQ_LEN previous games\n",
    "    for i in range(SEQ_LEN, len(group)):\n",
    "        seq = feats[i-SEQ_LEN:i]\n",
    "        y = targets[i]\n",
    "        gid = game_ids[i]\n",
    "        date = dates[i]\n",
    "\n",
    "        team_sequences.append(seq)\n",
    "        team_targets.append(y)\n",
    "        team_meta.append((gid, team_id, date))\n",
    "\n",
    "team_sequences = np.stack(team_sequences)          # [N_team_games, T, F]\n",
    "team_targets = np.array(team_targets, dtype=np.float32)\n",
    "\n",
    "print(\"team_sequences:\", team_sequences.shape)\n",
    "print(\"team_targets:\", team_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6a9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_index_by_game_team = {\n",
    "    (gid, tid): idx\n",
    "    for idx, (gid, tid, date) in enumerate(team_meta)\n",
    "}\n",
    "\n",
    "len(seq_index_by_game_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18856e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_full: (16280, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>y_home</th>\n",
       "      <th>y_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21000003</td>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>112.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21000002</td>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>106.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21000001</td>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21000015</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>132.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21000010</td>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  home_team_id  away_team_id  y_home  y_away\n",
       "0  21000003 2010-10-26    1610612747    1610612745   112.0   110.0\n",
       "1  21000002 2010-10-26    1610612757    1610612756   106.0    92.0\n",
       "2  21000001 2010-10-26    1610612738    1610612748    88.0    80.0\n",
       "3  21000015 2010-10-27    1610612744    1610612745   132.0   128.0\n",
       "4  21000010 2010-10-27    1610612740    1610612749    95.0    91.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_full = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL, AWAY_TEAM_COL, PTS_HOME_COL, PTS_AWAY_COL]].copy()\n",
    "\n",
    "games_full = games_full.rename(columns={\n",
    "    HOME_TEAM_COL: \"home_team_id\",\n",
    "    AWAY_TEAM_COL: \"away_team_id\",\n",
    "    PTS_HOME_COL: \"y_home\",\n",
    "    PTS_AWAY_COL: \"y_away\"\n",
    "})\n",
    "\n",
    "print(\"games_full:\", games_full.shape)\n",
    "games_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c119c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes:\n",
      "X_home: (15985, 15, 36)\n",
      "X_away: (15985, 15, 36)\n",
      "Y: (15985, 2)\n",
      "HOME_PLAYER_IDX: (15985, 10)\n",
      "AWAY_PLAYER_IDX: (15985, 10)\n"
     ]
    }
   ],
   "source": [
    "X_home = []\n",
    "X_away = []\n",
    "Y = []\n",
    "GAME_DATES = []\n",
    "\n",
    "HOME_TEAM_IDX = []\n",
    "AWAY_TEAM_IDX = []\n",
    "\n",
    "HOME_PLAYER_IDX_LIST = []\n",
    "AWAY_PLAYER_IDX_LIST = []\n",
    "\n",
    "for _, row in games_full.iterrows():\n",
    "    gid = row[GAME_ID_COL]\n",
    "    home_id = row[\"home_team_id\"]\n",
    "    away_id = row[\"away_team_id\"]\n",
    "    date = row[GAME_DATE_COL]\n",
    "\n",
    "    key_home = (gid, home_id)\n",
    "    key_away = (gid, away_id)\n",
    "\n",
    "    if key_home not in seq_index_by_game_team or key_away not in seq_index_by_game_team:\n",
    "        continue  # skip early games (not enough history)\n",
    "\n",
    "    idx_h = seq_index_by_game_team[key_home]\n",
    "    idx_a = seq_index_by_game_team[key_away]\n",
    "\n",
    "    X_home.append(team_sequences[idx_h])\n",
    "    X_away.append(team_sequences[idx_a])\n",
    "\n",
    "    # Targets: margin & total\n",
    "    home = row[\"y_home\"]\n",
    "    away = row[\"y_away\"]\n",
    "    margin = home - away\n",
    "    total  = home + away\n",
    "    Y.append([margin, total])\n",
    "\n",
    "    GAME_DATES.append(date)\n",
    "    HOME_TEAM_IDX.append(team_id_to_idx[home_id])\n",
    "    AWAY_TEAM_IDX.append(team_id_to_idx[away_id])\n",
    "\n",
    "    # --- NEW: home/away player rosters as embedding indices ---\n",
    "    home_roster_raw = roster_by_game_team.get(key_home, [0] * P)\n",
    "    away_roster_raw = roster_by_game_team.get(key_away, [0] * P)\n",
    "\n",
    "    # map raw player IDs -> embedding indices (0 reserved for padding)\n",
    "    home_player_idx = [player_id_to_idx.get(pid, 0) for pid in home_roster_raw]\n",
    "    away_player_idx = [player_id_to_idx.get(pid, 0) for pid in away_roster_raw]\n",
    "\n",
    "    HOME_PLAYER_IDX_LIST.append(home_player_idx)\n",
    "    AWAY_PLAYER_IDX_LIST.append(away_player_idx)\n",
    "\n",
    "X_home = np.stack(X_home)\n",
    "X_away = np.stack(X_away)\n",
    "Y = np.array(Y, dtype=np.float32)\n",
    "GAME_DATES = np.array(GAME_DATES)\n",
    "\n",
    "HOME_TEAM_IDX = np.array(HOME_TEAM_IDX, dtype=np.int64)\n",
    "AWAY_TEAM_IDX = np.array(AWAY_TEAM_IDX, dtype=np.int64)\n",
    "\n",
    "HOME_PLAYER_IDX = np.array(HOME_PLAYER_IDX_LIST, dtype=np.int64)  # [N_games, P]\n",
    "AWAY_PLAYER_IDX = np.array(AWAY_PLAYER_IDX_LIST, dtype=np.int64)\n",
    "\n",
    "print(\"Final dataset shapes:\")\n",
    "print(\"X_home:\", X_home.shape)\n",
    "print(\"X_away:\", X_away.shape)\n",
    "print(\"Y:\", Y.shape)\n",
    "print(\"HOME_PLAYER_IDX:\", HOME_PLAYER_IDX.shape)\n",
    "print(\"AWAY_PLAYER_IDX:\", AWAY_PLAYER_IDX.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25fd0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 13220 Val: 1385 Test: 1380\n",
      "Train mean scores (margin, total): [  2.5335855 208.52057  ]\n"
     ]
    }
   ],
   "source": [
    "VAL_SPLIT_DATE = pd.to_datetime(VAL_SPLIT_DATE)\n",
    "TEST_SPLIT_DATE = pd.to_datetime(TEST_SPLIT_DATE)\n",
    "\n",
    "dates = pd.to_datetime(GAME_DATES)\n",
    "\n",
    "train_mask = dates < VAL_SPLIT_DATE\n",
    "val_mask = (dates >= VAL_SPLIT_DATE) & (dates < TEST_SPLIT_DATE)\n",
    "test_mask = dates >= TEST_SPLIT_DATE\n",
    "\n",
    "def split(arr):\n",
    "    return arr[train_mask], arr[val_mask], arr[test_mask]\n",
    "\n",
    "X_home_train, X_home_val, X_home_test = split(X_home)\n",
    "X_away_train, X_away_val, X_away_test = split(X_away)\n",
    "Y_train, Y_val, Y_test = split(Y)\n",
    "\n",
    "home_idx_train, home_idx_val, home_idx_test = split(HOME_TEAM_IDX)\n",
    "away_idx_train, away_idx_val, away_idx_test = split(AWAY_TEAM_IDX)\n",
    "\n",
    "home_player_train, home_player_val, home_player_test = split(HOME_PLAYER_IDX)\n",
    "away_player_train, away_player_val, away_player_test = split(AWAY_PLAYER_IDX)\n",
    "\n",
    "\n",
    "print(\"Train:\", len(Y_train), \"Val:\", len(Y_val), \"Test:\", len(Y_test))\n",
    "\n",
    "\n",
    "# --- NEW: keep raw targets and create a scaler for [margin, total] ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_mean_scores = Y_train.mean(axis=0)   # still raw here!\n",
    "print(\"Train mean scores (margin, total):\", train_mean_scores)\n",
    "\n",
    "Y_train_raw = Y_train.copy()\n",
    "Y_val_raw   = Y_val.copy()\n",
    "Y_test_raw  = Y_test.copy()\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(Y_train_raw)        # fit on train only\n",
    "\n",
    "Y_train = y_scaler.transform(Y_train_raw)\n",
    "Y_val   = y_scaler.transform(Y_val_raw)\n",
    "Y_test  = y_scaler.transform(Y_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba18b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameSequenceDataset(Dataset):\n",
    "    def __init__(self, x_home, x_away, y, home_idx, away_idx, home_players, away_players):\n",
    "        self.x_home = torch.tensor(x_home, dtype=torch.float32)\n",
    "        self.x_away = torch.tensor(x_away, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        self.home_idx = torch.tensor(home_idx, dtype=torch.long)\n",
    "        self.away_idx = torch.tensor(away_idx, dtype=torch.long)\n",
    "\n",
    "        self.home_players = torch.tensor(home_players, dtype=torch.long)  # [N, P]\n",
    "        self.away_players = torch.tensor(away_players, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_home[idx],\n",
    "            self.x_away[idx],\n",
    "            self.y[idx],\n",
    "            self.home_idx[idx],\n",
    "            self.away_idx[idx],\n",
    "            self.home_players[idx],\n",
    "            self.away_players[idx],\n",
    "        )\n",
    "\n",
    "train_dataset = GameSequenceDataset(\n",
    "    X_home_train, X_away_train, Y_train,\n",
    "    home_idx_train, away_idx_train,\n",
    "    home_player_train, away_player_train,\n",
    ")\n",
    "val_dataset = GameSequenceDataset(\n",
    "    X_home_val, X_away_val, Y_val,\n",
    "    home_idx_val, away_idx_val,\n",
    "    home_player_val, away_player_val,\n",
    ")\n",
    "test_dataset = GameSequenceDataset(\n",
    "    X_home_test, X_away_test, Y_test,\n",
    "    home_idx_test, away_idx_test,\n",
    "    home_player_test, away_player_test,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80481bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_home shape: torch.Size([15, 36])\n",
      "x_away shape: torch.Size([15, 36])\n",
      "y: tensor([ 0.1791, -0.6802])\n",
      "home_idx: tensor(31)\n",
      "away_idx: tensor(34)\n",
      "home_players shape: torch.Size([10])\n",
      "away_players shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "x_home, x_away, y, home_idx, away_idx, home_players, away_players = sample\n",
    "\n",
    "print(\"x_home shape:\", x_home.shape)    # expected [SEQ_LEN, num_team_seq_features]\n",
    "print(\"x_away shape:\", x_away.shape)\n",
    "print(\"y:\", y)                          # expected shape [2] (margin, total)\n",
    "print(\"home_idx:\", home_idx)            # int\n",
    "print(\"away_idx:\", away_idx)            # int\n",
    "print(\"home_players shape:\", home_players.shape)  # expected [P]\n",
    "print(\"away_players shape:\", away_players.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e4198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx_home batch shape: torch.Size([64, 15, 36])\n",
      "bx_away batch shape: torch.Size([64, 15, 36])\n",
      "by batch shape: torch.Size([64, 2])\n",
      "bhome_players batch shape: torch.Size([64, 10])\n",
      "baway_players batch shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "(\n",
    "    bx_home, bx_away, by,\n",
    "    bhome_idx, baway_idx,\n",
    "    bhome_players, baway_players\n",
    ") = batch\n",
    "\n",
    "print(\"bx_home batch shape:\", bx_home.shape)        # [B, 20, 37]\n",
    "print(\"bx_away batch shape:\", bx_away.shape)\n",
    "print(\"by batch shape:\", by.shape)                  # [B, 2]\n",
    "print(\"bhome_players batch shape:\", bhome_players.shape)  # [B, P]\n",
    "print(\"baway_players batch shape:\", baway_players.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f04e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max home_idx: 52\n",
      "max away_idx: 52\n",
      "num_teams: 53\n"
     ]
    }
   ],
   "source": [
    "print(\"max home_idx:\", home_idx_train.max())\n",
    "print(\"max away_idx:\", away_idx_train.max())\n",
    "print(\"num_teams:\", num_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c3fdc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max home_players: 4653\n",
      "max away_players: 4653\n",
      "num_players: 4832\n"
     ]
    }
   ],
   "source": [
    "print(\"max home_players:\", home_player_train.max())\n",
    "print(\"max away_players:\", away_player_train.max())\n",
    "print(\"num_players:\", num_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02ed17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home roster unique values (first 1000 games): [  0 158 237 252 267 289 292 306 311 417 420 425 428 434 442 443 444 445\n",
      " 516 558]\n"
     ]
    }
   ],
   "source": [
    "unique_vals = np.unique(home_player_train[:1000])\n",
    "print(\"Home roster unique values (first 1000 games):\", unique_vals[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a37c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train latest date: 2021-07-20 00:00:00\n",
      "Val earliest date: 2021-10-03 00:00:00\n",
      "Test earliest date: 2022-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Train latest date:\", GAME_DATES[train_mask].max())\n",
    "print(\"Val earliest date:\", GAME_DATES[val_mask].min())\n",
    "print(\"Test earliest date:\", GAME_DATES[test_mask].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03959dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team index: 33 44\n",
      "Home players: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Away players: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(train_dataset))\n",
    "sample = train_dataset[idx]\n",
    "\n",
    "_, _, _, home_idx, away_idx, home_players, away_players = sample\n",
    "\n",
    "print(\"Team index:\", home_idx.item(), away_idx.item())\n",
    "print(\"Home players:\", home_players[:10])\n",
    "print(\"Away players:\", away_players[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7bca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 21600227 1610612739 1610612742\n",
      "Mapped home idx: 33 → 1610612749\n"
     ]
    }
   ],
   "source": [
    "gid, home_id, away_id = games_full.iloc[idx][['game_id','home_team_id','away_team_id']]\n",
    "print(\"Original:\", gid, home_id, away_id)\n",
    "print(\"Mapped home idx:\", home_idx.item(), \"→\", team_ids[home_idx.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e22816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.isnan(X_home).any()\n",
    "assert not np.isinf(X_home).any()\n",
    "assert not np.isnan(X_away).any()\n",
    "assert not np.isinf(X_away).any()\n",
    "assert not np.isnan(Y).any()\n",
    "assert not np.isinf(Y).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "766a13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (15, 36) (15, 36) [ 0.1791383  -0.68023914]\n",
      "1 (15, 36) (15, 36) [ 1.4138665 -1.3376623]\n",
      "2 (15, 36) (15, 36) [-0.76506555 -1.1623495 ]\n",
      "3 (15, 36) (15, 36) [-0.54717237 -0.50492626]\n",
      "4 (15, 36) (15, 36) [-0.54717237  1.3358588 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    seq_h = X_home_train[i]\n",
    "    seq_a = X_away_train[i]\n",
    "    t = Y_train[i]\n",
    "    print(i, seq_h.shape, seq_a.shape, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1cf0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TeamSequenceEncoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int = 1, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # output: [B, T, 2H]\n",
    "        return output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScorePredictorGNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,          # seq feature dim (36 in your printout)\n",
    "        hidden_size: int = 64,    # BiLSTM hidden\n",
    "        num_layers: int = 3,\n",
    "        num_teams: int = None,\n",
    "        num_players: int = None,\n",
    "        team_emb_dim: int = 16,\n",
    "        player_emb_dim: int = 64,   # bump player dim\n",
    "        gnn_hidden_dim: int = 128,  # graph node dim\n",
    "        gnn_steps: int = 2,         # message passing steps\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gnn_steps = gnn_steps\n",
    "\n",
    "        # --- Time encoder over team sequence (same as before) ---\n",
    "        self.encoder = TeamSequenceEncoder(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        seq_dim = hidden_size * 2  # BiLSTM\n",
    "\n",
    "        # --- Embeddings ---\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        # IMPORTANT: padding_idx=0 so id 0 is ignored / kept zero\n",
    "        self.player_embedding = nn.Embedding(\n",
    "            num_players,\n",
    "            player_emb_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "\n",
    "        # --- Project into graph space ---\n",
    "        # team node gets [seq_vec, team_id_emb] → gnn_hidden_dim\n",
    "        self.team_in = nn.Linear(seq_dim + team_emb_dim, gnn_hidden_dim)\n",
    "\n",
    "        # player node gets just player_emb → gnn_hidden_dim\n",
    "        self.player_in = nn.Linear(player_emb_dim, gnn_hidden_dim)\n",
    "\n",
    "        # --- Message-passing MLPs ---\n",
    "        # Team update sees [team_node, mean(player_nodes)]\n",
    "        self.team_update = nn.Linear(2 * gnn_hidden_dim, gnn_hidden_dim)\n",
    "\n",
    "        # Player update sees [player_node, team_node_broadcast]\n",
    "        self.player_update = nn.Linear(2 * gnn_hidden_dim, gnn_hidden_dim)\n",
    "\n",
    "        # --- Final prediction head ---\n",
    "        # We’ll use both teams’ final team_node and pooled player_node\n",
    "        pair_input_dim = 4 * gnn_hidden_dim  # home_team, away_team, home_players, away_players\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 2),  # [margin, total]\n",
    "        )\n",
    "        \n",
    "        # new\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_home, x_away,           # [B, T, F]\n",
    "        home_team_idx, away_team_idx,  # [B]\n",
    "        home_players, away_players,    # [B, P] int64 with 0 as padding\n",
    "    ):\n",
    "        B = x_home.size(0)\n",
    "        device = x_home.device\n",
    "\n",
    "        # --- Encode team sequences ---\n",
    "        h_home_seq = self.encoder(x_home)   # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)   # [B, T, 2H]\n",
    "\n",
    "        home_seq_vec = h_home_seq.mean(dim=1)  # [B, 2H]\n",
    "        away_seq_vec = h_away_seq.mean(dim=1)\n",
    "\n",
    "        # --- Team ID embeddings ---\n",
    "        home_team_emb = self.team_embedding(home_team_idx)  # [B, D_t]\n",
    "        away_team_emb = self.team_embedding(away_team_idx)\n",
    "\n",
    "        # --- Initial team nodes in graph space ---\n",
    "        home_team_node = self.team_in(torch.cat([home_seq_vec, home_team_emb], dim=-1))\n",
    "        away_team_node = self.team_in(torch.cat([away_seq_vec, away_team_emb], dim=-1))\n",
    "\n",
    "        # --- Player embeddings / nodes ---\n",
    "        # home_players: [B, P] -> [B, P, D_p]\n",
    "        home_player_emb = self.player_embedding(home_players)  # padding_idx=0 → zeros where 0\n",
    "        away_player_emb = self.player_embedding(away_players)\n",
    "\n",
    "        home_player_node = self.player_in(home_player_emb)   # [B, P, G]\n",
    "        away_player_node = self.player_in(away_player_emb)\n",
    "\n",
    "        # --- Masks for real players (id != 0) ---\n",
    "        home_mask = (home_players != 0).unsqueeze(-1).float()  # [B, P, 1]\n",
    "        away_mask = (away_players != 0).unsqueeze(-1).float()\n",
    "\n",
    "        # Ensure padded players stay zero\n",
    "        home_player_node = home_player_node * home_mask\n",
    "        away_player_node = away_player_node * away_mask\n",
    "\n",
    "        # --- Message passing ---\n",
    "        for _ in range(self.gnn_steps):\n",
    "            # Players → Team: masked mean\n",
    "            home_count = home_mask.sum(dim=1).clamp(min=1.0)  # [B, 1]\n",
    "            away_count = away_mask.sum(dim=1).clamp(min=1.0)\n",
    "\n",
    "            home_players_mean = (home_player_node * home_mask).sum(dim=1) / home_count  # [B, G]\n",
    "            away_players_mean = (away_player_node * away_mask).sum(dim=1) / away_count\n",
    "\n",
    "            # Team update (residual)\n",
    "            home_team_msg = torch.cat([home_team_node, home_players_mean], dim=-1)  # [B, 2G]\n",
    "            away_team_msg = torch.cat([away_team_node, away_players_mean], dim=-1)\n",
    "\n",
    "            home_team_delta = F.relu(self.team_update(home_team_msg))\n",
    "            away_team_delta = F.relu(self.team_update(away_team_msg))\n",
    "\n",
    "            home_team_node = home_team_node + home_team_delta\n",
    "            away_team_node = away_team_node + away_team_delta\n",
    "\n",
    "            # Team → Players: broadcast team node to each player\n",
    "            home_team_broadcast = home_team_node.unsqueeze(1).expand_as(home_player_node)  # [B, P, G]\n",
    "            away_team_broadcast = away_team_node.unsqueeze(1).expand_as(away_player_node)\n",
    "\n",
    "            home_player_msg = torch.cat([home_player_node, home_team_broadcast], dim=-1)  # [B, P, 2G]\n",
    "            away_player_msg = torch.cat([away_player_node, away_team_broadcast], dim=-1)\n",
    "\n",
    "            home_player_delta = F.relu(self.player_update(home_player_msg))\n",
    "            away_player_delta = F.relu(self.player_update(away_player_msg))\n",
    "\n",
    "            # Residual + mask\n",
    "            home_player_node = (home_player_node + home_player_delta) * home_mask\n",
    "            away_player_node = (away_player_node + away_player_delta) * away_mask\n",
    "\n",
    "        # --- Final pooling of players ---\n",
    "        home_players_final = (home_player_node * home_mask).sum(dim=1) / home_count  # [B, G]\n",
    "        away_players_final = (away_player_node * away_mask).sum(dim=1) / away_count\n",
    "\n",
    "        # --- Final pairwise representation ---\n",
    "        pair_vec = torch.cat([\n",
    "            home_team_node,\n",
    "            away_team_node,\n",
    "            home_players_final,\n",
    "            away_players_final,\n",
    "        ], dim=-1)  # [B, 4G]\n",
    "\n",
    "        # new extra dropout\n",
    "        pair_vec = self.dropout(pair_vec)\n",
    "        y_pred = self.mlp(pair_vec)  # [B, 2]\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class ScorePredictorCrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        num_heads: int = 4,\n",
    "        num_teams: int = None,\n",
    "        team_emb_dim: int = 16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = hidden_size * 2  # BiLSTM\n",
    "        self.team_emb_dim = team_emb_dim\n",
    "\n",
    "        self.encoder = TeamSequenceEncoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        pair_input_dim = self.embed_dim * 2 + team_emb_dim * 2\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 2),  # [margin, total]\n",
    "        )\n",
    "\n",
    "    def forward(self, x_home, x_away, home_team_idx, away_team_idx):\n",
    "        # Encode sequences\n",
    "        h_home_seq = self.encoder(x_home)   # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)   # [B, T, 2H]\n",
    "\n",
    "        # Home attends to away\n",
    "        home_ctx, _ = self.cross_attn(\n",
    "            query=h_home_seq,\n",
    "            key=h_away_seq,\n",
    "            value=h_away_seq,\n",
    "        )\n",
    "\n",
    "        # Away attends to home\n",
    "        away_ctx, _ = self.cross_attn(\n",
    "            query=h_away_seq,\n",
    "            key=h_home_seq,\n",
    "            value=h_home_seq,\n",
    "        )\n",
    "\n",
    "        # Pool over time\n",
    "        home_vec = home_ctx.mean(dim=1)   # [B, 2H]\n",
    "        away_vec = away_ctx.mean(dim=1)   # [B, 2H]\n",
    "\n",
    "        # Team embeddings\n",
    "        home_emb = self.team_embedding(home_team_idx)  # [B, D]\n",
    "        away_emb = self.team_embedding(away_team_idx)  # [B, D]\n",
    "\n",
    "        pair_vec = torch.cat([home_vec, away_vec, home_emb, away_emb], dim=-1)\n",
    "        y_pred = self.mlp(pair_vec)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98e7c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train: bool = True, model=None, use_players: bool = False):\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"model not set\")\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for batch in loader:\n",
    "        #\n",
    "        # ---- UNPACK BASED ON FLAG ----\n",
    "        #\n",
    "        if use_players:\n",
    "            (\n",
    "                x_home, x_away, y,\n",
    "                home_idx, away_idx,\n",
    "                home_players, away_players,\n",
    "            ) = batch\n",
    "\n",
    "            x_home        = x_home.to(device)\n",
    "            x_away        = x_away.to(device)\n",
    "            y             = y.to(device)\n",
    "            home_idx      = home_idx.to(device)\n",
    "            away_idx      = away_idx.to(device)\n",
    "            home_players  = home_players.to(device)\n",
    "            away_players  = away_players.to(device)\n",
    "        else:\n",
    "            #\n",
    "            # batch may be length 5 or 7 depending on DataLoader\n",
    "            #\n",
    "            if len(batch) == 5:\n",
    "                x_home, x_away, y, home_idx, away_idx = batch\n",
    "            else:\n",
    "                # ignore extra fields if they exist\n",
    "                x_home, x_away, y, home_idx, away_idx, *_ = batch\n",
    "\n",
    "            x_home   = x_home.to(device)\n",
    "            x_away   = x_away.to(device)\n",
    "            y        = y.to(device)\n",
    "            home_idx = home_idx.to(device)\n",
    "            away_idx = away_idx.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            if use_players:\n",
    "                # 🧠 GNN-style model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                )\n",
    "            else:\n",
    "                # 🧠 non-player baseline model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                )\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        all_true.append(y.detach().cpu().numpy())\n",
    "        all_pred.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "\n",
    "    # Unscale BEFORE metrics\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    mae = mean_absolute_error(all_true_unscaled, all_pred_unscaled)\n",
    "    rmse = math.sqrt(mean_squared_error(all_true_unscaled, all_pred_unscaled))\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab37699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScorePredictorGNN(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(36, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(53, 16)\n",
      "  (player_embedding): Embedding(4832, 32, padding_idx=0)\n",
      "  (team_in): Linear(in_features=144, out_features=64, bias=True)\n",
      "  (player_in): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (team_update): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (player_update): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "ScorePredictorCrossAttention(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(36, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (cross_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(53, 16)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = len(SEQ_FEATURES)\n",
    "\n",
    "P = HOME_PLAYER_IDX.shape[1]   # 10 in your current setup\n",
    "\n",
    "model_a = ScorePredictorGNN(\n",
    "    input_size=input_size,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_teams=num_teams,\n",
    "    num_players=num_players,\n",
    "    team_emb_dim=16,\n",
    "    player_emb_dim=32,\n",
    "    gnn_hidden_dim=64,\n",
    "    gnn_steps=2,\n",
    ").to(device)\n",
    "\n",
    "model_b = ScorePredictorCrossAttention(\n",
    "    input_size=input_size,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=4,\n",
    "    num_teams=num_teams,\n",
    "    team_emb_dim=16,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(model_a)\n",
    "print(model_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb9bfbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.368, MAE 13.137, RMSE 17.024 | Val Loss 0.392, MAE 13.441, RMSE 17.153\n",
      "Epoch 02 | Train Loss 0.335, MAE 12.342, RMSE 16.017 | Val Loss 0.384, MAE 13.258, RMSE 16.930\n",
      "Epoch 03 | Train Loss 0.330, MAE 12.247, RMSE 15.851 | Val Loss 0.384, MAE 13.301, RMSE 16.968\n",
      "Epoch 04 | Train Loss 0.326, MAE 12.150, RMSE 15.732 | Val Loss 0.383, MAE 13.240, RMSE 16.881\n",
      "Epoch 05 | Train Loss 0.324, MAE 12.092, RMSE 15.656 | Val Loss 0.384, MAE 13.290, RMSE 16.963\n",
      "Epoch 06 | Train Loss 0.321, MAE 12.029, RMSE 15.588 | Val Loss 0.383, MAE 13.267, RMSE 16.934\n",
      "Epoch 07 | Train Loss 0.320, MAE 12.011, RMSE 15.552 | Val Loss 0.386, MAE 13.350, RMSE 17.025\n",
      "Epoch 08 | Train Loss 0.316, MAE 11.903, RMSE 15.425 | Val Loss 0.384, MAE 13.296, RMSE 16.959\n",
      "Epoch 09 | Train Loss 0.314, MAE 11.879, RMSE 15.411 | Val Loss 0.384, MAE 13.291, RMSE 16.944\n",
      "Epoch 10 | Train Loss 0.314, MAE 11.865, RMSE 15.399 | Val Loss 0.384, MAE 13.303, RMSE 16.955\n",
      "Epoch 11 | Train Loss 0.311, MAE 11.799, RMSE 15.319 | Val Loss 0.386, MAE 13.349, RMSE 17.015\n",
      "Epoch 12 | Train Loss 0.310, MAE 11.757, RMSE 15.275 | Val Loss 0.387, MAE 13.389, RMSE 17.063\n",
      "Epoch 13 | Train Loss 0.310, MAE 11.764, RMSE 15.285 | Val Loss 0.391, MAE 13.488, RMSE 17.199\n",
      "Epoch 14 | Train Loss 0.308, MAE 11.720, RMSE 15.234 | Val Loss 0.387, MAE 13.379, RMSE 17.047\n",
      "Epoch 15 | Train Loss 0.308, MAE 11.714, RMSE 15.220 | Val Loss 0.387, MAE 13.369, RMSE 17.030\n",
      "Epoch 16 | Train Loss 0.308, MAE 11.725, RMSE 15.244 | Val Loss 0.388, MAE 13.404, RMSE 17.074\n",
      "Epoch 17 | Train Loss 0.307, MAE 11.687, RMSE 15.205 | Val Loss 0.388, MAE 13.399, RMSE 17.070\n",
      "Epoch 18 | Train Loss 0.308, MAE 11.706, RMSE 15.219 | Val Loss 0.388, MAE 13.397, RMSE 17.064\n",
      "Epoch 19 | Train Loss 0.306, MAE 11.666, RMSE 15.177 | Val Loss 0.390, MAE 13.450, RMSE 17.134\n",
      "Epoch 20 | Train Loss 0.306, MAE 11.671, RMSE 15.168 | Val Loss 0.389, MAE 13.426, RMSE 17.102\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_a.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',      # lower RMSE is better\n",
    "    factor=0.5,      # reduce LR by half\n",
    "    patience=2,      # wait 2 epochs before dropping LR\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_a, use_players=True\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_a, use_players=True\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 🔥 IMPORTANT → Notify the scheduler\n",
    "    scheduler.step(val_rmse)  # or val_loss if you prefer loss\n",
    "\n",
    "    # 🔥 Standard early stopping capture\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_a.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c19adcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.360, MAE 12.869, RMSE 16.644\n"
     ]
    }
   ],
   "source": [
    "model_a.load_state_dict(best_state)\n",
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_a, use_players=True)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "385a6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.380, MAE 13.461, RMSE 17.379 | Val Loss 0.405, MAE 13.668, RMSE 17.421\n",
      "Epoch 02 | Train Loss 0.351, MAE 12.705, RMSE 16.356 | Val Loss 0.392, MAE 13.407, RMSE 17.136\n",
      "Epoch 03 | Train Loss 0.335, MAE 12.358, RMSE 15.990 | Val Loss 0.384, MAE 13.226, RMSE 16.911\n",
      "Epoch 04 | Train Loss 0.332, MAE 12.274, RMSE 15.869 | Val Loss 0.386, MAE 13.298, RMSE 17.022\n",
      "Epoch 05 | Train Loss 0.330, MAE 12.242, RMSE 15.830 | Val Loss 0.382, MAE 13.201, RMSE 16.874\n",
      "Epoch 06 | Train Loss 0.328, MAE 12.200, RMSE 15.778 | Val Loss 0.382, MAE 13.184, RMSE 16.849\n",
      "Epoch 07 | Train Loss 0.328, MAE 12.171, RMSE 15.762 | Val Loss 0.384, MAE 13.234, RMSE 16.923\n",
      "Epoch 08 | Train Loss 0.327, MAE 12.154, RMSE 15.726 | Val Loss 0.382, MAE 13.197, RMSE 16.871\n",
      "Epoch 09 | Train Loss 0.326, MAE 12.137, RMSE 15.699 | Val Loss 0.382, MAE 13.202, RMSE 16.889\n",
      "Epoch 10 | Train Loss 0.324, MAE 12.091, RMSE 15.648 | Val Loss 0.383, MAE 13.209, RMSE 16.890\n",
      "Epoch 11 | Train Loss 0.324, MAE 12.095, RMSE 15.642 | Val Loss 0.382, MAE 13.207, RMSE 16.885\n",
      "Epoch 12 | Train Loss 0.324, MAE 12.078, RMSE 15.637 | Val Loss 0.383, MAE 13.205, RMSE 16.890\n",
      "Epoch 13 | Train Loss 0.323, MAE 12.076, RMSE 15.623 | Val Loss 0.383, MAE 13.213, RMSE 16.898\n",
      "Epoch 14 | Train Loss 0.322, MAE 12.055, RMSE 15.602 | Val Loss 0.383, MAE 13.218, RMSE 16.905\n",
      "Epoch 15 | Train Loss 0.322, MAE 12.051, RMSE 15.591 | Val Loss 0.383, MAE 13.207, RMSE 16.886\n",
      "Epoch 16 | Train Loss 0.322, MAE 12.052, RMSE 15.596 | Val Loss 0.383, MAE 13.215, RMSE 16.899\n",
      "Epoch 17 | Train Loss 0.321, MAE 12.027, RMSE 15.593 | Val Loss 0.383, MAE 13.214, RMSE 16.896\n",
      "Epoch 18 | Train Loss 0.321, MAE 12.034, RMSE 15.585 | Val Loss 0.383, MAE 13.223, RMSE 16.912\n",
      "Epoch 19 | Train Loss 0.322, MAE 12.047, RMSE 15.600 | Val Loss 0.383, MAE 13.214, RMSE 16.896\n",
      "Epoch 20 | Train Loss 0.321, MAE 12.026, RMSE 15.572 | Val Loss 0.383, MAE 13.217, RMSE 16.902\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL B\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_b.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',      # lower RMSE is better\n",
    "    factor=0.5,      # reduce LR by half\n",
    "    patience=2,      # wait 2 epochs before dropping LR\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_b, use_players=False\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_b, use_players=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 🔥 IMPORTANT → Notify the scheduler\n",
    "    scheduler.step(val_rmse)  # or val_loss if you prefer loss\n",
    "\n",
    "    # 🔥 Standard early stopping capture\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_b.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b74ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.351, MAE 12.626, RMSE 16.375\n"
     ]
    }
   ],
   "source": [
    "model_b.load_state_dict(best_state)\n",
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_b, use_players=False)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ad7da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant baseline | MAE 16.986, RMSE 22.370\n"
     ]
    }
   ],
   "source": [
    "# Using your train split\n",
    "\n",
    "\n",
    "def evaluate_constant_baseline(Y_true, const_pred):\n",
    "    const = np.tile(const_pred, (Y_true.shape[0], 1))\n",
    "    mae = mean_absolute_error(Y_true, const)\n",
    "    rmse = math.sqrt(mean_squared_error(Y_true, const))\n",
    "    return mae, rmse\n",
    "\n",
    "baseline_mae, baseline_rmse = evaluate_constant_baseline(Y_test_raw, train_mean_scores)\n",
    "print(f\"Constant baseline | MAE {baseline_mae:.3f}, RMSE {baseline_rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ea930d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A winner accuracy: 61.377%\n",
      "Model B winner accuracy: 60.942%\n",
      "Model A margin accuracy (within 5 points): 29.203%\n",
      "Model B margin accuracy (within 5 points): 29.855%\n",
      "Model A totals accuracy (within 5 points): 20.870%\n",
      "Model B totals accuracy (within 5 points): 22.971%\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, loader, use_players: bool):\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if use_players:\n",
    "                # New dataset: 7-tuple\n",
    "                (\n",
    "                    x_home, x_away, y,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                ) = batch\n",
    "\n",
    "                x_home = x_home.to(device)\n",
    "                x_away = x_away.to(device)\n",
    "                y = y.to(device)\n",
    "                home_idx = home_idx.to(device)\n",
    "                away_idx = away_idx.to(device)\n",
    "                home_players = home_players.to(device)\n",
    "                away_players = away_players.to(device)\n",
    "\n",
    "                # ✅ GNN / player-aware model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # Old models (5-input), but handle both 5- and 7-tuples gracefully\n",
    "                if len(batch) == 5:\n",
    "                    x_home, x_away, y, home_idx, away_idx = batch\n",
    "                elif len(batch) >= 7:\n",
    "                    x_home, x_away, y, home_idx, away_idx, *_ = batch\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "\n",
    "                x_home = x_home.to(device)\n",
    "                x_away = x_away.to(device)\n",
    "                y = y.to(device)\n",
    "                home_idx = home_idx.to(device)\n",
    "                away_idx = away_idx.to(device)\n",
    "\n",
    "                # ✅ old MLP / cross-attn model\n",
    "                y_pred = model(x_home, x_away, home_idx, away_idx)\n",
    "\n",
    "            all_true.append(y.cpu().numpy())\n",
    "            all_pred.append(y_pred.cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)  # scaled\n",
    "    all_pred = np.concatenate(all_pred, axis=0)  # scaled\n",
    "\n",
    "    # Unscale before returning\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    return all_true_unscaled, all_pred_unscaled\n",
    "\n",
    "\n",
    "Y_true_test, Y_pred_a = get_predictions(model_a, test_loader, use_players=True)\n",
    "_, Y_pred_b = get_predictions(model_b, test_loader, use_players=False)\n",
    "\n",
    "\n",
    "# True margin/total\n",
    "true_margin = Y_true_test[:, 0]\n",
    "true_total  = Y_true_test[:, 1]\n",
    "\n",
    "# Reconstruct true scores\n",
    "true_home = (true_total + true_margin) / 2\n",
    "true_away = (true_total - true_margin) / 2\n",
    "\n",
    "# Model A margin/total\n",
    "pred_margin_a = Y_pred_a[:, 0]\n",
    "pred_total_a  = Y_pred_a[:, 1]\n",
    "pred_home_a   = (pred_total_a + pred_margin_a) / 2\n",
    "pred_away_a   = (pred_total_a - pred_margin_a) / 2\n",
    "\n",
    "# Model B margin/total\n",
    "pred_margin_b = Y_pred_b[:, 0]\n",
    "pred_total_b  = Y_pred_b[:, 1]\n",
    "pred_home_b   = (pred_total_b + pred_margin_b) / 2\n",
    "pred_away_b   = (pred_total_b - pred_margin_b) / 2\n",
    "\n",
    "\n",
    "def winner_accuracy(y_true, y_pred):\n",
    "    true_margin = y_true[:, 0]\n",
    "    pred_margin = y_pred[:, 0]\n",
    "    return ((true_margin > 0) == (pred_margin > 0)).mean()\n",
    "\n",
    "def margin_accuracy(y_true, y_pred):\n",
    "    true_margin = y_true[:, 0]\n",
    "    pred_margin = y_pred[:, 0]\n",
    "    return (np.abs(true_margin - pred_margin) < 5).mean()\n",
    "\n",
    "def totals_accuracy(y_true, y_pred):\n",
    "    true_total = y_true[:, 1]\n",
    "    pred_total = y_pred[:, 1]\n",
    "    return (np.abs(true_total - pred_total) < 5).mean()\n",
    "\n",
    "\n",
    "acc_a = winner_accuracy(Y_true_test, Y_pred_a)\n",
    "acc_b = winner_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A winner accuracy: {acc_a:.3%}\")\n",
    "print(f\"Model B winner accuracy: {acc_b:.3%}\")\n",
    "\n",
    "margin_a = margin_accuracy(Y_true_test, Y_pred_a)\n",
    "margin_b = margin_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A margin accuracy (within 5 points): {margin_a:.3%}\")\n",
    "print(f\"Model B margin accuracy (within 5 points): {margin_b:.3%}\")\n",
    "\n",
    "total_a = totals_accuracy(Y_true_test, Y_pred_a)\n",
    "total_b = totals_accuracy(Y_true_test, Y_pred_b)\n",
    "print(f\"Model A totals accuracy (within 5 points): {total_a:.3%}\")\n",
    "print(f\"Model B totals accuracy (within 5 points): {total_b:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3f77994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_betting = pd.read_csv(f'{DATA_DIR}/nba_2008-2025.csv')\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "df_betting = df_betting[df_betting['game_date'] >= ERA_START].reset_index(drop=True)\n",
    "\n",
    "team_df = pd.read_csv(os.path.join(DATA_DIR, 'team.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3992c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_map = dict(zip(team_df['id'], team_df['nickname']))\n",
    "\n",
    "test_indices = np.where(test_mask)[0]\n",
    "test_game_indices = []\n",
    "\n",
    "# Rebuild to track which games_full indices match test_mask\n",
    "idx = 0\n",
    "for i, row in games_full.iterrows():\n",
    "    gid = row[GAME_ID_COL]\n",
    "    home_id = row[\"home_team_id\"]\n",
    "    away_id = row[\"away_team_id\"]\n",
    "    date = row[GAME_DATE_COL]\n",
    "\n",
    "    key_home = (gid, home_id)\n",
    "    key_away = (gid, away_id)\n",
    "\n",
    "    if key_home not in seq_index_by_game_team or key_away not in seq_index_by_game_team:\n",
    "        continue\n",
    "    \n",
    "    # This game is in our dataset\n",
    "    if pd.to_datetime(date) >= TEST_SPLIT_DATE:\n",
    "        test_game_indices.append(i)\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "# Build test_predictions_df with correct games_full rows\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    'game_date': games_full.iloc[test_game_indices][GAME_DATE_COL].values,\n",
    "    'home_team': [team_map.get(games_full.iloc[i]['home_team_id'], 'UNK') \n",
    "                  for i in test_game_indices],\n",
    "    'away_team': [team_map.get(games_full.iloc[i]['away_team_id'], 'UNK') \n",
    "                  for i in test_game_indices],\n",
    "    'y_home': true_home,\n",
    "    'y_away': true_away,\n",
    "    'pred_home_a': pred_home_a,\n",
    "    'pred_away_a': pred_away_a,\n",
    "    'pred_home_b': pred_home_b,\n",
    "    'pred_away_b': pred_away_b,\n",
    "}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e60b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       game_date whos_favored  spread      home_team away_team\n",
      "0     2010-10-26         away    -1.0        Celtics      Heat\n",
      "1     2010-10-26         home     7.0  Trail Blazers      Suns\n",
      "2     2010-10-26         home     6.5         Lakers   Rockets\n",
      "3     2010-10-27         home     4.0           Nets   Pistons\n",
      "4     2010-10-27         away    -4.5      Cavaliers   Celtics\n",
      "...          ...          ...     ...            ...       ...\n",
      "19170 2025-06-11         away    -4.5         Pacers   Thunder\n",
      "19171 2025-06-13         away    -6.5         Pacers   Thunder\n",
      "19172 2025-06-16         home     8.5        Thunder    Pacers\n",
      "19173 2025-06-19         away    -5.5         Pacers   Thunder\n",
      "19174 2025-06-22         home     6.5        Thunder    Pacers\n",
      "\n",
      "[19175 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'atl': 'Hawks',\n",
    "    'bos': 'Celtics',\n",
    "    'bkn': 'Nets',\n",
    "    'cha': 'Hornets',\n",
    "    'chi': 'Bulls',\n",
    "    'cle': 'Cavaliers',\n",
    "    'dal': 'Mavericks',\n",
    "    'den': 'Nuggets',\n",
    "    'det': 'Pistons',\n",
    "    'gs': 'Warriors',\n",
    "    'hou': 'Rockets',\n",
    "    'ind': 'Pacers',\n",
    "    'lac': 'Clippers',\n",
    "    'lal': 'Lakers',\n",
    "    'mem': 'Grizzlies',\n",
    "    'mia': 'Heat',\n",
    "    'mil': 'Bucks',\n",
    "    'min': 'Timberwolves',\n",
    "    'no': 'Pelicans',\n",
    "    'ny': 'Knicks',\n",
    "    'okc': 'Thunder',\n",
    "    'orl': 'Magic',\n",
    "    'phi': '76ers',\n",
    "    'phx': 'Suns',\n",
    "    'por': 'Trail Blazers',\n",
    "    'sac': 'Kings',\n",
    "    'sa': 'Spurs',\n",
    "    'tor': 'Raptors',\n",
    "    'utah': 'Jazz',\n",
    "    'wsh': 'Wizards'\n",
    "}\n",
    "\n",
    "df_betting['away_team'] = df_betting['away'].map(abbreviation_mapping)\n",
    "df_betting['home_team'] = df_betting['home'].map(abbreviation_mapping)\n",
    "# Rename date to game_date to match test_predictions_df\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "# Convert the spread to negative if the away team is favored\n",
    "df_betting['spread'] = df_betting.apply(\n",
    "    lambda row: -row['spread'] if 'away' == row['whos_favored'] else row['spread'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Print modified columns for verification\n",
    "print(df_betting[['game_date', 'whos_favored', 'spread', 'home_team', 'away_team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9009931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged betting data shape: (1314, 36)\n"
     ]
    }
   ],
   "source": [
    "# Merge betting data with test predictions on date, home_team, away_team\n",
    "merged_df = pd.merge(\n",
    "    test_predictions_df,\n",
    "    df_betting,\n",
    "    on=['game_date', 'home_team', 'away_team'],\n",
    "    how='inner'\n",
    ")\n",
    "print(\"Merged betting data shape:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cf1dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A Spread Record (W-L-P): {'W': 664, 'L': 637, 'P': 13}\n",
      "Model A Total Record (W-L-P): {'W': 670, 'L': 635, 'P': 9}\n",
      "Model B Spread Record (W-L-P): {'W': 659, 'L': 642, 'P': 13}\n",
      "Model B Total Record (W-L-P): {'W': 673, 'L': 632, 'P': 9}\n"
     ]
    }
   ],
   "source": [
    "def predict_betting_results(df):\n",
    "    \"\"\"\n",
    "    The spread will always be from the home team's perspective, if it is negative the away team is favored.\n",
    "    The total is the combined score of both teams.\n",
    "\n",
    "    Returns:\n",
    "        spread_record_a: wins-losses-pushes for model A spread bets\n",
    "        total_record_a: wins-losses-pushes for model A total bets\n",
    "        spread_record_b: wins-losses-pushes for model B spread bets\n",
    "        total_record_b: wins-losses-pushes for model B total bets\n",
    "    \"\"\"\n",
    "    for game in df:\n",
    "        # Model A predictions\n",
    "        pred_home_a = game['pred_home_a']\n",
    "        pred_away_a = game['pred_away_a']\n",
    "        pred_margin_a = pred_home_a - pred_away_a\n",
    "        pred_total_a = pred_home_a + pred_away_a\n",
    "\n",
    "        # Model B predictions\n",
    "        pred_home_b = game['pred_home_b']\n",
    "        pred_away_b = game['pred_away_b']\n",
    "        pred_margin_b = pred_home_b - pred_away_b\n",
    "        pred_total_b = pred_home_b + pred_away_b\n",
    "\n",
    "        # Actual results\n",
    "        actual_home = game['y_home']\n",
    "        actual_away = game['y_away']\n",
    "        actual_margin = actual_home - actual_away\n",
    "        actual_total = actual_home + actual_away\n",
    "\n",
    "        spread = game['spread']\n",
    "        total_line = game['total']\n",
    "\n",
    "        # Spread bet results for Model A\n",
    "        if (spread) > 0: # Home team Favoured\n",
    "            if (actual_margin - spread) > 0: # If home team covers\n",
    "                if (pred_margin_a - spread) > 0: # Predicted home team covers\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            elif (actual_margin - spread) < 0: # If home team fails to cover\n",
    "                if (pred_margin_a - spread) < 0: # Predicted home team fails to cover\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_a'] = 'P'\n",
    "        elif (spread) < 0: # Away team Favoured\n",
    "            if (actual_margin - spread) < 0: # If away team covers\n",
    "                if (pred_margin_a - spread) < 0: # Predicted away team covers\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            elif (actual_margin - spread) > 0: # If away team fails to cover\n",
    "                if (pred_margin_a - spread) > 0: # Predicted away team fails to cover\n",
    "                    game['spread_result_a'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_a'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_a'] = 'P'\n",
    "        else: # Spread is 0, no favorite\n",
    "            if actual_margin > 0 and pred_margin_a > 0: # Home team wins, predicted home team wins\n",
    "                game['spread_result_a'] = 'W'\n",
    "            elif actual_margin < 0 and pred_margin_a < 0: # Away team wins, predicted away team wins\n",
    "                game['spread_result_a'] = 'W'\n",
    "            else: # One team wins, predicted the other team wins\n",
    "                game['spread_result_a'] = 'L'\n",
    "\n",
    "\n",
    "         # Spread bet results for Model B\n",
    "        if (spread) > 0: # Home team Favoured\n",
    "            if (actual_margin - spread) > 0: # If home team covers\n",
    "                if (pred_margin_b - spread) > 0: # Predicted home team covers\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            elif (actual_margin - spread) < 0: # If home team fails to cover\n",
    "                if (pred_margin_b - spread) < 0: # Predicted home team fails to cover\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_b'] = 'P'\n",
    "        elif (spread) < 0: # Away team Favoured\n",
    "            if (actual_margin - spread) < 0: # If away team covers\n",
    "                if (pred_margin_b - spread) < 0: # Predicted away team covers\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            elif (actual_margin - spread) > 0: # If away team fails to cover\n",
    "                if (pred_margin_b - spread) > 0: # Predicted away team fails to cover\n",
    "                    game['spread_result_b'] = 'W'\n",
    "                else:\n",
    "                    game['spread_result_b'] = 'L'\n",
    "            else: # Push\n",
    "                game['spread_result_b'] = 'P'\n",
    "        else: # Spread is 0, no favorite\n",
    "            if actual_margin > 0 and pred_margin_a > 0: # Home team wins, predicted home team wins\n",
    "                game['spread_result_b'] = 'W'\n",
    "            elif actual_margin < 0 and pred_margin_a < 0: # Away team wins, predicted away team wins\n",
    "                game['spread_result_b'] = 'W'\n",
    "            else: # One team wins, predicted the other team wins\n",
    "                game['spread_result_b'] = 'L'\n",
    "\n",
    "        # Total bet results for Model A\n",
    "        if (actual_total > total_line): # Over pays\n",
    "            if (pred_total_a > total_line):\n",
    "                game['total_result_a'] = 'W'\n",
    "            else:\n",
    "                game['total_result_a'] = 'L'\n",
    "        elif (actual_total < total_line): # Under Pays\n",
    "            if (pred_total_a < total_line):\n",
    "                game['total_result_a'] = 'W'\n",
    "            else:\n",
    "                game['total_result_a'] = 'L'\n",
    "        else: # Push = Exactly on the total line, bet refunded\n",
    "            game['total_result_a'] = 'P'\n",
    "\n",
    "        # Total bet results for Model B\n",
    "        if (actual_total > total_line): # Over pays\n",
    "            if (pred_total_b > total_line):\n",
    "                game['total_result_b'] = 'W'\n",
    "            else:\n",
    "                game['total_result_b'] = 'L'\n",
    "        elif (actual_total < total_line): # Under Pays\n",
    "            if (pred_total_b < total_line):\n",
    "                game['total_result_b'] = 'W'\n",
    "            else:\n",
    "                game['total_result_b'] = 'L'\n",
    "        else: # Push = Exactly on the total line, bet refunded\n",
    "            game['total_result_b'] = 'P'\n",
    "            \n",
    "    # Calculate records\n",
    "    spread_record_a = {'W': 0, 'L': 0, 'P': 0}\n",
    "    total_record_a = {'W': 0, 'L': 0, 'P': 0}\n",
    "    spread_record_b = {'W': 0, 'L': 0, 'P': 0}\n",
    "    total_record_b = {'W': 0, 'L': 0, 'P': 0}\n",
    "    for game in df:\n",
    "        spread_record_a[game['spread_result_a']] += 1\n",
    "        total_record_a[game['total_result_a']] += 1\n",
    "        spread_record_b[game['spread_result_b']] += 1\n",
    "        total_record_b[game['total_result_b']] += 1\n",
    "    return spread_record_a, total_record_a, spread_record_b, total_record_b\n",
    "\n",
    "spread_record_a, total_record_a, spread_record_b, total_record_b = predict_betting_results(merged_df.to_dict('records'))\n",
    "print(\"Model A Spread Record (W-L-P):\", spread_record_a)\n",
    "print(\"Model A Total Record (W-L-P):\", total_record_a)\n",
    "print(\"Model B Spread Record (W-L-P):\", spread_record_b)\n",
    "print(\"Model B Total Record (W-L-P):\", total_record_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fde74b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model Bet Type  Wins  Losses  Pushes  Win Ratio\n",
      "0     A   Spread   664     637      13   0.510377\n",
      "1     A    Total   670     635       9   0.513410\n",
      "2     B   Spread   659     642      13   0.506533\n",
      "3     B    Total   673     632       9   0.515709\n"
     ]
    }
   ],
   "source": [
    "# create a summary betting DF\n",
    "betting_summary = pd.DataFrame({\n",
    "    'Model': ['A', 'A', 'B', 'B'],\n",
    "    'Bet Type': ['Spread', 'Total', 'Spread', 'Total'],\n",
    "    'Wins': [spread_record_a['W'], total_record_a['W'], spread_record_b['W'], total_record_b['W']],\n",
    "    'Losses': [spread_record_a['L'], total_record_a['L'], spread_record_b['L'], total_record_b['L']],\n",
    "    'Pushes': [spread_record_a['P'], total_record_a['P'], spread_record_b['P'], total_record_b['P']],\n",
    "    'Win Ratio': [\n",
    "        spread_record_a['W'] / (spread_record_a['W'] + spread_record_a['L']),\n",
    "        total_record_a['W'] / (total_record_a['W'] + total_record_a['L']),\n",
    "        spread_record_b['W'] / (spread_record_b['W'] + spread_record_b['L']),\n",
    "        total_record_b['W'] / (total_record_b['W'] + total_record_b ['L']),\n",
    "    ]\n",
    "})\n",
    "print(betting_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eaf0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
