{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267c7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports & config\n",
    "\n",
    "\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead36b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"./data/csv\"\n",
    "\n",
    "# add the kaggel data csv files in the above dir.\n",
    "# https://www.kaggle.com/datasets/wyattowalsh/basketball\n",
    "# https://www.kaggle.com/datasets/cviaxmiwnptr/nba-betting-data-october-2007-to-june-2024\n",
    "# (too large for d2l)\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LEN = 15              # number of past games per team\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "ERA_START = pd.to_datetime(\"2016-10-01\")\n",
    "VAL_SPLIT_DATE = \"2021-10-01\"\n",
    "TEST_SPLIT_DATE = \"2022-10-01\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56555458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== common_player_info.csv ===\n",
      "shape: (4171, 33)\n",
      "columns: ['person_id', 'first_name', 'last_name', 'display_first_last', 'display_last_comma_first', 'display_fi_last', 'player_slug', 'birthdate', 'school', 'country', 'last_affiliation', 'height', 'weight', 'season_exp', 'jersey'] ...\n",
      "\n",
      "=== game_info.csv ===\n",
      "shape: (58053, 4)\n",
      "columns: ['game_id', 'game_date', 'attendance', 'game_time'] ...\n",
      "\n",
      "=== officials.csv ===\n",
      "shape: (70971, 5)\n",
      "columns: ['game_id', 'official_id', 'first_name', 'last_name', 'jersey_num'] ...\n",
      "\n",
      "=== team.csv ===\n",
      "shape: (30, 7)\n",
      "columns: ['id', 'full_name', 'abbreviation', 'nickname', 'city', 'state', 'year_founded'] ...\n",
      "\n",
      "=== draft_combine_stats.csv ===\n",
      "shape: (1202, 47)\n",
      "columns: ['season', 'player_id', 'first_name', 'last_name', 'player_name', 'position', 'height_wo_shoes', 'height_wo_shoes_ft_in', 'height_w_shoes', 'height_w_shoes_ft_in', 'weight', 'wingspan', 'wingspan_ft_in', 'standing_reach', 'standing_reach_ft_in'] ...\n",
      "\n",
      "=== game_summary.csv ===\n",
      "shape: (58110, 14)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'game_status_id', 'game_status_text', 'gamecode', 'home_team_id', 'visitor_team_id', 'season', 'live_period', 'live_pc_time', 'natl_tv_broadcaster_abbreviation', 'live_period_time_bcast', 'wh_status'] ...\n",
      "\n",
      "=== other_stats.csv ===\n",
      "shape: (28271, 26)\n",
      "columns: ['game_id', 'league_id', 'team_id_home', 'team_abbreviation_home', 'team_city_home', 'pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home'] ...\n",
      "\n",
      "=== team_details.csv ===\n",
      "shape: (25, 14)\n",
      "columns: ['team_id', 'abbreviation', 'nickname', 'yearfounded', 'city', 'arena', 'arenacapacity', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'facebook', 'instagram', 'twitter'] ...\n",
      "\n",
      "=== draft_history.csv ===\n",
      "shape: (7990, 14)\n",
      "columns: ['person_id', 'player_name', 'season', 'round_number', 'round_pick', 'overall_pick', 'draft_type', 'team_id', 'team_city', 'team_name', 'team_abbreviation', 'organization', 'organization_type', 'player_profile_flag'] ...\n",
      "\n",
      "=== inactive_players.csv ===\n",
      "shape: (110191, 9)\n",
      "columns: ['game_id', 'player_id', 'first_name', 'last_name', 'jersey_num', 'team_id', 'team_city', 'team_name', 'team_abbreviation'] ...\n",
      "\n",
      "=== play_by_play.csv ===\n",
      "shape: (13592899, 34)\n",
      "columns: ['game_id', 'eventnum', 'eventmsgtype', 'eventmsgactiontype', 'period', 'wctimestring', 'pctimestring', 'homedescription', 'neutraldescription', 'visitordescription', 'score', 'scoremargin', 'person1type', 'player1_id', 'player1_name'] ...\n",
      "\n",
      "=== team_history.csv ===\n",
      "shape: (52, 5)\n",
      "columns: ['team_id', 'city', 'nickname', 'year_founded', 'year_active_till'] ...\n",
      "\n",
      "=== game.csv ===\n",
      "shape: (65698, 55)\n",
      "columns: ['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home', 'game_id', 'game_date', 'matchup_home', 'wl_home', 'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home'] ...\n",
      "\n",
      "=== line_score.csv ===\n",
      "shape: (58053, 43)\n",
      "columns: ['game_date_est', 'game_sequence', 'game_id', 'team_id_home', 'team_abbreviation_home', 'team_city_name_home', 'team_nickname_home', 'team_wins_losses_home', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home', 'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home'] ...\n",
      "\n",
      "=== player.csv ===\n",
      "shape: (4831, 5)\n",
      "columns: ['id', 'full_name', 'first_name', 'last_name', 'is_active'] ...\n",
      "\n",
      "=== team_info_common.csv ===\n",
      "shape: (0, 26)\n",
      "columns: ['team_id', 'season_year', 'team_city', 'team_name', 'team_abbreviation', 'team_conference', 'team_division', 'team_code', 'team_slug', 'w', 'l', 'pct', 'conf_rank', 'div_rank', 'min_year'] ...\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    \"common_player_info.csv\",\n",
    "    \"game_info.csv\",\n",
    "    \"officials.csv\",\n",
    "    \"team.csv\",\n",
    "    \"draft_combine_stats.csv\",\n",
    "    \"game_summary.csv\",\n",
    "    \"other_stats.csv\",\n",
    "    \"team_details.csv\",\n",
    "    \"draft_history.csv\",\n",
    "    \"inactive_players.csv\",\n",
    "    \"play_by_play.csv\",\n",
    "    \"team_history.csv\",\n",
    "    \"game.csv\",\n",
    "    \"line_score.csv\",\n",
    "    \"player.csv\",\n",
    "    \"team_info_common.csv\",\n",
    "]\n",
    "\n",
    "for fname in files:\n",
    "    path = os.path.join(DATA_DIR, fname)\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\n=== {fname} ===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(\"columns:\", list(df.columns)[:15], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd2417f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games: (65698, 55)\n",
      "game_info: (58053, 4)\n",
      "other_stats: (28271, 26)\n"
     ]
    }
   ],
   "source": [
    "# Core tables for modeling\n",
    "games = pd.read_csv(os.path.join(DATA_DIR, \"game.csv\"))\n",
    "game_info = pd.read_csv(os.path.join(DATA_DIR, \"game_info.csv\"))\n",
    "other_stats = pd.read_csv(os.path.join(DATA_DIR, \"other_stats.csv\"))\n",
    "\n",
    "print(\"games:\", games.shape)\n",
    "print(\"game_info:\", game_info.shape)\n",
    "print(\"other_stats:\", other_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd257c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_df: (4831, 5)\n",
      "common_player_info: (4171, 33)\n",
      "play_by_play: (13592899, 34)\n",
      "num_players (including padding): 4832\n"
     ]
    }
   ],
   "source": [
    "# --- Player-level tables ---\n",
    "player_df = pd.read_csv(os.path.join(DATA_DIR, \"player.csv\"))\n",
    "common_player_info = pd.read_csv(os.path.join(DATA_DIR, \"common_player_info.csv\"))\n",
    "play_by_play = pd.read_csv(os.path.join(DATA_DIR, \"play_by_play.csv\"))\n",
    "\n",
    "print(\"player_df:\", player_df.shape)\n",
    "print(\"common_player_info:\", common_player_info.shape)\n",
    "print(\"play_by_play:\", play_by_play.shape)\n",
    "\n",
    "# Player ID mapping (reserve 0 for padding / unknown)\n",
    "player_ids = sorted(player_df[\"id\"].unique())\n",
    "player_id_to_idx = {pid: i + 1 for i, pid in enumerate(player_ids)}\n",
    "num_players = len(player_ids) + 1  # +1 for padding index 0\n",
    "\n",
    "print(\"num_players (including padding):\", num_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47f7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column config for our pipeline\n",
    "GAME_ID_COL = \"game_id\"\n",
    "GAME_DATE_COL = \"game_date\"\n",
    "HOME_TEAM_COL = \"team_id_home\"\n",
    "AWAY_TEAM_COL = \"team_id_away\"\n",
    "PTS_HOME_COL = \"pts_home\"\n",
    "PTS_AWAY_COL = \"pts_away\"\n",
    "\n",
    "# Make sure game_date is datetime\n",
    "games[GAME_DATE_COL] = pd.to_datetime(games[GAME_DATE_COL])\n",
    "game_info[\"game_date\"] = pd.to_datetime(game_info[\"game_date\"])\n",
    "\n",
    "# Keep only modern-era games\n",
    "mask_games = games[GAME_DATE_COL] >= ERA_START\n",
    "games = games.loc[mask_games].reset_index(drop=True)\n",
    "\n",
    "# Match game_info to the same window\n",
    "mask_info = game_info[\"game_date\"] >= ERA_START\n",
    "game_info = game_info.loc[mask_info].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db22d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Restrict PBP to games in our modeling window ---\n",
    "valid_game_ids = set(games[GAME_ID_COL].unique())\n",
    "play_by_play = play_by_play[play_by_play[\"game_id\"].isin(valid_game_ids)].copy()\n",
    "\n",
    "# Attach home/away team IDs to each pbp row\n",
    "games_for_merge = games[[GAME_ID_COL, HOME_TEAM_COL, AWAY_TEAM_COL]].drop_duplicates()\n",
    "play_by_play = play_by_play.merge(games_for_merge, on=GAME_ID_COL, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b9c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_games (per game/team/player): (249022, 4)\n",
      "    game_id     team_id  player_id  event_count\n",
      "0  11600001  1610612744       2561           19\n",
      "1  11600001  1610612744       2585           10\n",
      "2  11600001  1610612744       2733           12\n",
      "3  11600001  1610612744       2738            8\n",
      "4  11600001  1610612744       2760            6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Infer team_id for each event where we have a player1_id\n",
    "def infer_team(row):\n",
    "    # home side event if homedescription is non-null\n",
    "    if pd.notna(row.get(\"homedescription\")) and row[\"homedescription\"] != \"\":\n",
    "        return row[HOME_TEAM_COL]\n",
    "    # visitor side event if visitordescription is non-null\n",
    "    if pd.notna(row.get(\"visitordescription\")) and row[\"visitordescription\"] != \"\":\n",
    "        return row[AWAY_TEAM_COL]\n",
    "    return np.nan\n",
    "\n",
    "play_by_play[\"team_id_event\"] = play_by_play.apply(infer_team, axis=1)\n",
    "\n",
    "# Keep only rows where we can assign team + player\n",
    "pbp_players = play_by_play.dropna(subset=[\"team_id_event\", \"player1_id\"]).copy()\n",
    "pbp_players[\"team_id_event\"] = pbp_players[\"team_id_event\"].astype(int)\n",
    "\n",
    "# Count events per (game, team, player) as a crude \"usage\" proxy\n",
    "pbp_players[\"event_count\"] = 1\n",
    "player_games = (\n",
    "    pbp_players\n",
    "    .groupby([\"game_id\", \"team_id_event\", \"player1_id\"], as_index=False)\n",
    "    .agg(event_count=(\"event_count\", \"sum\"))\n",
    "    .rename(columns={\"team_id_event\": \"team_id\", \"player1_id\": \"player_id\"})\n",
    ")\n",
    "\n",
    "print(\"player_games (per game/team/player):\", player_games.shape)\n",
    "print(player_games.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30b5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num (game, team) rosters: 16850\n"
     ]
    }
   ],
   "source": [
    "P = 10  # max players per side we keep (you can tweak this)\n",
    "\n",
    "roster_by_game_team = {}\n",
    "\n",
    "for (gid, tid), group in player_games.groupby([\"game_id\", \"team_id\"]):\n",
    "    # sort players by event_count desc (proxy for minutes/importance)\n",
    "    group = group.sort_values(\"event_count\", ascending=False)\n",
    "    player_ids_this = group[\"player_id\"].astype(int).tolist()\n",
    "    \n",
    "    # truncate / pad to length P\n",
    "    player_ids_this = player_ids_this[:P]\n",
    "    while len(player_ids_this) < P:\n",
    "        player_ids_this.append(0)  # 0 = padding / unknown player\n",
    "    \n",
    "    roster_by_game_team[(gid, tid)] = player_ids_this\n",
    "\n",
    "print(\"Num (game, team) rosters:\", len(roster_by_game_team))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f2af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num home_feature_cols: 24\n",
      "Num away_feature_cols: 24\n",
      "team_games initial: (18494, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pf</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11600043</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-39</td>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11700021</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-39</td>\n",
       "      <td>78.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11700055</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>89.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11700074</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-48</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11600020</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>12304</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>FCB</td>\n",
       "      <td>Barcelona FC Barcelona Lassa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11600043 2016-10-10       93        0      96.0  19.0  0.0  21.0    0.417   \n",
       "1  11700021 2017-10-04       93        0      78.0  19.0  2.0  28.0    0.294   \n",
       "2  11700055 2017-10-10       93        0      89.0  16.0  8.0  28.0    0.360   \n",
       "3  11700074 2017-10-13       93        0      81.0  11.0  6.0  23.0    0.212   \n",
       "4  11600020 2016-10-05    12304        1      89.0  24.0  2.0  22.0    0.452   \n",
       "\n",
       "   fg3a  ...    pf  plus_minus   pts   reb   stl  team_abbreviation  \\\n",
       "0  36.0  ...  26.0         -39  96.0  35.0   7.0                MAC   \n",
       "1  34.0  ...  23.0         -39  78.0  43.0  10.0                MAC   \n",
       "2  25.0  ...  25.0         -19  89.0  31.0  12.0                MAC   \n",
       "3  33.0  ...  27.0         -48  81.0  38.0   8.0                MAC   \n",
       "4  31.0  ...  24.0          -3  89.0  28.0  15.0                FCB   \n",
       "\n",
       "                      team_name   tov  video_available  wl  \n",
       "0           Haifa Maccabi Haifa  24.0                0   L  \n",
       "1           Haifa Maccabi Haifa  18.0                0   L  \n",
       "2           Haifa Maccabi Haifa  26.0                0   L  \n",
       "3           Haifa Maccabi Haifa  22.0                0   L  \n",
       "4  Barcelona FC Barcelona Lassa  23.0                0   L  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Select home/away feature columns, EXCLUDING the team_id columns\n",
    "home_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_home\") and c != HOME_TEAM_COL\n",
    "]\n",
    "\n",
    "away_feature_cols = [\n",
    "    c for c in games.columns\n",
    "    if c.endswith(\"_away\") and c != AWAY_TEAM_COL\n",
    "]\n",
    "\n",
    "print(\"Num home_feature_cols:\", len(home_feature_cols))\n",
    "print(\"Num away_feature_cols:\", len(away_feature_cols))\n",
    "\n",
    "# 2) Home rows\n",
    "home_df = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL] + home_feature_cols].copy()\n",
    "home_df = home_df.rename(columns={HOME_TEAM_COL: \"team_id\"})\n",
    "home_df[\"is_home\"] = 1\n",
    "\n",
    "for col in home_feature_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_df[base] = home_df[col]\n",
    "\n",
    "home_df[\"y_points\"] = home_df[PTS_HOME_COL]\n",
    "\n",
    "# 3) Away rows\n",
    "away_df = games[[GAME_ID_COL, GAME_DATE_COL, AWAY_TEAM_COL] + away_feature_cols].copy()\n",
    "away_df = away_df.rename(columns={AWAY_TEAM_COL: \"team_id\"})\n",
    "away_df[\"is_home\"] = 0\n",
    "\n",
    "for col in away_feature_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_df[base] = away_df[col]\n",
    "\n",
    "away_df[\"y_points\"] = away_df[PTS_AWAY_COL]\n",
    "\n",
    "# 4) Keep only unified columns\n",
    "keep_cols = [GAME_ID_COL, GAME_DATE_COL, \"team_id\", \"is_home\", \"y_points\"]\n",
    "base_feature_names = sorted(\n",
    "    {c.replace(\"_home\", \"\").replace(\"_away\", \"\") for c in home_feature_cols + away_feature_cols}\n",
    ")\n",
    "keep_cols += base_feature_names\n",
    "\n",
    "home_df = home_df[keep_cols].copy()\n",
    "away_df = away_df[keep_cols].copy()\n",
    "\n",
    "# 5) Combine into team_games\n",
    "team_games = pd.concat([home_df, away_df], axis=0).reset_index(drop=True)\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "print(\"team_games initial:\", team_games.shape)\n",
    "team_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed3ab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_info_small sample:\n",
      "    game_id  attendance  game_hour\n",
      "0  21600002     19446.0        NaN\n",
      "1  21600001         NaN        NaN\n",
      "2  21600003     19596.0        NaN\n",
      "3  21600010     15869.0        NaN\n",
      "4  21600005     17923.0        NaN\n",
      "team_games after game_info: (18506, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>stl</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>team_name</th>\n",
       "      <th>tov</th>\n",
       "      <th>video_available</th>\n",
       "      <th>wl</th>\n",
       "      <th>attendance</th>\n",
       "      <th>game_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11600043</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11700021</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>14126.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11700055</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>9110.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11700074</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Haifa Maccabi Haifa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11600020</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>12304</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>FCB</td>\n",
       "      <td>Barcelona FC Barcelona Lassa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>16236.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11600043 2016-10-10       93        0      96.0  19.0  0.0  21.0    0.417   \n",
       "1  11700021 2017-10-04       93        0      78.0  19.0  2.0  28.0    0.294   \n",
       "2  11700055 2017-10-10       93        0      89.0  16.0  8.0  28.0    0.360   \n",
       "3  11700074 2017-10-13       93        0      81.0  11.0  6.0  23.0    0.212   \n",
       "4  11600020 2016-10-05    12304        1      89.0  24.0  2.0  22.0    0.452   \n",
       "\n",
       "   fg3a  ...   pts   reb   stl  team_abbreviation  \\\n",
       "0  36.0  ...  96.0  35.0   7.0                MAC   \n",
       "1  34.0  ...  78.0  43.0  10.0                MAC   \n",
       "2  25.0  ...  89.0  31.0  12.0                MAC   \n",
       "3  33.0  ...  81.0  38.0   8.0                MAC   \n",
       "4  31.0  ...  89.0  28.0  15.0                FCB   \n",
       "\n",
       "                      team_name   tov  video_available wl  attendance  \\\n",
       "0           Haifa Maccabi Haifa  24.0                0  L     16000.0   \n",
       "1           Haifa Maccabi Haifa  18.0                0  L     14126.0   \n",
       "2           Haifa Maccabi Haifa  26.0                0  L      9110.0   \n",
       "3           Haifa Maccabi Haifa  22.0                0  L         NaN   \n",
       "4  Barcelona FC Barcelona Lassa  23.0                0  L     16236.0   \n",
       "\n",
       "   game_hour  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 2: merge game_info (attendance + game_hour) ---\n",
    "\n",
    "# Parse game_time to hour-of-day\n",
    "game_info[\"game_hour\"] = pd.to_datetime(\n",
    "    game_info[\"game_time\"],\n",
    "    format=\"%I:%M %p\",\n",
    "    errors=\"coerce\"\n",
    ").dt.hour\n",
    "\n",
    "# Keep only what we need\n",
    "game_info_small = game_info[[GAME_ID_COL, \"attendance\", \"game_hour\"]].copy()\n",
    "\n",
    "print(\"game_info_small sample:\")\n",
    "print(game_info_small.head())\n",
    "\n",
    "# Merge into team_games\n",
    "team_games = team_games.merge(\n",
    "    game_info_small,\n",
    "    on=GAME_ID_COL,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after game_info:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2b61f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_stats sample:\n",
      "    game_id  league_id  team_id_home team_abbreviation_home team_city_home  \\\n",
      "0  29600012          0    1610612756                    PHX        Phoenix   \n",
      "1  29600005          0    1610612737                    ATL        Atlanta   \n",
      "2  29600002          0    1610612739                    CLE      Cleveland   \n",
      "3  29600007          0    1610612754                    IND        Indiana   \n",
      "4  29600013          0    1610612746                    LAC    Los Angeles   \n",
      "\n",
      "   pts_paint_home  pts_2nd_chance_home  pts_fb_home  largest_lead_home  \\\n",
      "0              44                   18            2                  1   \n",
      "1              32                    9            6                  0   \n",
      "2              36                   14            6                 20   \n",
      "3              34                   11            4                 10   \n",
      "4              40                   19            2                 12   \n",
      "\n",
      "   lead_changes  ...  team_abbreviation_away  team_city_away  pts_paint_away  \\\n",
      "0             4  ...                     LAL     Los Angeles              42   \n",
      "1             0  ...                     MIA           Miami              32   \n",
      "2             1  ...                     NJN      New Jersey              26   \n",
      "3             7  ...                     DET         Detroit              30   \n",
      "4             5  ...                     GSW    Golden State              30   \n",
      "\n",
      "   pts_2nd_chance_away  pts_fb_away  largest_lead_away team_turnovers_away  \\\n",
      "0                   10           13                 19                 0.0   \n",
      "1                   15           14                 16                 1.0   \n",
      "2                   16            4                  2                 1.0   \n",
      "3                   14            7                  9                 2.0   \n",
      "4                    9            2                  6                 0.0   \n",
      "\n",
      "  total_turnovers_away  team_rebounds_away  pts_off_to_away  \n",
      "0                 23.0                11.0              NaN  \n",
      "1                 19.0                 6.0              NaN  \n",
      "2                 22.0                12.0              NaN  \n",
      "3                 19.0                10.0              NaN  \n",
      "4                 20.0                 7.0              NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "home_stat_cols: ['pts_paint_home', 'pts_2nd_chance_home', 'pts_fb_home', 'largest_lead_home', 'team_turnovers_home', 'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home']\n",
      "away_stat_cols: ['pts_paint_away', 'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away', 'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away']\n",
      "game_level_cols: ['lead_changes', 'times_tied']\n",
      "home_adv shape: (28271, 12)\n",
      "away_adv shape: (28271, 12)\n",
      "adv_long shape: (56542, 12)\n",
      "    game_id     team_id  lead_changes  times_tied  pts_paint  pts_2nd_chance  \\\n",
      "0  29600012  1610612756             4           1         44              18   \n",
      "1  29600005  1610612737             0           0         32               9   \n",
      "2  29600002  1610612739             1           1         36              14   \n",
      "3  29600007  1610612754             7           4         34              11   \n",
      "4  29600013  1610612746             5           4         40              19   \n",
      "\n",
      "   pts_fb  largest_lead  team_turnovers  total_turnovers  team_rebounds  \\\n",
      "0       2             1             0.0             12.0           11.0   \n",
      "1       6             0             1.0             24.0            7.0   \n",
      "2       6            20             0.0             15.0            5.0   \n",
      "3       4            10             0.0             18.0            8.0   \n",
      "4       2            12             0.0             20.0            7.0   \n",
      "\n",
      "   pts_off_to  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "team_games after other_stats: (18530, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>lead_changes</th>\n",
       "      <th>times_tied</th>\n",
       "      <th>pts_paint</th>\n",
       "      <th>pts_2nd_chance</th>\n",
       "      <th>pts_fb</th>\n",
       "      <th>largest_lead</th>\n",
       "      <th>team_turnovers</th>\n",
       "      <th>total_turnovers</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11600043</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11700021</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11700055</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11700074</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11600020</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>12304</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points   ast  blk  dreb  fg3_pct  \\\n",
       "0  11600043 2016-10-10       93        0      96.0  19.0  0.0  21.0    0.417   \n",
       "1  11700021 2017-10-04       93        0      78.0  19.0  2.0  28.0    0.294   \n",
       "2  11700055 2017-10-10       93        0      89.0  16.0  8.0  28.0    0.360   \n",
       "3  11700074 2017-10-13       93        0      81.0  11.0  6.0  23.0    0.212   \n",
       "4  11600020 2016-10-05    12304        1      89.0  24.0  2.0  22.0    0.452   \n",
       "\n",
       "   fg3a  ...  lead_changes  times_tied  pts_paint  pts_2nd_chance  pts_fb  \\\n",
       "0  36.0  ...           0.0         0.0       26.0            18.0     4.0   \n",
       "1  34.0  ...           1.0         3.0       24.0            17.0     8.0   \n",
       "2  25.0  ...           2.0         0.0       42.0            10.0     7.0   \n",
       "3  33.0  ...           0.0         0.0       36.0            23.0     6.0   \n",
       "4  31.0  ...           NaN         NaN        NaN             NaN     NaN   \n",
       "\n",
       "   largest_lead  team_turnovers total_turnovers  team_rebounds  pts_off_to  \n",
       "0           0.0             0.0            24.0            7.0        37.0  \n",
       "1           2.0             0.0            18.0           10.0        23.0  \n",
       "2           1.0             0.0            26.0           10.0        30.0  \n",
       "3           0.0             1.0            22.0           12.0        33.0  \n",
       "4           NaN             NaN             NaN            NaN         NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tier 3: merge other_stats (advanced team stats) ---\n",
    "\n",
    "print(\"other_stats sample:\")\n",
    "print(other_stats.head())\n",
    "\n",
    "# Game-level columns that apply to the whole game\n",
    "game_level_cols = []\n",
    "for col in [\"lead_changes\", \"times_tied\"]:\n",
    "    if col in other_stats.columns:\n",
    "        game_level_cols.append(col)\n",
    "\n",
    "# Home/away advanced stat columns (excluding id/label columns)\n",
    "home_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_home\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "away_stat_cols = [\n",
    "    c for c in other_stats.columns\n",
    "    if c.endswith(\"_away\")\n",
    "    and not c.startswith((\"team_id_\", \"team_abbreviation_\", \"team_city_\"))\n",
    "]\n",
    "\n",
    "print(\"home_stat_cols:\", home_stat_cols)\n",
    "print(\"away_stat_cols:\", away_stat_cols)\n",
    "print(\"game_level_cols:\", game_level_cols)\n",
    "\n",
    "# 4.1 Home advanced stats → unified format\n",
    "home_adv = other_stats[[\"game_id\", \"team_id_home\"] + game_level_cols + home_stat_cols].copy()\n",
    "home_adv = home_adv.rename(columns={\"team_id_home\": \"team_id\"})\n",
    "\n",
    "for col in home_stat_cols:\n",
    "    base = col.replace(\"_home\", \"\")\n",
    "    home_adv[base] = home_adv[col]\n",
    "\n",
    "home_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_home\", \"\") for c in home_stat_cols]\n",
    "home_adv = home_adv[home_keep_cols]\n",
    "\n",
    "# 4.2 Away advanced stats → unified format\n",
    "away_adv = other_stats[[\"game_id\", \"team_id_away\"] + game_level_cols + away_stat_cols].copy()\n",
    "away_adv = away_adv.rename(columns={\"team_id_away\": \"team_id\"})\n",
    "\n",
    "for col in away_stat_cols:\n",
    "    base = col.replace(\"_away\", \"\")\n",
    "    away_adv[base] = away_adv[col]\n",
    "\n",
    "away_keep_cols = [\"game_id\", \"team_id\"] + game_level_cols + [c.replace(\"_away\", \"\") for c in away_stat_cols]\n",
    "away_adv = away_adv[away_keep_cols]\n",
    "\n",
    "print(\"home_adv shape:\", home_adv.shape)\n",
    "print(\"away_adv shape:\", away_adv.shape)\n",
    "\n",
    "# 4.3 Combine advanced stats\n",
    "adv_long = pd.concat([home_adv, away_adv], axis=0).reset_index(drop=True)\n",
    "print(\"adv_long shape:\", adv_long.shape)\n",
    "print(adv_long.head())\n",
    "\n",
    "# 4.4 Merge advanced stats into team_games\n",
    "team_games = team_games.merge(\n",
    "    adv_long,\n",
    "    on=[\"game_id\", \"team_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"team_games after other_stats:\", team_games.shape)\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e860f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequence features: 35\n",
      "First 30 SEQ_FEATURES: ['is_home', 'ast', 'blk', 'dreb', 'fg3_pct', 'fg3a', 'fg3m', 'fg_pct', 'fga', 'fgm', 'ft_pct', 'fta', 'ftm', 'oreb', 'pf', 'plus_minus', 'pts', 'reb', 'stl', 'tov', 'game_hour', 'lead_changes', 'times_tied', 'pts_paint', 'pts_2nd_chance', 'pts_fb', 'largest_lead', 'team_turnovers', 'total_turnovers', 'team_rebounds']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>team_id</th>\n",
       "      <th>is_home</th>\n",
       "      <th>y_points</th>\n",
       "      <th>ast</th>\n",
       "      <th>blk</th>\n",
       "      <th>dreb</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>...</th>\n",
       "      <th>team_rebounds</th>\n",
       "      <th>pts_off_to</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>prev3_date</th>\n",
       "      <th>prev4_date</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>is_b2b</th>\n",
       "      <th>is_3in4</th>\n",
       "      <th>is_4in6</th>\n",
       "      <th>team_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11600043</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-0.905870</td>\n",
       "      <td>-1.948776</td>\n",
       "      <td>-2.426350</td>\n",
       "      <td>0.658299</td>\n",
       "      <td>0.589102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>2.791415</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.211051</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.156174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11700021</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-0.905870</td>\n",
       "      <td>-1.141344</td>\n",
       "      <td>-1.144814</td>\n",
       "      <td>-0.723736</td>\n",
       "      <td>0.336133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769881</td>\n",
       "      <td>1.095270</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>17.752823</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.156174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11700055</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-1.469527</td>\n",
       "      <td>1.280955</td>\n",
       "      <td>-1.144814</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>-0.802230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769881</td>\n",
       "      <td>1.943343</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.089181</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.156174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11700074</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>93</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-2.408956</td>\n",
       "      <td>0.473522</td>\n",
       "      <td>-2.060197</td>\n",
       "      <td>-1.645093</td>\n",
       "      <td>0.209648</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263900</td>\n",
       "      <td>2.306802</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.060935</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.156174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11600020</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>12304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.033558</td>\n",
       "      <td>-1.141344</td>\n",
       "      <td>-2.243274</td>\n",
       "      <td>1.051561</td>\n",
       "      <td>-0.043321</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.700210</td>\n",
       "      <td>-1.691253</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.211051</td>\n",
       "      <td>-0.441619</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-0.156174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  team_id  is_home  y_points       ast       blk  \\\n",
       "0  11600043 2016-10-10       93     -1.0      96.0 -0.905870 -1.948776   \n",
       "1  11700021 2017-10-04       93     -1.0      78.0 -0.905870 -1.141344   \n",
       "2  11700055 2017-10-10       93     -1.0      89.0 -1.469527  1.280955   \n",
       "3  11700074 2017-10-13       93     -1.0      81.0 -2.408956  0.473522   \n",
       "4  11600020 2016-10-05    12304      1.0      89.0  0.033558 -1.141344   \n",
       "\n",
       "       dreb   fg3_pct      fg3a  ...  team_rebounds  pts_off_to  prev_date  \\\n",
       "0 -2.426350  0.658299  0.589102  ...       0.028854    2.791415        NaT   \n",
       "1 -1.144814 -0.723736  0.336133  ...       0.769881    1.095270 2016-10-10   \n",
       "2 -1.144814  0.017844 -0.802230  ...       0.769881    1.943343 2017-10-04   \n",
       "3 -2.060197 -1.645093  0.209648  ...       1.263900    2.306802 2017-10-10   \n",
       "4 -2.243274  1.051561 -0.043321  ...      -1.700210   -1.691253        NaT   \n",
       "\n",
       "   prev3_date  prev4_date  days_rest    is_b2b   is_3in4   is_4in6  team_idx  \n",
       "0         NaT         NaT  -0.211051 -0.441619 -0.062811 -0.156174         0  \n",
       "1         NaT         NaT  17.752823 -0.441619 -0.062811 -0.156174         0  \n",
       "2         NaT         NaT   0.089181 -0.441619 -0.062811 -0.156174         0  \n",
       "3  2016-10-10         NaT  -0.060935 -0.441619 -0.062811 -0.156174         0  \n",
       "4         NaT         NaT  -0.211051 -0.441619 -0.062811 -0.156174         1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compute SEQ_FEATURES and scale ---\n",
    "\n",
    "# --- Schedule features: rest / B2B / 3-in-4 / 4-in-6 ---\n",
    "\n",
    "# Ensure sorted by team + date\n",
    "team_games = team_games.sort_values([\"team_id\", GAME_DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "grouped = team_games.groupby(\"team_id\")\n",
    "\n",
    "# Previous game dates\n",
    "team_games[\"prev_date\"]  = grouped[GAME_DATE_COL].shift(1)\n",
    "team_games[\"prev3_date\"] = grouped[GAME_DATE_COL].shift(3)\n",
    "team_games[\"prev4_date\"] = grouped[GAME_DATE_COL].shift(4)\n",
    "\n",
    "# Days of rest since last game\n",
    "team_games[\"days_rest\"] = (team_games[GAME_DATE_COL] - team_games[\"prev_date\"]).dt.days\n",
    "\n",
    "# Schedule intensity flags\n",
    "team_games[\"is_b2b\"]  = (team_games[\"days_rest\"] == 1).astype(int)\n",
    "\n",
    "team_games[\"is_3in4\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev3_date\"]).dt.days <= 4\n",
    ").astype(int)\n",
    "\n",
    "team_games[\"is_4in6\"] = (\n",
    "    (team_games[GAME_DATE_COL] - team_games[\"prev4_date\"]).dt.days <= 6\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# --- Team ID ↔ index mapping for embeddings ---\n",
    "\n",
    "team_ids = sorted(team_games[\"team_id\"].unique())\n",
    "team_id_to_idx = {tid: i for i, tid in enumerate(team_ids)}\n",
    "num_teams = len(team_ids)\n",
    "\n",
    "# Optional: store per-row team index (not used in SEQ_FEATURES)\n",
    "team_games[\"team_idx\"] = team_games[\"team_id\"].map(team_id_to_idx)\n",
    "\n",
    "\n",
    "\n",
    "exclude_cols = {\n",
    "    GAME_ID_COL,\n",
    "    GAME_DATE_COL,\n",
    "    \"team_id\",\n",
    "    \"y_points\",\n",
    "    \"prev_date\",\n",
    "    \"prev3_date\",\n",
    "    \"prev4_date\",\n",
    "    \"team_idx\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    # non signals (i think)\n",
    "    \"video_available\",\n",
    "    \"attendance\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in team_games.columns\n",
    "    if c not in exclude_cols and pd.api.types.is_numeric_dtype(team_games[c])\n",
    "]\n",
    "\n",
    "SEQ_FEATURES = numeric_cols\n",
    "print(\"Number of sequence features:\", len(SEQ_FEATURES))\n",
    "print(\"First 30 SEQ_FEATURES:\", SEQ_FEATURES[:30])\n",
    "\n",
    "train_rows = team_games[team_games[GAME_DATE_COL] < VAL_SPLIT_DATE].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_rows[SEQ_FEATURES].fillna(0.0))\n",
    "\n",
    "team_games[SEQ_FEATURES] = scaler.transform(\n",
    "    team_games[SEQ_FEATURES].fillna(0.0)\n",
    ")\n",
    "\n",
    "team_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d671461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_sequences: (18032, 15, 35)\n",
      "team_targets: (18032,)\n"
     ]
    }
   ],
   "source": [
    "team_sequences = []\n",
    "team_targets = []\n",
    "team_meta = []  # (game_id, team_id, game_date)\n",
    "\n",
    "for team_id, group in team_games.groupby(\"team_id\"):\n",
    "    group = group.sort_values(GAME_DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    feats = group[SEQ_FEATURES].values           # [num_games, F]\n",
    "    targets = group[\"y_points\"].values\n",
    "    game_ids = group[GAME_ID_COL].values\n",
    "    dates = group[GAME_DATE_COL].values\n",
    "\n",
    "    # require SEQ_LEN previous games\n",
    "    for i in range(SEQ_LEN, len(group)):\n",
    "        seq = feats[i-SEQ_LEN:i]\n",
    "        y = targets[i]\n",
    "        gid = game_ids[i]\n",
    "        date = dates[i]\n",
    "\n",
    "        team_sequences.append(seq)\n",
    "        team_targets.append(y)\n",
    "        team_meta.append((gid, team_id, date))\n",
    "\n",
    "team_sequences = np.stack(team_sequences)          # [N_team_games, T, F]\n",
    "team_targets = np.array(team_targets, dtype=np.float32)\n",
    "\n",
    "print(\"team_sequences:\", team_sequences.shape)\n",
    "print(\"team_targets:\", team_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6a9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18012"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_index_by_game_team = {\n",
    "    (gid, tid): idx\n",
    "    for idx, (gid, tid, date) in enumerate(team_meta)\n",
    "}\n",
    "\n",
    "len(seq_index_by_game_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18856e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_full: (9247, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>y_home</th>\n",
       "      <th>y_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21600002</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>113.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21600001</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>117.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21600003</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>100.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21600010</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>102.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21600005</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>1610612754</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>130.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  game_date  home_team_id  away_team_id  y_home  y_away\n",
       "0  21600002 2016-10-25    1610612757    1610612762   113.0   104.0\n",
       "1  21600001 2016-10-25    1610612739    1610612752   117.0    88.0\n",
       "2  21600003 2016-10-25    1610612744    1610612759   100.0   129.0\n",
       "3  21600010 2016-10-26    1610612740    1610612743   102.0   107.0\n",
       "4  21600005 2016-10-26    1610612754    1610612742   130.0   121.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_full = games[[GAME_ID_COL, GAME_DATE_COL, HOME_TEAM_COL, AWAY_TEAM_COL, PTS_HOME_COL, PTS_AWAY_COL]].copy()\n",
    "\n",
    "games_full = games_full.rename(columns={\n",
    "    HOME_TEAM_COL: \"home_team_id\",\n",
    "    AWAY_TEAM_COL: \"away_team_id\",\n",
    "    PTS_HOME_COL: \"y_home\",\n",
    "    PTS_AWAY_COL: \"y_away\"\n",
    "})\n",
    "\n",
    "print(\"games_full:\", games_full.shape)\n",
    "games_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f77994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_betting = pd.read_csv(f'{DATA_DIR}/nba_2008-2025.csv')\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "df_betting = df_betting[df_betting['game_date'] >= ERA_START].reset_index(drop=True)\n",
    "\n",
    "team_df = pd.read_csv(os.path.join(DATA_DIR, 'team.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e60b3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       game_date whos_favored  spread      home_team  away_team\n",
      "0     2016-10-25         home     9.0      Cavaliers     Knicks\n",
      "1     2016-10-25         home     5.5  Trail Blazers       Jazz\n",
      "2     2016-10-25         home     8.0       Warriors      Spurs\n",
      "3     2016-10-26         home     3.0          Magic       Heat\n",
      "4     2016-10-26         home     5.5         Pacers  Mavericks\n",
      "...          ...          ...     ...            ...        ...\n",
      "11525 2025-06-11         away    -4.5         Pacers    Thunder\n",
      "11526 2025-06-13         away    -6.5         Pacers    Thunder\n",
      "11527 2025-06-16         home     8.5        Thunder     Pacers\n",
      "11528 2025-06-19         away    -5.5         Pacers    Thunder\n",
      "11529 2025-06-22         home     6.5        Thunder     Pacers\n",
      "\n",
      "[11530 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'atl': 'Hawks',\n",
    "    'bos': 'Celtics',\n",
    "    'bkn': 'Nets',\n",
    "    'cha': 'Hornets',\n",
    "    'chi': 'Bulls',\n",
    "    'cle': 'Cavaliers',\n",
    "    'dal': 'Mavericks',\n",
    "    'den': 'Nuggets',\n",
    "    'det': 'Pistons',\n",
    "    'gs': 'Warriors',\n",
    "    'hou': 'Rockets',\n",
    "    'ind': 'Pacers',\n",
    "    'lac': 'Clippers',\n",
    "    'lal': 'Lakers',\n",
    "    'mem': 'Grizzlies',\n",
    "    'mia': 'Heat',\n",
    "    'mil': 'Bucks',\n",
    "    'min': 'Timberwolves',\n",
    "    'no': 'Pelicans',\n",
    "    'ny': 'Knicks',\n",
    "    'okc': 'Thunder',\n",
    "    'orl': 'Magic',\n",
    "    'phi': '76ers',\n",
    "    'phx': 'Suns',\n",
    "    'por': 'Trail Blazers',\n",
    "    'sac': 'Kings',\n",
    "    'sa': 'Spurs',\n",
    "    'tor': 'Raptors',\n",
    "    'utah': 'Jazz',\n",
    "    'wsh': 'Wizards'\n",
    "}\n",
    "\n",
    "df_betting['away_team'] = df_betting['away'].map(abbreviation_mapping)\n",
    "df_betting['home_team'] = df_betting['home'].map(abbreviation_mapping)\n",
    "# Rename date to game_date to match test_predictions_df\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['date'])\n",
    "# Convert the spread to negative if the away team is favored\n",
    "df_betting['spread'] = df_betting.apply(\n",
    "    lambda row: -row['spread'] if 'away' == row['whos_favored'] else row['spread'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Print modified columns for verification\n",
    "print(df_betting[['game_date', 'whos_favored', 'spread', 'home_team', 'away_team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a52c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games_with_lines: (5629, 10)\n"
     ]
    }
   ],
   "source": [
    "# Build team abbreviation mapping for games_full\n",
    "team_df = pd.read_csv(os.path.join(DATA_DIR, 'team.csv'))\n",
    "id_to_abbrev = dict(zip(team_df['id'], team_df['abbreviation']))\n",
    "\n",
    "games_full_with_names = games_full.copy()\n",
    "games_full_with_names['home_abbrev'] = games_full_with_names['home_team_id'].map(id_to_abbrev)\n",
    "games_full_with_names['away_abbrev'] = games_full_with_names['away_team_id'].map(id_to_abbrev)\n",
    "\n",
    "# df_betting has lower-case abbrevs like 'atl', 'bos', etc.\n",
    "# Make them comparable: upper-case\n",
    "df_betting['home_abbrev'] = df_betting['home'].str.upper()\n",
    "df_betting['away_abbrev'] = df_betting['away'].str.upper()\n",
    "\n",
    "# Ensure game_date is datetime\n",
    "games_full_with_names['game_date'] = pd.to_datetime(games_full_with_names['game_date'])\n",
    "df_betting['game_date'] = pd.to_datetime(df_betting['game_date'])\n",
    "\n",
    "# Merge lines onto games_full\n",
    "games_with_lines = pd.merge(\n",
    "    games_full_with_names,\n",
    "    df_betting[['game_date', 'home_abbrev', 'away_abbrev', 'spread', 'total']],\n",
    "    on=['game_date', 'home_abbrev', 'away_abbrev'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"games_with_lines:\", games_with_lines.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c119c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes with lines:\n",
      "X_home: (5545, 15, 35)\n",
      "Y (errors): (5545, 2)\n"
     ]
    }
   ],
   "source": [
    "X_home = []\n",
    "X_away = []\n",
    "Y      = []  # will now hold [margin_error, total_error]\n",
    "GAME_DATES = []\n",
    "HOME_TEAM_IDX = []\n",
    "AWAY_TEAM_IDX = []\n",
    "HOME_PLAYER_IDX_LIST = []\n",
    "AWAY_PLAYER_IDX_LIST = []\n",
    "LINE_SPREAD = []\n",
    "LINE_TOTAL  = []\n",
    "\n",
    "for _, row in games_with_lines.iterrows():\n",
    "    gid  = row[GAME_ID_COL]\n",
    "    home_id = row['home_team_id']\n",
    "    away_id = row['away_team_id']\n",
    "    date    = row['game_date']\n",
    "\n",
    "    key_home = (gid, home_id)\n",
    "    key_away = (gid, away_id)\n",
    "\n",
    "    if key_home not in seq_index_by_game_team or key_away not in seq_index_by_game_team:\n",
    "        continue  # skip early games (not enough history)\n",
    "\n",
    "    idx_h = seq_index_by_game_team[key_home]\n",
    "    idx_a = seq_index_by_game_team[key_away]\n",
    "\n",
    "    X_home.append(team_sequences[idx_h])\n",
    "    X_away.append(team_sequences[idx_a])\n",
    "\n",
    "    # Raw scores\n",
    "    home = row['y_home']\n",
    "    away = row['y_away']\n",
    "    margin = home - away\n",
    "    total  = home + away\n",
    "\n",
    "    # Market lines\n",
    "    line_spread = row['spread']\n",
    "    line_total  = row['total']\n",
    "\n",
    "    margin_error = margin - line_spread\n",
    "    total_error  = total  - line_total\n",
    "    Y.append([margin_error, total_error])\n",
    "\n",
    "    LINE_SPREAD.append(line_spread)\n",
    "    LINE_TOTAL.append(line_total)\n",
    "    GAME_DATES.append(date)\n",
    "\n",
    "    HOME_TEAM_IDX.append(team_id_to_idx[home_id])\n",
    "    AWAY_TEAM_IDX.append(team_id_to_idx[away_id])\n",
    "\n",
    "    # Players as before\n",
    "    home_roster_raw = roster_by_game_team.get(key_home, [0] * P)\n",
    "    away_roster_raw = roster_by_game_team.get(key_away, [0] * P)\n",
    "    home_player_idx = [player_id_to_idx.get(pid, 0) for pid in home_roster_raw]\n",
    "    away_player_idx = [player_id_to_idx.get(pid, 0) for pid in away_roster_raw]\n",
    "\n",
    "    HOME_PLAYER_IDX_LIST.append(home_player_idx)\n",
    "    AWAY_PLAYER_IDX_LIST.append(away_player_idx)\n",
    "\n",
    "# Convert to arrays\n",
    "X_home = np.stack(X_home)\n",
    "X_away = np.stack(X_away)\n",
    "Y      = np.array(Y, dtype=np.float32)\n",
    "GAME_DATES = np.array(GAME_DATES)\n",
    "HOME_TEAM_IDX = np.array(HOME_TEAM_IDX, dtype=np.int64)\n",
    "AWAY_TEAM_IDX = np.array(AWAY_TEAM_IDX, dtype=np.int64)\n",
    "HOME_PLAYER_IDX = np.array(HOME_PLAYER_IDX_LIST, dtype=np.int64)\n",
    "AWAY_PLAYER_IDX = np.array(AWAY_PLAYER_IDX_LIST, dtype=np.int64)\n",
    "LINE_SPREAD = np.array(LINE_SPREAD, dtype=np.float32)\n",
    "LINE_TOTAL  = np.array(LINE_TOTAL, dtype=np.float32)\n",
    "\n",
    "print(\"Final dataset shapes with lines:\")\n",
    "print(\"X_home:\", X_home.shape)\n",
    "print(\"Y (errors):\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe630964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games: 5545\n",
      "Games with full betting lines: 5542\n"
     ]
    }
   ],
   "source": [
    "# 0) Assume these are all same length N_games:\n",
    "# X_home, X_away, Y, HOME_TEAM_IDX, AWAY_TEAM_IDX,\n",
    "# HOME_PLAYER_IDX, AWAY_PLAYER_IDX, GAME_DATES,\n",
    "# LINE_SPREAD, LINE_TOTAL\n",
    "\n",
    "line_mask = ~np.isnan(LINE_SPREAD) & ~np.isnan(LINE_TOTAL)\n",
    "print(\"Total games:\", len(Y))\n",
    "print(\"Games with full betting lines:\", line_mask.sum())\n",
    "\n",
    "X_home        = X_home[line_mask]\n",
    "X_away        = X_away[line_mask]\n",
    "Y             = Y[line_mask]\n",
    "HOME_TEAM_IDX = HOME_TEAM_IDX[line_mask]\n",
    "AWAY_TEAM_IDX = AWAY_TEAM_IDX[line_mask]\n",
    "HOME_PLAYER_IDX = HOME_PLAYER_IDX[line_mask]\n",
    "AWAY_PLAYER_IDX = AWAY_PLAYER_IDX[line_mask]\n",
    "GAME_DATES    = GAME_DATES[line_mask]\n",
    "LINE_SPREAD   = LINE_SPREAD[line_mask]\n",
    "LINE_TOTAL    = LINE_TOTAL[line_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25fd0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3873 Val: 830 Test: 839\n",
      "Train mean errors (margin_error, total_error): [-0.15453137  0.33049315]\n"
     ]
    }
   ],
   "source": [
    "VAL_SPLIT_DATE = pd.to_datetime(VAL_SPLIT_DATE)\n",
    "TEST_SPLIT_DATE = pd.to_datetime(TEST_SPLIT_DATE)\n",
    "\n",
    "dates = pd.to_datetime(GAME_DATES)\n",
    "\n",
    "train_mask = dates < VAL_SPLIT_DATE\n",
    "val_mask = (dates >= VAL_SPLIT_DATE) & (dates < TEST_SPLIT_DATE)\n",
    "test_mask = dates >= TEST_SPLIT_DATE\n",
    "\n",
    "def split(arr):\n",
    "    return arr[train_mask], arr[val_mask], arr[test_mask]\n",
    "\n",
    "X_home_train, X_home_val, X_home_test = split(X_home)\n",
    "X_away_train, X_away_val, X_away_test = split(X_away)\n",
    "Y_train, Y_val, Y_test = split(Y)\n",
    "\n",
    "home_idx_train, home_idx_val, home_idx_test = split(HOME_TEAM_IDX)\n",
    "away_idx_train, away_idx_val, away_idx_test = split(AWAY_TEAM_IDX)\n",
    "\n",
    "home_player_train, home_player_val, home_player_test = split(HOME_PLAYER_IDX)\n",
    "away_player_train, away_player_val, away_player_test = split(AWAY_PLAYER_IDX)\n",
    "\n",
    "spread_train, spread_val, spread_test = split(LINE_SPREAD)\n",
    "total_train,  total_val,  total_test  = split(LINE_TOTAL)\n",
    "\n",
    "print(\"Train:\", len(Y_train), \"Val:\", len(Y_val), \"Test:\", len(Y_test))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_mean_errors = Y_train.mean(axis=0)\n",
    "print(\"Train mean errors (margin_error, total_error):\", train_mean_errors)\n",
    "\n",
    "Y_train_raw = Y_train.copy()\n",
    "Y_val_raw   = Y_val.copy()\n",
    "Y_test_raw  = Y_test.copy()\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(Y_train_raw)        # fit on train only\n",
    "\n",
    "Y_train = y_scaler.transform(Y_train_raw)\n",
    "Y_val   = y_scaler.transform(Y_val_raw)\n",
    "Y_test  = y_scaler.transform(Y_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20961c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in Y_train_raw per column: [0 0]\n",
      "NaNs in Y_val_raw per column: [0 0]\n",
      "NaNs in Y_test_raw per column: [0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in Y_train_raw per column:\", np.isnan(Y_train_raw).sum(axis=0))\n",
    "print(\"NaNs in Y_val_raw per column:\",   np.isnan(Y_val_raw).sum(axis=0))\n",
    "print(\"NaNs in Y_test_raw per column:\",  np.isnan(Y_test_raw).sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf6c17c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always over sign accuracy: 0.4898688915375447\n",
      "Always under sign accuracy: 0.5053635280095352\n"
     ]
    }
   ],
   "source": [
    "# On the *test* set arrays, no merges:\n",
    "true_total_err = Y_test_raw[:, 1]   # total_error = total - line_total\n",
    "\n",
    "always_over_pred = np.ones_like(true_total_err)  # pretend we always guess \"over\"\n",
    "always_under_pred = -np.ones_like(true_total_err)\n",
    "\n",
    "def sign_acc(true_err, pred_err):\n",
    "    return (np.sign(true_err) == np.sign(pred_err)).mean()\n",
    "\n",
    "print(\"Always over sign accuracy:\", sign_acc(true_total_err, always_over_pred))\n",
    "print(\"Always under sign accuracy:\", sign_acc(true_total_err, always_under_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba18b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameSequenceDataset(Dataset):\n",
    "    def __init__(self, x_home, x_away, y, home_idx, away_idx, home_players, away_players):\n",
    "        self.x_home = torch.tensor(x_home, dtype=torch.float32)\n",
    "        self.x_away = torch.tensor(x_away, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        self.home_idx = torch.tensor(home_idx, dtype=torch.long)\n",
    "        self.away_idx = torch.tensor(away_idx, dtype=torch.long)\n",
    "\n",
    "        self.home_players = torch.tensor(home_players, dtype=torch.long)  # [N, P]\n",
    "        self.away_players = torch.tensor(away_players, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_home[idx],\n",
    "            self.x_away[idx],\n",
    "            self.y[idx],\n",
    "            self.home_idx[idx],\n",
    "            self.away_idx[idx],\n",
    "            self.home_players[idx],\n",
    "            self.away_players[idx],\n",
    "        )\n",
    "\n",
    "train_dataset = GameSequenceDataset(\n",
    "    X_home_train, X_away_train, Y_train,\n",
    "    home_idx_train, away_idx_train,\n",
    "    home_player_train, away_player_train,\n",
    ")\n",
    "val_dataset = GameSequenceDataset(\n",
    "    X_home_val, X_away_val, Y_val,\n",
    "    home_idx_val, away_idx_val,\n",
    "    home_player_val, away_player_val,\n",
    ")\n",
    "test_dataset = GameSequenceDataset(\n",
    "    X_home_test, X_away_test, Y_test,\n",
    "    home_idx_test, away_idx_test,\n",
    "    home_player_test, away_player_test,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec27546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_home shape: torch.Size([15, 35])\n",
      "x_away shape: torch.Size([15, 35])\n",
      "y: tensor([-1.2078, -1.0681])\n",
      "home_idx: tensor(32)\n",
      "away_idx: tensor(21)\n",
      "home_players shape: torch.Size([10])\n",
      "away_players shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "x_home, x_away, y, home_idx, away_idx, home_players, away_players = sample\n",
    "\n",
    "print(\"x_home shape:\", x_home.shape)    # expected [SEQ_LEN, num_team_seq_features]\n",
    "print(\"x_away shape:\", x_away.shape)\n",
    "print(\"y:\", y)                          # expected shape [2] (margin, total)\n",
    "print(\"home_idx:\", home_idx)            # int\n",
    "print(\"away_idx:\", away_idx)            # int\n",
    "print(\"home_players shape:\", home_players.shape)  # expected [P]\n",
    "print(\"away_players shape:\", away_players.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01124d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx_home batch shape: torch.Size([64, 15, 35])\n",
      "bx_away batch shape: torch.Size([64, 15, 35])\n",
      "by batch shape: torch.Size([64, 2])\n",
      "bhome_players batch shape: torch.Size([64, 10])\n",
      "baway_players batch shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "(\n",
    "    bx_home, bx_away, by,\n",
    "    bhome_idx, baway_idx,\n",
    "    bhome_players, baway_players\n",
    ") = batch\n",
    "\n",
    "print(\"bx_home batch shape:\", bx_home.shape)        # [B, 20, 37]\n",
    "print(\"bx_away batch shape:\", bx_away.shape)\n",
    "print(\"by batch shape:\", by.shape)                  # [B, 2]\n",
    "print(\"bhome_players batch shape:\", bhome_players.shape)  # [B, P]\n",
    "print(\"baway_players batch shape:\", baway_players.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04aa4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max home_idx: 40\n",
      "max away_idx: 40\n",
      "num_teams: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"max home_idx:\", home_idx_train.max())\n",
    "print(\"max away_idx:\", away_idx_train.max())\n",
    "print(\"num_teams:\", num_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cfe2ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max home_players: 4653\n",
      "max away_players: 4653\n",
      "num_players: 4832\n"
     ]
    }
   ],
   "source": [
    "print(\"max home_players:\", home_player_train.max())\n",
    "print(\"max away_players:\", away_player_train.max())\n",
    "print(\"num_players:\", num_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58ef2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home roster unique values (first 1000 games): [   0  643  647  648  736  741  797  855  866  872  915  922  926  959\n",
      "  965  984  986  988  995 1003]\n"
     ]
    }
   ],
   "source": [
    "unique_vals = np.unique(home_player_train[:1000])\n",
    "print(\"Home roster unique values (first 1000 games):\", unique_vals[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faa6f7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train latest date: 2021-07-20 00:00:00\n",
      "Val earliest date: 2021-10-19 00:00:00\n",
      "Test earliest date: 2022-10-18 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Train latest date:\", GAME_DATES[train_mask].max())\n",
    "print(\"Val earliest date:\", GAME_DATES[val_mask].min())\n",
    "print(\"Test earliest date:\", GAME_DATES[test_mask].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b5a7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team index: 11 13\n",
      "Home players: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Away players: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(train_dataset))\n",
    "sample = train_dataset[idx]\n",
    "\n",
    "_, _, _, home_idx, away_idx, home_players, away_players = sample\n",
    "\n",
    "print(\"Team index:\", home_idx.item(), away_idx.item())\n",
    "print(\"Home players:\", home_players[:10])\n",
    "print(\"Away players:\", away_players[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc530824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 21800368 1610612766 1610612743\n",
      "Mapped home idx: 11 → 1610612737\n"
     ]
    }
   ],
   "source": [
    "gid, home_id, away_id = games_full.iloc[idx][['game_id','home_team_id','away_team_id']]\n",
    "print(\"Original:\", gid, home_id, away_id)\n",
    "print(\"Mapped home idx:\", home_idx.item(), \"→\", team_ids[home_idx.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6933711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.isnan(X_home).any()\n",
    "assert not np.isinf(X_home).any()\n",
    "assert not np.isnan(X_away).any()\n",
    "assert not np.isinf(X_away).any()\n",
    "assert not np.isnan(Y).any()\n",
    "assert not np.isinf(Y).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1357b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (15, 35) (15, 35) [-1.2078357 -1.0681163]\n",
      "1 (15, 35) (15, 35) [-0.3420301  1.8604258]\n",
      "2 (15, 35) (15, 35) [-1.2471905  -0.07351708]\n",
      "3 (15, 35) (15, 35) [-0.3420301 -0.4326779]\n",
      "4 (15, 35) (15, 35) [0.5237755  0.28564376]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    seq_h = X_home_train[i]\n",
    "    seq_a = X_away_train[i]\n",
    "    t = Y_train[i]\n",
    "    print(i, seq_h.shape, seq_a.shape, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1cf0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TeamSequenceEncoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int = 1, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # output: [B, T, 2H]\n",
    "        return output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScorePredictorGNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,          # seq feature dim (36 in your printout)\n",
    "        hidden_size: int = 16,    # BiLSTM hidden\n",
    "        num_layers: int = 1,\n",
    "        num_teams: int = None,\n",
    "        num_players: int = None,\n",
    "        team_emb_dim: int = 4,\n",
    "        player_emb_dim: int = 8,   # bump player dim\n",
    "        gnn_hidden_dim: int = 16,  # graph node dim\n",
    "        gnn_steps: int = 3,         # message passing steps\n",
    "        mlp_hidden: int = 24,\n",
    "        global_dropout: float = 0.35,\n",
    "        mlp_dropout: float = 0.25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gnn_steps = gnn_steps\n",
    "\n",
    "        # --- Time encoder over team sequence (same as before) ---\n",
    "        self.encoder = TeamSequenceEncoder(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        seq_dim = hidden_size * 2  # BiLSTM\n",
    "\n",
    "        # --- Embeddings ---\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        # IMPORTANT: padding_idx=0 so id 0 is ignored / kept zero\n",
    "        self.player_embedding = nn.Embedding(\n",
    "            num_players,\n",
    "            player_emb_dim,\n",
    "            padding_idx=0,\n",
    "        )\n",
    "\n",
    "        # --- Project into graph space ---\n",
    "        # team node gets [seq_vec, team_id_emb] → gnn_hidden_dim\n",
    "        self.team_in = nn.Linear(seq_dim + team_emb_dim, gnn_hidden_dim)\n",
    "\n",
    "        # player node gets just player_emb → gnn_hidden_dim\n",
    "        self.player_in = nn.Linear(player_emb_dim, gnn_hidden_dim)\n",
    "\n",
    "        # --- Message-passing MLPs ---\n",
    "        # Team update sees [team_node, mean(player_nodes)]\n",
    "        self.team_update = nn.Linear(2 * gnn_hidden_dim, gnn_hidden_dim)\n",
    "\n",
    "        # Player update sees [player_node, team_node_broadcast]\n",
    "        self.player_update = nn.Linear(2 * gnn_hidden_dim, gnn_hidden_dim)\n",
    "\n",
    "        # --- Final prediction head ---\n",
    "        # We’ll use both teams’ final team_node and pooled player_node\n",
    "        pair_input_dim = 4 * gnn_hidden_dim  # home_team, away_team, home_players, away_players\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(mlp_dropout),\n",
    "            nn.Linear(mlp_hidden, 2),  # [margin, total]\n",
    "        )\n",
    "        \n",
    "        # new\n",
    "        self.dropout = nn.Dropout(global_dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_home, x_away,           # [B, T, F]\n",
    "        home_team_idx, away_team_idx,  # [B]\n",
    "        home_players, away_players,    # [B, P] int64 with 0 as padding\n",
    "    ):\n",
    "        B = x_home.size(0)\n",
    "        device = x_home.device\n",
    "\n",
    "        # --- Encode team sequences ---\n",
    "        h_home_seq = self.encoder(x_home)   # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)   # [B, T, 2H]\n",
    "\n",
    "        home_seq_vec = h_home_seq.mean(dim=1)  # [B, 2H]\n",
    "        away_seq_vec = h_away_seq.mean(dim=1)\n",
    "\n",
    "        # --- Team ID embeddings ---\n",
    "        home_team_emb = self.team_embedding(home_team_idx)  # [B, D_t]\n",
    "        away_team_emb = self.team_embedding(away_team_idx)\n",
    "\n",
    "        # --- Initial team nodes in graph space ---\n",
    "        home_team_node = self.team_in(torch.cat([home_seq_vec, home_team_emb], dim=-1))\n",
    "        away_team_node = self.team_in(torch.cat([away_seq_vec, away_team_emb], dim=-1))\n",
    "\n",
    "        # --- Player embeddings / nodes ---\n",
    "        # home_players: [B, P] -> [B, P, D_p]\n",
    "        home_player_emb = self.player_embedding(home_players)  # padding_idx=0 → zeros where 0\n",
    "        away_player_emb = self.player_embedding(away_players)\n",
    "\n",
    "        home_player_node = self.player_in(home_player_emb)   # [B, P, G]\n",
    "        away_player_node = self.player_in(away_player_emb)\n",
    "\n",
    "        # --- Masks for real players (id != 0) ---\n",
    "        home_mask = (home_players != 0).unsqueeze(-1).float()  # [B, P, 1]\n",
    "        away_mask = (away_players != 0).unsqueeze(-1).float()\n",
    "\n",
    "        # Ensure padded players stay zero\n",
    "        home_player_node = home_player_node * home_mask\n",
    "        away_player_node = away_player_node * away_mask\n",
    "\n",
    "        # --- Message passing ---\n",
    "        for _ in range(self.gnn_steps):\n",
    "            # Players → Team: masked mean\n",
    "            home_count = home_mask.sum(dim=1).clamp(min=1.0)  # [B, 1]\n",
    "            away_count = away_mask.sum(dim=1).clamp(min=1.0)\n",
    "\n",
    "            home_players_mean = (home_player_node * home_mask).sum(dim=1) / home_count  # [B, G]\n",
    "            away_players_mean = (away_player_node * away_mask).sum(dim=1) / away_count\n",
    "\n",
    "            # Team update (residual)\n",
    "            home_team_msg = torch.cat([home_team_node, home_players_mean], dim=-1)  # [B, 2G]\n",
    "            away_team_msg = torch.cat([away_team_node, away_players_mean], dim=-1)\n",
    "\n",
    "            home_team_delta = F.relu(self.team_update(home_team_msg))\n",
    "            away_team_delta = F.relu(self.team_update(away_team_msg))\n",
    "\n",
    "            home_team_node = home_team_node + home_team_delta\n",
    "            away_team_node = away_team_node + away_team_delta\n",
    "\n",
    "            # Team → Players: broadcast team node to each player\n",
    "            home_team_broadcast = home_team_node.unsqueeze(1).expand_as(home_player_node)  # [B, P, G]\n",
    "            away_team_broadcast = away_team_node.unsqueeze(1).expand_as(away_player_node)\n",
    "\n",
    "            home_player_msg = torch.cat([home_player_node, home_team_broadcast], dim=-1)  # [B, P, 2G]\n",
    "            away_player_msg = torch.cat([away_player_node, away_team_broadcast], dim=-1)\n",
    "\n",
    "            home_player_delta = F.relu(self.player_update(home_player_msg))\n",
    "            away_player_delta = F.relu(self.player_update(away_player_msg))\n",
    "\n",
    "            # Residual + mask\n",
    "            home_player_node = (home_player_node + home_player_delta) * home_mask\n",
    "            away_player_node = (away_player_node + away_player_delta) * away_mask\n",
    "\n",
    "        # --- Final pooling of players ---\n",
    "        home_players_final = (home_player_node * home_mask).sum(dim=1) / home_count  # [B, G]\n",
    "        away_players_final = (away_player_node * away_mask).sum(dim=1) / away_count\n",
    "\n",
    "        # --- Final pairwise representation ---\n",
    "        pair_vec = torch.cat([\n",
    "            home_team_node,\n",
    "            away_team_node,\n",
    "            home_players_final,\n",
    "            away_players_final,\n",
    "        ], dim=-1)  # [B, 4G]\n",
    "\n",
    "        # new extra dropout\n",
    "        pair_vec = self.dropout(pair_vec)\n",
    "        y_pred = self.mlp(pair_vec)  # [B, 2]\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class ScorePredictorCrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        num_heads: int = 4,\n",
    "        num_teams: int = None,\n",
    "        team_emb_dim: int = 16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = hidden_size * 2  # BiLSTM\n",
    "        self.team_emb_dim = team_emb_dim\n",
    "\n",
    "        self.encoder = TeamSequenceEncoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.team_embedding = nn.Embedding(num_teams, team_emb_dim)\n",
    "\n",
    "        pair_input_dim = self.embed_dim * 2 + team_emb_dim * 2\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(pair_input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 2),  # [margin, total]\n",
    "        )\n",
    "\n",
    "    def forward(self, x_home, x_away, home_team_idx, away_team_idx):\n",
    "        # Encode sequences\n",
    "        h_home_seq = self.encoder(x_home)   # [B, T, 2H]\n",
    "        h_away_seq = self.encoder(x_away)   # [B, T, 2H]\n",
    "\n",
    "        # Home attends to away\n",
    "        home_ctx, _ = self.cross_attn(\n",
    "            query=h_home_seq,\n",
    "            key=h_away_seq,\n",
    "            value=h_away_seq,\n",
    "        )\n",
    "\n",
    "        # Away attends to home\n",
    "        away_ctx, _ = self.cross_attn(\n",
    "            query=h_away_seq,\n",
    "            key=h_home_seq,\n",
    "            value=h_home_seq,\n",
    "        )\n",
    "\n",
    "        # Pool over time\n",
    "        home_vec = home_ctx.mean(dim=1)   # [B, 2H]\n",
    "        away_vec = away_ctx.mean(dim=1)   # [B, 2H]\n",
    "\n",
    "        # Team embeddings\n",
    "        home_emb = self.team_embedding(home_team_idx)  # [B, D]\n",
    "        away_emb = self.team_embedding(away_team_idx)  # [B, D]\n",
    "\n",
    "        pair_vec = torch.cat([home_vec, away_vec, home_emb, away_emb], dim=-1)\n",
    "        y_pred = self.mlp(pair_vec)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e7c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train: bool = True, model=None, use_players: bool = False):\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"model not set\")\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for batch in loader:\n",
    "        #\n",
    "        # ---- UNPACK BASED ON FLAG ----\n",
    "        #\n",
    "        if use_players:\n",
    "            (\n",
    "                x_home, x_away, y,\n",
    "                home_idx, away_idx,\n",
    "                home_players, away_players,\n",
    "            ) = batch\n",
    "\n",
    "            x_home        = x_home.to(device)\n",
    "            x_away        = x_away.to(device)\n",
    "            y             = y.to(device)\n",
    "            home_idx      = home_idx.to(device)\n",
    "            away_idx      = away_idx.to(device)\n",
    "            home_players  = home_players.to(device)\n",
    "            away_players  = away_players.to(device)\n",
    "        else:\n",
    "            #\n",
    "            # batch may be length 5 or 7 depending on DataLoader\n",
    "            #\n",
    "            if len(batch) == 5:\n",
    "                x_home, x_away, y, home_idx, away_idx = batch\n",
    "            else:\n",
    "                # ignore extra fields if they exist\n",
    "                x_home, x_away, y, home_idx, away_idx, *_ = batch\n",
    "\n",
    "            x_home   = x_home.to(device)\n",
    "            x_away   = x_away.to(device)\n",
    "            y        = y.to(device)\n",
    "            home_idx = home_idx.to(device)\n",
    "            away_idx = away_idx.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            if use_players:\n",
    "                # 🧠 GNN-style model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                )\n",
    "            else:\n",
    "                # 🧠 non-player baseline model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                )\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        all_true.append(y.detach().cpu().numpy())\n",
    "        all_pred.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)\n",
    "    all_pred = np.concatenate(all_pred, axis=0)\n",
    "\n",
    "    # Unscale BEFORE metrics\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    mae = mean_absolute_error(all_true_unscaled, all_pred_unscaled)\n",
    "    rmse = math.sqrt(mean_squared_error(all_true_unscaled, all_pred_unscaled))\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ab37699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScorePredictorGNN(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(35, 16, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(43, 4)\n",
      "  (player_embedding): Embedding(4832, 8, padding_idx=0)\n",
      "  (team_in): Linear(in_features=36, out_features=16, bias=True)\n",
      "  (player_in): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (team_update): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (player_update): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=24, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=24, out_features=2, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.35, inplace=False)\n",
      ")\n",
      "ScorePredictorCrossAttention(\n",
      "  (encoder): TeamSequenceEncoder(\n",
      "    (lstm): LSTM(35, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (cross_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (team_embedding): Embedding(43, 16)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = len(SEQ_FEATURES)\n",
    "\n",
    "P = HOME_PLAYER_IDX.shape[1]   # 10 in your current setup\n",
    "\n",
    "model_a = ScorePredictorGNN(\n",
    "    input_size=input_size,\n",
    "    num_teams=num_teams,\n",
    "    num_players=num_players,\n",
    ").to(device)\n",
    "\n",
    "model_b = ScorePredictorCrossAttention(\n",
    "    input_size=input_size,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=4,\n",
    "    num_teams=num_teams,\n",
    "    team_emb_dim=16,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(model_a)\n",
    "print(model_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb9bfbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.422, MAE 12.192, RMSE 15.738 | Val Loss 0.456, MAE 12.646, RMSE 16.219\n",
      "Epoch 02 | Train Loss 0.418, MAE 12.124, RMSE 15.647 | Val Loss 0.455, MAE 12.631, RMSE 16.206\n",
      "Epoch 03 | Train Loss 0.417, MAE 12.114, RMSE 15.643 | Val Loss 0.454, MAE 12.621, RMSE 16.201\n",
      "Epoch 04 | Train Loss 0.417, MAE 12.109, RMSE 15.640 | Val Loss 0.454, MAE 12.617, RMSE 16.199\n",
      "Epoch 05 | Train Loss 0.417, MAE 12.113, RMSE 15.644 | Val Loss 0.455, MAE 12.622, RMSE 16.209\n",
      "Epoch 06 | Train Loss 0.416, MAE 12.080, RMSE 15.611 | Val Loss 0.454, MAE 12.621, RMSE 16.204\n",
      "Epoch 07 | Train Loss 0.416, MAE 12.085, RMSE 15.618 | Val Loss 0.455, MAE 12.633, RMSE 16.226\n",
      "Epoch 08 | Train Loss 0.415, MAE 12.062, RMSE 15.594 | Val Loss 0.455, MAE 12.631, RMSE 16.220\n",
      "Epoch 09 | Train Loss 0.414, MAE 12.039, RMSE 15.575 | Val Loss 0.455, MAE 12.633, RMSE 16.224\n",
      "Epoch 10 | Train Loss 0.413, MAE 12.038, RMSE 15.560 | Val Loss 0.456, MAE 12.649, RMSE 16.234\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "EPOCHS = 40\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_a.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-3,  # was 5e-3\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "no_improve = 0\n",
    "patience = 6\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_a, use_players=True\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_a, use_players=True\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    if val_rmse < best_val_rmse - 1e-3:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_a.state_dict()\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "model_a.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c19adcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.412, MAE 11.946, RMSE 15.745\n"
     ]
    }
   ],
   "source": [
    "model_a.load_state_dict(best_state)\n",
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_a, use_players=True)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "385a6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 0.420, MAE 12.161, RMSE 15.693 | Val Loss 0.454, MAE 12.627, RMSE 16.211\n",
      "Epoch 02 | Train Loss 0.418, MAE 12.133, RMSE 15.672 | Val Loss 0.454, MAE 12.616, RMSE 16.206\n",
      "Epoch 03 | Train Loss 0.417, MAE 12.104, RMSE 15.633 | Val Loss 0.454, MAE 12.613, RMSE 16.202\n",
      "Epoch 04 | Train Loss 0.416, MAE 12.093, RMSE 15.631 | Val Loss 0.454, MAE 12.612, RMSE 16.202\n",
      "Epoch 05 | Train Loss 0.415, MAE 12.075, RMSE 15.601 | Val Loss 0.454, MAE 12.615, RMSE 16.203\n",
      "Epoch 06 | Train Loss 0.415, MAE 12.067, RMSE 15.591 | Val Loss 0.454, MAE 12.615, RMSE 16.202\n",
      "Epoch 07 | Train Loss 0.414, MAE 12.060, RMSE 15.588 | Val Loss 0.454, MAE 12.614, RMSE 16.202\n",
      "Epoch 08 | Train Loss 0.414, MAE 12.061, RMSE 15.582 | Val Loss 0.454, MAE 12.613, RMSE 16.200\n",
      "Epoch 09 | Train Loss 0.414, MAE 12.040, RMSE 15.575 | Val Loss 0.454, MAE 12.614, RMSE 16.199\n",
      "Epoch 10 | Train Loss 0.413, MAE 12.034, RMSE 15.553 | Val Loss 0.454, MAE 12.611, RMSE 16.197\n",
      "Epoch 11 | Train Loss 0.412, MAE 12.021, RMSE 15.544 | Val Loss 0.454, MAE 12.611, RMSE 16.197\n",
      "Epoch 12 | Train Loss 0.412, MAE 12.012, RMSE 15.532 | Val Loss 0.454, MAE 12.611, RMSE 16.196\n",
      "Epoch 13 | Train Loss 0.412, MAE 12.004, RMSE 15.528 | Val Loss 0.453, MAE 12.610, RMSE 16.195\n",
      "Epoch 14 | Train Loss 0.411, MAE 11.981, RMSE 15.505 | Val Loss 0.453, MAE 12.608, RMSE 16.193\n",
      "Epoch 15 | Train Loss 0.411, MAE 11.983, RMSE 15.505 | Val Loss 0.453, MAE 12.611, RMSE 16.194\n",
      "Epoch 16 | Train Loss 0.410, MAE 11.966, RMSE 15.479 | Val Loss 0.453, MAE 12.611, RMSE 16.194\n",
      "Epoch 17 | Train Loss 0.410, MAE 11.971, RMSE 15.481 | Val Loss 0.453, MAE 12.613, RMSE 16.197\n",
      "Epoch 18 | Train Loss 0.409, MAE 11.954, RMSE 15.467 | Val Loss 0.454, MAE 12.616, RMSE 16.198\n",
      "Epoch 19 | Train Loss 0.409, MAE 11.947, RMSE 15.467 | Val Loss 0.454, MAE 12.616, RMSE 16.197\n",
      "Epoch 20 | Train Loss 0.409, MAE 11.942, RMSE 15.449 | Val Loss 0.454, MAE 12.619, RMSE 16.198\n",
      "Epoch 21 | Train Loss 0.408, MAE 11.927, RMSE 15.429 | Val Loss 0.454, MAE 12.619, RMSE 16.198\n",
      "Epoch 22 | Train Loss 0.408, MAE 11.928, RMSE 15.433 | Val Loss 0.454, MAE 12.621, RMSE 16.199\n",
      "Epoch 23 | Train Loss 0.407, MAE 11.905, RMSE 15.417 | Val Loss 0.454, MAE 12.621, RMSE 16.199\n",
      "Epoch 24 | Train Loss 0.407, MAE 11.909, RMSE 15.417 | Val Loss 0.454, MAE 12.622, RMSE 16.200\n",
      "Epoch 25 | Train Loss 0.407, MAE 11.907, RMSE 15.414 | Val Loss 0.454, MAE 12.622, RMSE 16.200\n",
      "Epoch 26 | Train Loss 0.407, MAE 11.911, RMSE 15.415 | Val Loss 0.454, MAE 12.624, RMSE 16.201\n",
      "Epoch 27 | Train Loss 0.407, MAE 11.916, RMSE 15.420 | Val Loss 0.454, MAE 12.624, RMSE 16.201\n",
      "Epoch 28 | Train Loss 0.407, MAE 11.900, RMSE 15.411 | Val Loss 0.454, MAE 12.624, RMSE 16.201\n",
      "Epoch 29 | Train Loss 0.407, MAE 11.910, RMSE 15.415 | Val Loss 0.454, MAE 12.624, RMSE 16.202\n",
      "Epoch 30 | Train Loss 0.407, MAE 11.903, RMSE 15.409 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 31 | Train Loss 0.407, MAE 11.902, RMSE 15.408 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 32 | Train Loss 0.406, MAE 11.891, RMSE 15.399 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 33 | Train Loss 0.407, MAE 11.915, RMSE 15.416 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 34 | Train Loss 0.407, MAE 11.909, RMSE 15.417 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 35 | Train Loss 0.407, MAE 11.912, RMSE 15.415 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 36 | Train Loss 0.407, MAE 11.916, RMSE 15.424 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 37 | Train Loss 0.407, MAE 11.900, RMSE 15.402 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 38 | Train Loss 0.407, MAE 11.905, RMSE 15.414 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 39 | Train Loss 0.407, MAE 11.900, RMSE 15.411 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n",
      "Epoch 40 | Train Loss 0.407, MAE 11.906, RMSE 15.410 | Val Loss 0.454, MAE 12.625, RMSE 16.202\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL B\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_b.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',      # lower RMSE is better\n",
    "    factor=0.5,      # reduce LR by half\n",
    "    patience=2,      # wait 2 epochs before dropping LR\n",
    ")\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae, train_rmse = run_epoch(\n",
    "        train_loader, train=True, model=model_b, use_players=False\n",
    "    )\n",
    "    val_loss, val_mae, val_rmse = run_epoch(\n",
    "        val_loader, train=False, model=model_b, use_players=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss {train_loss:.3f}, MAE {train_mae:.3f}, RMSE {train_rmse:.3f} | \"\n",
    "        f\"Val Loss {val_loss:.3f}, MAE {val_mae:.3f}, RMSE {val_rmse:.3f}\"\n",
    "    )\n",
    "\n",
    "    # 🔥 IMPORTANT → Notify the scheduler\n",
    "    scheduler.step(val_rmse)  # or val_loss if you prefer loss\n",
    "\n",
    "    # 🔥 Standard early stopping capture\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_state = model_b.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b74ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.417, MAE 12.078, RMSE 15.871\n"
     ]
    }
   ],
   "source": [
    "model_b.load_state_dict(best_state)\n",
    "test_loss, test_mae, test_rmse = run_epoch(test_loader, train=False, model=model_b, use_players=False)\n",
    "print(f\"Test Loss {test_loss:.3f}, MAE {test_mae:.3f}, RMSE {test_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ad7da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant baseline | MAE 11.950, RMSE 15.717\n"
     ]
    }
   ],
   "source": [
    "# Using your train split\n",
    "\n",
    "\n",
    "def evaluate_constant_baseline(Y_true, const_pred):\n",
    "    const = np.tile(const_pred, (Y_true.shape[0], 1))\n",
    "    mae = mean_absolute_error(Y_true, const)\n",
    "    rmse = math.sqrt(mean_squared_error(Y_true, const))\n",
    "    return mae, rmse\n",
    "\n",
    "zero_const = np.array([0.0, 0.0])\n",
    "baseline_mae_err, baseline_rmse_err = evaluate_constant_baseline(Y_test_raw, zero_const)\n",
    "print(f\"Constant baseline | MAE {baseline_mae_err:.3f}, RMSE {baseline_rmse_err:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ea930d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A winner accuracy: 67.461%\n",
      "Model B winner accuracy: 66.746%\n",
      "Model A margin accuracy (within 5 points): 33.611%\n",
      "Model B margin accuracy (within 5 points): 33.254%\n",
      "Model A totals accuracy (within 5 points): 24.315%\n",
      "Model B totals accuracy (within 5 points): 22.527%\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, loader, use_players: bool):\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if use_players:\n",
    "                # New dataset: 7-tuple\n",
    "                (\n",
    "                    x_home, x_away, y,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                ) = batch\n",
    "\n",
    "                x_home = x_home.to(device)\n",
    "                x_away = x_away.to(device)\n",
    "                y = y.to(device)\n",
    "                home_idx = home_idx.to(device)\n",
    "                away_idx = away_idx.to(device)\n",
    "                home_players = home_players.to(device)\n",
    "                away_players = away_players.to(device)\n",
    "\n",
    "                # ✅ GNN / player-aware model\n",
    "                y_pred = model(\n",
    "                    x_home, x_away,\n",
    "                    home_idx, away_idx,\n",
    "                    home_players, away_players,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # Old models (5-input), but handle both 5- and 7-tuples gracefully\n",
    "                if len(batch) == 5:\n",
    "                    x_home, x_away, y, home_idx, away_idx = batch\n",
    "                elif len(batch) >= 7:\n",
    "                    x_home, x_away, y, home_idx, away_idx, *_ = batch\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "\n",
    "                x_home = x_home.to(device)\n",
    "                x_away = x_away.to(device)\n",
    "                y = y.to(device)\n",
    "                home_idx = home_idx.to(device)\n",
    "                away_idx = away_idx.to(device)\n",
    "\n",
    "                # ✅ old MLP / cross-attn model\n",
    "                y_pred = model(x_home, x_away, home_idx, away_idx)\n",
    "\n",
    "            all_true.append(y.cpu().numpy())\n",
    "            all_pred.append(y_pred.cpu().numpy())\n",
    "\n",
    "    all_true = np.concatenate(all_true, axis=0)  # scaled\n",
    "    all_pred = np.concatenate(all_pred, axis=0)  # scaled\n",
    "\n",
    "    # Unscale before returning\n",
    "    all_true_unscaled = y_scaler.inverse_transform(all_true)\n",
    "    all_pred_unscaled = y_scaler.inverse_transform(all_pred)\n",
    "\n",
    "    return all_true_unscaled, all_pred_unscaled\n",
    "\n",
    "\n",
    "Y_true_test, Y_pred_a = get_predictions(model_a, test_loader, use_players=True)\n",
    "_, Y_pred_b = get_predictions(model_b, test_loader, use_players=False)\n",
    "\n",
    "Y_true_err = Y_true_test       # shape [N, 2]\n",
    "Y_pred_err_a = Y_pred_a\n",
    "Y_pred_err_b = Y_pred_b\n",
    "\n",
    "\n",
    "# Residuals\n",
    "true_margin_err = Y_true_err[:, 0]\n",
    "true_total_err  = Y_true_err[:, 1]\n",
    "\n",
    "pred_margin_err_a = Y_pred_err_a[:, 0]\n",
    "pred_total_err_a  = Y_pred_err_a[:, 1]\n",
    "\n",
    "pred_margin_err_b = Y_pred_err_b[:, 0]\n",
    "pred_total_err_b  = Y_pred_err_b[:, 1]\n",
    "\n",
    "# Restore true margin/total using test lines\n",
    "true_margin = spread_test + true_margin_err\n",
    "true_total  = total_test  + true_total_err\n",
    "\n",
    "# Restore model-implied margin/total\n",
    "pred_margin_a = spread_test + pred_margin_err_a\n",
    "pred_total_a  = total_test  + pred_total_err_a\n",
    "\n",
    "pred_margin_b = spread_test + pred_margin_err_b\n",
    "pred_total_b  = total_test  + pred_total_err_b\n",
    "\n",
    "\n",
    "# True scores\n",
    "true_home = (true_total + true_margin) / 2\n",
    "true_away = (true_total - true_margin) / 2\n",
    "\n",
    "# Model A scores\n",
    "pred_home_a = (pred_total_a + pred_margin_a) / 2\n",
    "pred_away_a = (pred_total_a - pred_margin_a) / 2\n",
    "\n",
    "# Model B scores\n",
    "pred_home_b = (pred_total_b + pred_margin_b) / 2\n",
    "pred_away_b = (pred_total_b - pred_margin_b) / 2\n",
    "\n",
    "\n",
    "def winner_accuracy(true_margin, pred_margin):\n",
    "    return ((true_margin > 0) == (pred_margin > 0)).mean()\n",
    "\n",
    "def margin_accuracy(true_margin, pred_margin, threshold=5.0):\n",
    "    return (np.abs(true_margin - pred_margin) < threshold).mean()\n",
    "\n",
    "def totals_accuracy(true_total, pred_total, threshold=5.0):\n",
    "    return (np.abs(true_total - pred_total) < threshold).mean()\n",
    "\n",
    "\n",
    "acc_a = winner_accuracy(true_margin, pred_margin_a)\n",
    "acc_b = winner_accuracy(true_margin, pred_margin_b)\n",
    "print(f\"Model A winner accuracy: {acc_a:.3%}\")\n",
    "print(f\"Model B winner accuracy: {acc_b:.3%}\")\n",
    "\n",
    "margin_a = margin_accuracy(true_margin, pred_margin_a)\n",
    "margin_b = margin_accuracy(true_margin, pred_margin_b)\n",
    "print(f\"Model A margin accuracy (within 5 points): {margin_a:.3%}\")\n",
    "print(f\"Model B margin accuracy (within 5 points): {margin_b:.3%}\")\n",
    "\n",
    "total_a = totals_accuracy(true_total, pred_total_a)\n",
    "total_b = totals_accuracy(true_total, pred_total_b)\n",
    "print(f\"Model A totals accuracy (within 5 points): {total_a:.3%}\")\n",
    "print(f\"Model B totals accuracy (within 5 points): {total_b:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73da3916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Spread WR: 0.5518474374255066 A Totals WR: 0.48748510131108463\n",
      "B Spread WR: 0.5065554231227652 B Totals WR: 0.46722288438617404\n"
     ]
    }
   ],
   "source": [
    "def spread_win_rate(true_margin_err, pred_margin_err):\n",
    "    # true_margin_err = margin - spread\n",
    "    # pred_margin_err = model’s predicted error\n",
    "    actual_side = true_margin_err > 0      # True = home covers, False = away covers\n",
    "    pred_side   = pred_margin_err > 0\n",
    "\n",
    "    wins  = np.sum(actual_side == pred_side)\n",
    "    losses = np.sum(actual_side != pred_side)\n",
    "    return wins, losses, wins / (wins + losses)\n",
    "\n",
    "def totals_win_rate(true_total_err, pred_total_err):\n",
    "    actual_over = true_total_err > 0\n",
    "    pred_over   = pred_total_err > 0\n",
    "\n",
    "    wins  = np.sum(actual_over == pred_over)\n",
    "    losses = np.sum(actual_over != pred_over)\n",
    "    return wins, losses, wins / (wins + losses)\n",
    "\n",
    "# example\n",
    "w_s, l_s, wr_s = spread_win_rate(true_margin_err, pred_margin_err_a)\n",
    "w_t, l_t, wr_t = totals_win_rate(true_total_err, pred_total_err_a)\n",
    "print(\"A Spread WR:\", wr_s, \"A Totals WR:\", wr_t)\n",
    "\n",
    "w_s, l_s, wr_s = spread_win_rate(true_margin_err, pred_margin_err_b)\n",
    "w_t, l_t, wr_t = totals_win_rate(true_total_err, pred_total_err_b)\n",
    "print(\"B Spread WR:\", wr_s, \"B Totals WR:\", wr_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3992c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backtest_spread_from_errors(true_err, pred_err, threshold=0.0):\n",
    "    \"\"\"\n",
    "    true_err: (N,) array, (margin - spread)\n",
    "    pred_err: (N,) array, model prediction of that error\n",
    "    threshold: only bet when |pred_err| >= threshold points\n",
    "    \n",
    "    Returns dict with n_bets, win_rate, roi, wins, losses, pushes\n",
    "    \"\"\"\n",
    "    # Only bet when model thinks it's far enough from the line\n",
    "    mask = np.abs(pred_err) >= threshold\n",
    "    if mask.sum() == 0:\n",
    "        return {\n",
    "            'n_bets': 0,\n",
    "            'win_rate': np.nan,\n",
    "            'roi': np.nan,\n",
    "            'wins': 0,\n",
    "            'losses': 0,\n",
    "            'pushes': 0,\n",
    "        }\n",
    "\n",
    "    t = true_err[mask]\n",
    "    p = pred_err[mask]\n",
    "\n",
    "    # Actual result vs line\n",
    "    # t > 0 → home covers, t < 0 → away covers, t == 0 → push\n",
    "    # Model prediction: p > 0 → bet home, p < 0 → bet away\n",
    "    actual_side = np.sign(t)   # +1 home, -1 away, 0 push\n",
    "    pred_side   = np.sign(p)\n",
    "\n",
    "    pushes = np.sum(actual_side == 0)\n",
    "    # Exclude pushes for W/L\n",
    "    non_push_mask = (actual_side != 0)\n",
    "    actual_np = actual_side[non_push_mask]\n",
    "    pred_np   = pred_side[non_push_mask]\n",
    "\n",
    "    wins   = np.sum(actual_np == pred_np)\n",
    "    losses = np.sum(actual_np != pred_np)\n",
    "\n",
    "    if wins + losses == 0:\n",
    "        return {\n",
    "            'n_bets': int(mask.sum()),\n",
    "            'win_rate': np.nan,\n",
    "            'roi': np.nan,\n",
    "            'wins': 0,\n",
    "            'losses': 0,\n",
    "            'pushes': int(pushes),\n",
    "        }\n",
    "\n",
    "    win_rate = wins / (wins + losses)\n",
    "\n",
    "    # -110 juice: W = +1, L = -1.1\n",
    "    profit_units = wins * 1.0 - losses * 1.1\n",
    "    roi = profit_units / (wins + losses)\n",
    "\n",
    "    return {\n",
    "        'n_bets': int(mask.sum()),\n",
    "        'win_rate': win_rate,\n",
    "        'roi': roi,\n",
    "        'wins': int(wins),\n",
    "        'losses': int(losses),\n",
    "        'pushes': int(pushes),\n",
    "    }\n",
    "\n",
    "def backtest_totals_from_errors(true_err, pred_err, threshold=0.0):\n",
    "    \"\"\"\n",
    "    true_err: (N,) array, (total - total_line)\n",
    "    pred_err: (N,) array, model prediction of that error\n",
    "    threshold: only bet when |pred_err| >= threshold points\n",
    "    \"\"\"\n",
    "    mask = np.abs(pred_err) >= threshold\n",
    "    if mask.sum() == 0:\n",
    "        return {\n",
    "            'n_bets': 0,\n",
    "            'win_rate': np.nan,\n",
    "            'roi': np.nan,\n",
    "            'wins': 0,\n",
    "            'losses': 0,\n",
    "            'pushes': 0,\n",
    "        }\n",
    "\n",
    "    t = true_err[mask]\n",
    "    p = pred_err[mask]\n",
    "\n",
    "    # t > 0 → game went over\n",
    "    # t < 0 → game went under\n",
    "    actual_side = np.sign(t)   # +1 over, -1 under, 0 push\n",
    "    pred_side   = np.sign(p)\n",
    "\n",
    "    pushes = np.sum(actual_side == 0)\n",
    "    non_push_mask = (actual_side != 0)\n",
    "    actual_np = actual_side[non_push_mask]\n",
    "    pred_np   = pred_side[non_push_mask]\n",
    "\n",
    "    wins   = np.sum(actual_np == pred_np)\n",
    "    losses = np.sum(actual_np != pred_np)\n",
    "\n",
    "    if wins + losses == 0:\n",
    "        return {\n",
    "            'n_bets': int(mask.sum()),\n",
    "            'win_rate': np.nan,\n",
    "            'roi': np.nan,\n",
    "            'wins': 0,\n",
    "            'losses': 0,\n",
    "            'pushes': int(pushes),\n",
    "        }\n",
    "\n",
    "    win_rate = wins / (wins + losses)\n",
    "    profit_units = wins * 1.0 - losses * 1.1\n",
    "    roi = profit_units / (wins + losses)\n",
    "\n",
    "    return {\n",
    "        'n_bets': int(mask.sum()),\n",
    "        'win_rate': win_rate,\n",
    "        'roi': roi,\n",
    "        'wins': int(wins),\n",
    "        'losses': int(losses),\n",
    "        'pushes': int(pushes),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ffc7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPREAD BACKTEST (ATS) ===\n",
      "|   Threshold | Model   |   Bets |   Win Rate |     ROI |   Wins |   Losses |   Pushes |\n",
      "|-------------|---------|--------|------------|---------|--------|----------|----------|\n",
      "|      0.0000 | A       |    839 |     0.5518 |  0.0589 |    463 |      376 |        0 |\n",
      "|      0.0000 | B       |    839 |     0.5066 | -0.0362 |    425 |      414 |        0 |\n",
      "|      1.0000 | A       |    247 |     0.5304 |  0.0138 |    131 |      116 |        0 |\n",
      "|      1.0000 | B       |    329 |     0.4742 | -0.1043 |    156 |      173 |        0 |\n",
      "|      2.0000 | A       |     64 |     0.6094 |  0.1797 |     39 |       25 |        0 |\n",
      "|      2.0000 | B       |     64 |     0.4062 | -0.2469 |     26 |       38 |        0 |\n",
      "|      3.0000 | A       |     12 |     0.5000 | -0.0500 |      6 |        6 |        0 |\n",
      "|      3.0000 | B       |      6 |     0.3333 | -0.4000 |      2 |        4 |        0 |\n",
      "|      4.0000 | A       |      1 |     0.0000 | -1.1000 |      0 |        1 |        0 |\n",
      "|      4.0000 | B       |      2 |     0.5000 | -0.0500 |      1 |        1 |        0 |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=== TOTALS BACKTEST (O/U) ===\n",
      "|   Threshold | Model   |   Bets |   Win Rate |     ROI |   Wins |   Losses |   Pushes |\n",
      "|-------------|---------|--------|------------|---------|--------|----------|----------|\n",
      "|      0.0000 | A       |    839 |     0.4875 | -0.0763 |    409 |      430 |        0 |\n",
      "|      0.0000 | B       |    839 |     0.4672 | -0.1188 |    392 |      447 |        0 |\n",
      "|      1.0000 | A       |    261 |     0.4828 | -0.0862 |    126 |      135 |        0 |\n",
      "|      1.0000 | B       |    551 |     0.4864 | -0.0786 |    268 |      283 |        0 |\n",
      "|      2.0000 | A       |     51 |     0.5882 |  0.1353 |     30 |       21 |        0 |\n",
      "|      2.0000 | B       |    340 |     0.4765 | -0.0994 |    162 |      178 |        0 |\n",
      "|      3.0000 | A       |      5 |     0.4000 | -0.2600 |      2 |        3 |        0 |\n",
      "|      3.0000 | B       |    181 |     0.5028 | -0.0442 |     91 |       90 |        0 |\n",
      "|      4.0000 | A       |      2 |     0.5000 | -0.0500 |      1 |        1 |        0 |\n",
      "|      4.0000 | B       |     91 |     0.5055 | -0.0385 |     46 |       45 |        0 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "spread_rows = []\n",
    "for t in [0.0, 1.0, 2.0, 3.0, 4.0]:\n",
    "    res_a = backtest_spread_from_errors(true_margin_err, pred_margin_err_a, threshold=t)\n",
    "    res_b = backtest_spread_from_errors(true_margin_err, pred_margin_err_b, threshold=t)\n",
    "\n",
    "    spread_rows.append([\n",
    "        t, \"A\", res_a['n_bets'], res_a['win_rate'], res_a['roi'], res_a['wins'], res_a['losses'], res_a['pushes']\n",
    "    ])\n",
    "    spread_rows.append([\n",
    "        t, \"B\", res_b['n_bets'], res_b['win_rate'], res_b['roi'], res_b['wins'], res_b['losses'], res_b['pushes']\n",
    "    ])\n",
    "\n",
    "print(\"\\n=== SPREAD BACKTEST (ATS) ===\")\n",
    "print(tabulate(\n",
    "    spread_rows,\n",
    "    headers=[\"Threshold\", \"Model\", \"Bets\", \"Win Rate\", \"ROI\", \"Wins\", \"Losses\", \"Pushes\"],\n",
    "    floatfmt=\".4f\",\n",
    "    tablefmt=\"github\"\n",
    "))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "    \n",
    "total_rows = []\n",
    "for t in [0.0, 1.0, 2.0, 3.0, 4.0]:\n",
    "    res_total_a = backtest_totals_from_errors(true_total_err, pred_total_err_a, threshold=t)\n",
    "    res_total_b = backtest_totals_from_errors(true_total_err, pred_total_err_b, threshold=t)\n",
    "\n",
    "    total_rows.append([\n",
    "        t, \"A\", res_total_a['n_bets'], res_total_a['win_rate'], res_total_a['roi'], res_total_a['wins'], res_total_a['losses'], res_total_a['pushes']\n",
    "    ])\n",
    "    total_rows.append([\n",
    "        t, \"B\", res_total_b['n_bets'], res_total_b['win_rate'], res_total_b['roi'], res_total_b['wins'], res_total_b['losses'], res_total_b['pushes']\n",
    "    ])\n",
    "\n",
    "print(\"\\n=== TOTALS BACKTEST (O/U) ===\")\n",
    "print(tabulate(\n",
    "    total_rows,\n",
    "    headers=[\"Threshold\", \"Model\", \"Bets\", \"Win Rate\", \"ROI\", \"Wins\", \"Losses\", \"Pushes\"],\n",
    "    floatfmt=\".4f\",\n",
    "    tablefmt=\"github\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8eaf0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure test-set totals win rate (model A): 0.48748510131108463\n"
     ]
    }
   ],
   "source": [
    "def simple_backtest_totals(true_err, pred_err):\n",
    "    # true_err = total - line\n",
    "    # pred_err = model's prediction for that error\n",
    "    \n",
    "    actual_over = true_err > 0\n",
    "    pred_over   = pred_err > 0\n",
    "    \n",
    "    wins  = np.sum(actual_over == pred_over)\n",
    "    losses = np.sum(actual_over != pred_over)\n",
    "    return wins, losses, wins / (wins + losses)\n",
    "\n",
    "wins, losses, wr = simple_backtest_totals(true_total_err, pred_total_err_a)\n",
    "print(\"Pure test-set totals win rate (model A):\", wr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37110b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test MAE: 11.946, RMSE: 15.745\n",
      "Baseline residual MAE (0): 11.950, RMSE: 15.717\n"
     ]
    }
   ],
   "source": [
    "# After you compute test metrics (all_true, all_pred) inside run_epoch,\n",
    "# but you can also just recompute once outside.\n",
    "\n",
    "# 1) Get test residuals and model predictions (unscaled):\n",
    "test_loss, test_mae, test_rmse = run_epoch(\n",
    "    test_loader, train=False, model=model_a, use_players=True\n",
    ")\n",
    "\n",
    "print(f\"Model test MAE: {test_mae:.3f}, RMSE: {test_rmse:.3f}\")\n",
    "\n",
    "# 2) Compute baseline: always predict 0 residual\n",
    "#    (shape must match all_true_unscaled → [N, 2])\n",
    "y_true = []  # collect inside a loop like in run_epoch, but for test only\n",
    "for batch in test_loader:\n",
    "    if len(batch) == 7:\n",
    "        _, _, y, _, _, _, _ = batch\n",
    "    else:\n",
    "        _, _, y, _, _ = batch\n",
    "    y_true.append(y.numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_true_unscaled = y_scaler.inverse_transform(y_true)\n",
    "\n",
    "baseline_pred = np.zeros_like(y_true_unscaled)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "baseline_mae = mean_absolute_error(y_true_unscaled, baseline_pred)\n",
    "baseline_rmse = math.sqrt(mean_squared_error(y_true_unscaled, baseline_pred))\n",
    "\n",
    "print(f\"Baseline residual MAE (0): {baseline_mae:.3f}, RMSE: {baseline_rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb8a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
